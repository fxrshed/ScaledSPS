{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook tests SPS2 method with the following constraint: Second order Taylor series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gU0LRobGb5cz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farshed.abdukhakimov/.conda/envs/sps2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "import math\n",
    "# from adahessian import AdaHessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i5cdPg-mQluX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import matplotlib\n",
    "# import fqs\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wMAftncHb5c4"
   },
   "source": [
    "# Generate data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$f(x) = \\frac1n \\sum_{i=1}^n \\frac12(a_i^Tx-b_i)^2$\n",
    "suppose $x^*=xo$, $b_i=a_i^Txo$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n = 1000\n",
    "d = 20\n",
    "A = np.random.randn(n,d)\n",
    "xopt = np.random.randn(d)\n",
    "b= A @ xopt \n",
    "tA = torch.Tensor(A)\n",
    "tb = torch.Tensor(b)\n",
    "xopt = torch.Tensor(xopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798, ..., -0.20515826,\n",
       "         0.3130677 , -0.85409574],\n",
       "       [-2.55298982,  0.6536186 ,  0.8644362 , ...,  1.20237985,\n",
       "        -0.38732682, -0.30230275],\n",
       "       [-1.04855297, -1.42001794, -1.70627019, ...,  0.3024719 ,\n",
       "        -0.63432209, -0.36274117],\n",
       "       ...,\n",
       "       [-0.85259255, -0.1797548 , -0.84311081, ...,  0.62572622,\n",
       "        -0.59228872, -0.73691532],\n",
       "       [-0.06113942, -0.49714704,  0.43210231, ..., -0.7888105 ,\n",
       "         0.20570363,  0.34291633],\n",
       "       [-0.75590132,  0.9190708 ,  1.53418368, ..., -0.05725925,\n",
       "        -1.05893126, -0.32652844]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.3005e-01, -4.7998e-04,  8.1812e-01,  4.2821e-01, -2.5039e+00,\n",
       "         1.2048e-01,  8.0789e-01,  6.0212e-01, -8.6519e-01, -1.5332e-01,\n",
       "        -2.4049e-01, -6.0763e-02,  5.3287e-01,  7.6440e-01, -8.5608e-01,\n",
       "        -1.6823e+00,  6.5307e-01,  9.3026e-01,  4.0518e-01,  2.0400e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(At,x,bt):\n",
    "    return 1/2*torch.mean(torch.norm(At@x-bt)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfun(At,x,bt):\n",
    "    return At.T@(At@x-bt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 14248.9342353893\n",
      "loss= 4.344033080458574e-06\n",
      "loss= 7.255037454958109e-16\n",
      "loss= 4.4434545228429845e-25\n",
      "loss= 1.715664616778815e-28\n",
      "loss= 3.424026107208514e-28\n",
      "loss= 1.7826407565248253e-28\n",
      "loss= 1.056950353479715e-28\n",
      "loss= 7.52838311541193e-29\n",
      "loss= 1.3765314647315554e-28\n",
      "loss= 5.613238378713262e-29\n",
      "loss= 1.701351105432129e-28\n",
      "loss= 2.064138529056353e-28\n",
      "loss= 1.0166637509030228e-28\n",
      "loss= 1.6426988349057602e-28\n",
      "loss= 7.738232442152364e-29\n",
      "loss= 1.4431224184886885e-28\n",
      "loss= 1.4287819441227813e-28\n",
      "loss= 9.717356571603574e-29\n",
      "loss= 2.4134213319105327e-29\n",
      "loss= 0.0\n",
      "loss= 2.3454437085934416e-28\n",
      "loss= 2.3378825076317764e-28\n",
      "loss= 1.4493354684892817e-28\n",
      "loss= 2.8325036878091955e-29\n",
      "loss= 9.151402798145942e-29\n",
      "loss= 1.9024181916261563e-28\n",
      "loss= 2.4134213319105327e-29\n",
      "loss= 5.265646542350255e-29\n",
      "loss= 0.0\n",
      "loss= 1.9006617435168753e-29\n",
      "loss= 1.843839106437674e-28\n",
      "loss= 1.6599243523283594e-28\n",
      "loss= 1.2056321451864096e-28\n",
      "loss= 1.1840501742296065e-28\n",
      "loss= 2.730710586528553e-28\n",
      "loss= 1.2347676133851e-28\n",
      "loss= 1.2466775641611902e-28\n",
      "loss= 8.720610788185403e-29\n",
      "loss= 3.819196116917665e-29\n",
      "loss= 9.86754058866689e-29\n",
      "loss= 4.277721518077377e-29\n",
      "loss= 3.7600315490260883e-29\n",
      "loss= 6.329992466816416e-29\n",
      "loss= 1.3680573729762518e-28\n",
      "loss= 6.379912570974933e-29\n",
      "loss= 7.515132717394546e-29\n",
      "loss= 6.802692712366819e-29\n",
      "loss= 7.142272680161178e-29\n",
      "loss= 1.3382016069783604e-28\n",
      "loss= 1.266614790945487e-28\n",
      "loss= 1.4251265290883341e-28\n",
      "loss= 5.973772464302554e-29\n",
      "loss= 5.575027928616619e-29\n",
      "loss= 1.4628786078582127e-28\n",
      "loss= 9.684500206752329e-29\n",
      "loss= 1.5830566363879763e-28\n",
      "loss= 1.1189036679307636e-28\n",
      "loss= 2.744916245798353e-28\n",
      "loss= 1.2922258073459483e-28\n",
      "loss= 1.064962222048366e-28\n",
      "loss= 6.144486894573037e-29\n",
      "loss= 3.774206393416778e-29\n",
      "loss= 1.5815428554516877e-28\n",
      "loss= 1.9862847369844433e-28\n",
      "loss= 1.7756496308266996e-28\n",
      "loss= 1.6938630898083515e-28\n",
      "loss= 4.8816931486372145e-29\n",
      "loss= 3.3840900238817e-29\n",
      "loss= 2.0031828463164969e-28\n",
      "loss= 1.49925172078791e-28\n",
      "loss= 1.8566426887079604e-28\n",
      "loss= 2.598911496714356e-28\n",
      "loss= 3.540629609761494e-29\n",
      "loss= 1.9242967557943953e-28\n",
      "loss= 0.0\n",
      "loss= 1.3238072065740104e-29\n",
      "loss= 0.0\n",
      "loss= 1.117100997502817e-28\n",
      "loss= 5.789499487223582e-29\n",
      "loss= 1.474881003271634e-28\n",
      "loss= 5.644053257823458e-29\n",
      "loss= 1.519543318681974e-28\n",
      "loss= 7.513746047834588e-29\n",
      "loss= 1.2916095097637446e-28\n",
      "loss= 2.0359390628106348e-28\n",
      "loss= 7.006687212076316e-29\n",
      "loss= 2.5246977122373387e-28\n",
      "loss= 9.788654498144788e-29\n",
      "loss= 8.503674039249626e-29\n",
      "loss= 2.4373067150808235e-28\n",
      "loss= 1.9989342448591786e-28\n",
      "loss= 1.5493104919024233e-28\n",
      "loss= 1.1908101883344055e-28\n",
      "loss= 1.1925974513227968e-28\n",
      "loss= 1.3644828469994689e-29\n",
      "loss= 8.256538708785856e-29\n",
      "loss= 8.782240546405795e-29\n",
      "loss= 3.9449208236872624e-29\n",
      "loss= 1.5186073167290016e-28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0f38ed5720>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJYAAAF1CAYAAAC6f2D4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABiRElEQVR4nO3dd3yV5f3/8deVdRJIAshUhqACglsR3HvPDq17j2odnba2dtjqr9pql99qLXW3zqpVVBx14igKIiqIKKJi2DuskHX9/rhPIIQEQsiCvJ6PRx6Hc537nHxyn4xz3lzX5woxRiRJkiRJkqQNldHSBUiSJEmSJGnTZLAkSZIkSZKkBjFYkiRJkiRJUoMYLEmSJEmSJKlBDJYkSZIkSZLUIAZLkiRJkiRJahCDJUlajxDCuSGEN1q6DkmSJElqbQyWJK0hhPBFCOGwFvrcR4QQPg4hLAkhvB9C2K0e99kyhPCPEMKMEMLSEMLUEMI9IYTtm6NmSZIkSWrLDJYktSb3An8ACoHTgYXrOjiE0Bl4C2gH7A8UALsDrwGH13GfrEasV5IkSZLaNIMlSfUSQkiFEP6cnhk0I/3vVPq2LiGEp0MIi0IIC0IIr4cQMtK3/SSEMD09C2lyCOHQdXyaMuCLmJgYY/xiPWV9HygGzooxfpa+36IY490xxv9Lf/6+IYQYQrgghDANeDk9/u8QwqwQwuIQwqgQwg7VvtbOIYQRIYTiEMI7wLYNPW+SJEmStDkzWJJUX9cAewG7ArsAQ4Gfp2/7IVAEdAW6Az8DYghhIHA5sGeMsQA4EviitgcPIQTgHeCOEMLW9azpMOA/McbKehx7IDAoXQPAs0B/oBswDri/2rG3AiXAlsD56Q9JkiRJUg0GS5Lq6wzgNzHGOTHGucCvgbPSt5WRhDBbxxjLYoyvxxgjUAGkgMEhhOwY4xcxxs/qePyfkCxp+xnwclW4FEK4KITwWB336QLMqroSQjghPWtqSQjhhRrHXhtjXBZjXAEQY7wrxrgkxrgSuBbYJYTQIYSQCXwT+GX6+AkkS/QkSZIkSTUYLEmqr62AL6td/zI9BnATMAV4Id08+2qAGOMU4Hskwc2cEMJDIYStqN13gZtjjPenH+/VdLi0D/BiHfeZTxJokf58I2KMHUmWyOXUOParqn+EEDJDCDeGED4LIRSzehZVF5JZV1nVj6/xdUuSJEmS0gyWJNXXDKD6ErU+6THSM39+GGPcBjge+EFVL6UY4wMxxv3S943A7+p4/CygPH2f24F/kDTh3g+4u477vAR8raqf03rEav8+HTiRZCldB6BvejwAc9N19K7xtUqSJEmSajBYklSb7BBCbrWPLOBB4OchhK4hhC7AL4F/AYQQjgshbJfuk1RMsgSuIoQwMIRwSLrJdwmwIn1bbf4N3BRC2Cb9+d4BtgAqgdw67vNHoBPwzxDCtiFRQNIHal0KgJUkM57aAb+tuiHGWAE8DlwbQmgXQhgMnLOex5MkSZKkNslgSVJtRpKEQFUf1wLXA2OBD4APSRpeX58+vj/JcrWlwP+A22KMr5L0V7oRmEfSC6kbSQ+l2vwQeB0YBcxJH3ck8D7weAghu+YdYozzSBqKlwBvAEuA8STB0aXr+PruI1neNh34CBhd4/bLgfx0zfdQ94wpSZIkSWrTQtJfV5IkSZIkSdowzliSJEmSJElSgxgsSZIkbSZCCHeFEOaEECbUcXsIIdwSQpgSQvgghLB7c9coSZI2LwZLkiRJm497gKPWcfvRJH3x+gMXA39rhpokSdJmzGBJkiRpMxFjHAUsWMchJwL3xcRooGMIYcvmqU6SJG2ODJYkSZLajp7AV9WuF6XHJEmSGiSrpQvYEF26dIl9+/Zt6TIkSVITeffdd+fFGLu2dB2bsVDLWK1bBIcQLiZZLkf79u332H777ZuyLkmS1II25jXYJhUs9e3bl7Fjx7Z0GZIkqYmEEL5s6Ro2c0VA72rXewEzajswxjgcGA4wZMiQ6GswSZI2XxvzGsylcJIkSW3HCODs9O5wewGLY4wzW7ooSZK06dqkZixJkiSpbiGEB4GDgC4hhCLgV0A2QIzxdmAkcAwwBVgOnNcylUqSpM2FwZIkSdJmIsZ42npuj8BlzVSOJElqAwyWJElqRcrKyigqKqKkpKSlS2lSubm59OrVi+zs7JYuRZIkSRvBYEmSpFakqKiIgoIC+vbtSwi1beC16YsxMn/+fIqKiujXr19LlyNJkqSNYPNuSZJakZKSEjp37rzZhkoAIQQ6d+682c/KkiRJagsMliRJamU251CpSlv4GiVJktoCgyVJktSk+vbty7x581q6DEmSJDUBgyVJkrTBysvLW7oESZIktQI275YkSWu57rrruP/+++nduzddunRhjz324Omnn2afffbhzTff5IQTTmDAgAFcf/31lJaW0rlzZ+6//366d+/O/PnzOe2005g7dy5Dhw4l2eFekiRJmyODJUmSWqlfPzWRj2YUN+pjDt6qkF8dv8M6jxk7diyPPfYY7733HuXl5ey+++7sscceACxatIjXXnsNgIULFzJ69GhCCNxxxx38/ve/5w9/+AO//vWv2W+//fjlL3/JM888w/Dhwxv1a5AkSVLrYbAEsOBzmPsxDDgKbCYqSWrj3njjDU488UTy8vIAOP7441fddsopp6z6d1FREaeccgozZ86ktLSUfv36ATBq1Cgef/xxAI499lg6derUjNVLkiSpORksAUz8D7z0a7hmNmTntnQ1kiQBrHdmUVNZ19K19u3br/r3FVdcwQ9+8ANOOOEEXn31Va699tpVt7nrmyRJUttg826AVEFyubJxlxtIkrQp2m+//XjqqacoKSlh6dKlPPPMM7Uet3jxYnr27AnAvffeu2r8gAMO4P777wfg2WefZeHChU1ftCRJklqEwRJAqjC5XLmkZeuQJKkV2HPPPTnhhBPYZZdd+MY3vsGQIUPo0KHDWsdde+21nHzyyey///506dJl1fivfvUrRo0axe67784LL7xAnz59mrN8SZIkNaOwKe3UMmTIkDh27NjGf+DJz8KDp8LFr8JWuzX+40uSVE+TJk1i0KBBLV0GS5cuJT8/n+XLl3PAAQcwfPhwdt9990b9HLV9rSGEd2OMQxr1E2mjNdlrMEmS1CpszGsweyxBtaVwzliSJAng4osv5qOPPqKkpIRzzjmn0UMlSZIkbR4MlsBgSZKkGh544IGWLkGSJEmbAHsswepgqcTm3ZIkSZIkSfXVYsFSCGFQCOH2EMKjIYRLW6oOwObdkiRJkiRJDdCowVII4a4QwpwQwoQa40eFECaHEKaEEK4GiDFOijFeAnwLaNkmnauWwjljSZIkSZIkqb4ae8bSPcBR1QdCCJnArcDRwGDgtBDC4PRtJwBvAC81ch0bJisFmSlnLEmSJEmSJG2ARg2WYoyjgAU1hocCU2KMU2OMpcBDwInp40fEGPcBzmjMOhokVWCwJEkSkJ+f39IlSJIkaRPRHLvC9QS+qna9CBgWQjgI+AaQAkbWdecQwsXAxQB9+vRpsiKTYMmlcJIkSZIkSfXVHM27Qy1jMcb4aozxyhjjt2OMt9Z15xjj8BjjkBjjkK5duzZdlc5YkiRpDTFGrrrqKnbccUd22mknHn74YQBmzpzJAQccwK677sqOO+7I66+/TkVFBeeee+6qY//0pz+1cPWSJElqDs0xY6kI6F3tei9gRjN83g2T28FgSZLUujx7Ncz6sHEfs8dOcPSN9Tr08ccfZ/z48bz//vvMmzePPffckwMOOIAHHniAI488kmuuuYaKigqWL1/O+PHjmT59OhMmJPt3LFq0qHHrliRJUqvUHDOWxgD9Qwj9Qgg5wKnAiGb4vBvGpXCSJK3hjTfe4LTTTiMzM5Pu3btz4IEHMmbMGPbcc0/uvvturr32Wj788EMKCgrYZpttmDp1KldccQXPPfcchYWFLV2+JEmSmkGjzlgKITwIHAR0CSEUAb+KMd4ZQrgceB7IBO6KMU5szM/bKFwKJ0lqbeo5s6ipxBhrHT/ggAMYNWoUzzzzDGeddRZXXXUVZ599Nu+//z7PP/88t956K4888gh33XVXM1csSZKk5taowVKM8bQ6xkeyjgbdrUKqAEqcsSRJUpUDDjiAv//975xzzjksWLCAUaNGcdNNN/Hll1/Ss2dPLrroIpYtW8a4ceM45phjyMnJ4Zvf/Cbbbrst5557bkuXL0mSpGbQHD2WNg1VM5ZihFBbv3FJktqWr3/96/zvf/9jl112IYTA73//e3r06MG9997LTTfdRHZ2Nvn5+dx3331Mnz6d8847j8rKSgBuuOGGFq5ekiRJzcFgqUqqECrLoHwlZOe2dDWSJLWYpUuXAhBC4KabbuKmm25a4/ZzzjmHc845Z637jRs3rlnqkyRJUuvRHM27Nw2pguTSPkuSJEmSJEn1YrBUJZXevcad4SRJkiRJkurFYKnKqhlLBkuSJEmSJEn1YbBUJbdqxpJL4SRJLSvG2NIlNLm28DVKkiS1BQZLVeyxJElqBXJzc5k/f/5mHbzEGJk/fz65uW6WIUmStKlzV7gqBkuSpFagV69eFBUVMXfu3JYupUnl5ubSq1evli5DkiRJG8lgqUpV8+4SeyxJklpOdnY2/fr1a+kyJEmSpHpxKVwVm3dLkiRJkiRtEIOlKlkpyEy5FE6SJEmSJKmeDJaqSxUYLEmSJEmSJNWTwVJ1BkuSJEmSJEn1ZrBUXarAHkuSJEmSJEn1ZLBUXarQGUuSJEmSJEn1ZLBUXW6hM5YkSZIkSZLqyWCpOnssSZIkSZIk1ZvBUnUGS5IkSZIkSfVmsFRdqgBKiiHGlq5EkiRJkiSp1TNYqi5VAJVlUL6ypSuRJEmSJElq9QyWqksVJpcuh5MkSZIkSVovg6XqVgVL7gwnSZIkSZK0PgZL1aUKkktnLEmSJEmSJK2XwVJ1q4IlZyxJkiRJkiStj8FSdc5YkiRJkiRJqjeDpepybd4tSZIkSZJUXwZL1bkrnCRJkiRJUr0ZLFVnjyVJkiRJkqR6M1iqLisFmTlQYrAkSZIkSZK0PgZLNaUKXQonSZIkSZJUDwZLNaUKDJYkSdImK4RwVAhhcghhSgjh6lpu7xBCeCqE8H4IYWII4byWqFOSJG0eDJZqMliSJEmbqBBCJnArcDQwGDgthDC4xmGXAR/FGHcBDgL+EELIadZCJUnSZsNgqaZUoc27JUnSpmooMCXGODXGWAo8BJxY45gIFIQQApAPLADKm7dMSZK0uTBYqilVYLAkSZI2VT2Br6pdL0qPVfdXYBAwA/gQ+G6MsbJ5ypMkSZubFg2WQghfCyH8I4TwZAjhiJasZZVcm3dLkqRNVqhlLNa4fiQwHtgK2BX4awihcK0HCuHiEMLYEMLYuXPnNnadkiRpM9HgYCmEcFcIYU4IYUKN8XU2jKwuxvhEjPEi4FzglIbW0qjssSRJkjZdRUDvatd7kcxMqu484PGYmAJ8Dmxf84FijMNjjENijEO6du3aZAVLkqRN28bMWLoHOKr6QF0NI0MIO4UQnq7x0a3aXX+evl/LM1iSJEmbrjFA/xBCv3RD7lOBETWOmQYcChBC6A4MBKY2a5WSJGmzkdXQO8YYR4UQ+tYYXtUwEiCE8BBwYozxBuC4mo+Rbhp5I/BsjHFcQ2tpVKkCqCiFshLIzm3paiRJkuotxlgeQrgceB7IBO6KMU4MIVySvv124DrgnhDChyRL534SY5zXYkVLkqRNWoODpTrU1jBy2DqOvwI4DOgQQtgu/WJnDSGEi4GLAfr06dOIpdYhlW4xsHKJwZIkSdrkxBhHAiNrjN1e7d8zgNbR21KSJG3yGjtYqk/DyNU3xHgLcMu6HjDGOBwYDjBkyJA6H6vRrAqWiiHffgKSJEmSJEl1aexd4erTMLJ1SxUkl/ZZkiRJkiRJWqfGDpbq0zCydTNYkiRJkiRJqpcGB0shhAeB/wEDQwhFIYQLYozlQFXDyEnAIzHGiY1TajNZFSwVt2wdkiRJkiRJrdzG7Ap3Wh3jazWM3KQ4Y0mSJEmSJKleGnsp3KYvt0NyabAkSZIkSZK0TgZLNbkUTpIkSZIkqV4MlmrKSkFmjjOWJEmSJEmS1sNgqTapAihxxpIkSZIkSdK6GCzVJlXgjCVJkiRJkqT1MFiqTarQYEmSJEmSJGk9DJZqY7AkSZIkSZK0XgZLtUkVuCucJEmSJEnSehgs1cZgSZIkSZIkab0MlmqT61I4SZIkSZKk9TFYqo27wkmSJEmSJK2XwRJQXlHJouWlqwdSBVBRCuUrW64oSZIkSZKkVs5gCfjbq5+x62/+S2l5ZTKQKkwuS+yzJEmSJEmSVBeDJaB9KguAZSvLk4FUQXJpA29JkiRJkqQ6GSwB+blJsLR0VbCUnrFknyVJkiRJkqQ6GSwB+amawVLVjCWDJUmSJEmSpLoYLLE6WFp7KZzBkiRJkiRJUl0MlljdY2mJPZYkSZIkSZLqzWCJ2mYs2WNJkiRJkiRpfQyWWN28e1WwlFsVLDljSZIkSZIkqS4GS0B+TnopXEk6WMpKQWaOM5YkSZIkSZLWwWAJaJ/KBGDZyorVg6kCgyVJkiRJkqR1MFgCsjIzyM3OYFlp+erBVAGUuBROkiRJkiSpLgZLafmprNVL4SA9Y8lgSZIkSZIkqS4GS2ntU1mrm3dDsjPcyqUtV5AkSZIkSVIrZ7CUlr9WsFQApfZYkiRJkiRJqovBUlr7VBZLagZLNu+WJEmSJEmqk8FSWq0zlgyWJEmSJEmS6mSwlGawJEmSJEmStGEMltLap7JYWj1YyimA8hIoL225oiRJkiRJkloxg6W0gtwawVKqILksdWc4SZIkSZKk2hgspbXPyaKkrJLyispkoCpYcjmcJEmSJElSrQyW0tqnMgFYtrIiGTBYkiRJkiRJWieDpbSC3CwAlpaml8MZLEmSJEmSJK1TVkt+8hDC/sAZ6ToGxxj3aala2qeSU7FqZ7hUYXJpsCRJkiRJklSrBs9YCiHcFUKYE0KYUGP8qBDC5BDClBDC1et6jBjj6zHGS4CngXsbWktjqAqWlpRUBUv5yeXK4haqSJIkSZIkqXXbmBlL9wB/Be6rGgghZAK3AocDRcCYEMIIIBO4ocb9z48xzkn/+3Tgwo2oZaMVrDVjyaVwkiRJkiRJ69LgYCnGOCqE0LfG8FBgSoxxKkAI4SHgxBjjDcBxtT1OCKEPsDjG2KJTg9ZeCpcOlkqXtlBFkiRJkiRJrVtjN+/uCXxV7XpRemxdLgDuruvGEMLFIYSxIYSxc+fObYQSa5dftRSuKljKbg8EZyxJkiRJkiTVobGDpVDLWFzXHWKMv4oxvrWO24fHGIfEGId07dp1owusS37NGUsZGcmsJYMlSZIkSZKkWjV2sFQE9K52vRcwo5E/R5OoWgq3tKp5N0BOvs27JUmSJEmS6tDYwdIYoH8IoV8IIQc4FRjRyJ+jSeRkZZCTlcHS0mrBkjOWJEmSJEmS6tTgYCmE8CDwP2BgCKEohHBBjLEcuBx4HpgEPBJjnNg4pTa9/FTW6qVwYLAkSZIkSZK0DhuzK9xpdYyPBEY2uKIW1D6VueZSuFQBrHRXOEmSJEmSpNo09lK4TVp+KpulKytWDzhjSZIkSZIkqU4GS9XkpzJrLIUrNFiSJEmSJEmqg8FSNe1TWSxdI1jKN1iSJEmSJEmqg8FSNbU37y6GGFuuKEmSJEmSpFbKYKma/LVmLBUAEUqXtVhNkiRJkiRJrZXBUjVrL4UrSC5L3RlOkiRJkiSpJoOlavJTWSwvraCyMr30LVWYXNpnSZIkSZIkaS0GS9Xkp7IAWFaanrVUNWNpZXELVSRJkiRJktR6GSxV0z4dLK1aDpeTn1w6Y0mSJG0iQghHhRAmhxCmhBCuruOYg0II40MIE0MIrzV3jZIkafOR1dIFtCb5uekZSytrzlgyWJIkSa1fCCETuBU4HCgCxoQQRsQYP6p2TEfgNuCoGOO0EEK3FilWkiRtFpyxVE1+KhOApSsrkgGDJUmStGkZCkyJMU6NMZYCDwEn1jjmdODxGOM0gBjjnGauUZIkbUYMlqrJT2UDsLSkasZSVfNud4WTJEmbhJ7AV9WuF6XHqhsAdAohvBpCeDeEcHZtDxRCuDiEMDaEMHbu3LlNVK4kSdrUGSxV037VjKWqYKmqx5LNuyVJ0iYh1DIWa1zPAvYAjgWOBH4RQhiw1p1iHB5jHBJjHNK1a9fGr1SSJG0W7LFUzapd4aqCpawUZOa4FE6SJG0qioDe1a73AmbUcsy8GOMyYFkIYRSwC/BJ85QoSZI2J85Yqia/5q5wkPRZMliSJEmbhjFA/xBCvxBCDnAqMKLGMU8C+4cQskII7YBhwKRmrlOSJG0mnLFUTXuDJUmStAmLMZaHEC4HngcygbtijBNDCJekb789xjgphPAc8AFQCdwRY5zQclVLkqRNmcFSNamsDLIygsGSJEnaZMUYRwIja4zdXuP6TcBNzVmXJEnaPLkUrpoQAvm5Wat7LEGyM1ypu8JJkiRJkiTVZLBUQ/ucrFpmLLkrnCRJkiRJUk0GSzXkp7JYWlItWMrJdymcJEmSJElSLQyWasjPzWJZqT2WJEmSJEmS1sdgqYb2qSyWrqxYPWCwJEmSJEmSVCuDpRryU5ksLSlbPZAqhPISKC9tuaIkSZIkSZJaIYOlGvJTWSyrOWMJ3BlOkiRJkiSpBoOlGtqnslhWc1c4cDmcJEmSJElSDQZLNRSkslhaWk6MMRlI5SeXBkuSJEmSJElrMFiqoX0qixhheWl6OZwzliRJkiRJkmplsFRD+1QWwOrlcKnC5NJgSZIkSZIkaQ0GSzUU5CbB0pJVwVLVjKXiFqpIkiRJkiSpdTJYqqF9Ts0ZSy6FkyRJkiRJqo3BUg1VS+GWVgVLOenm3aVLW6giSZIkSZKk1slgqYaqpXBLS2oES85YkiRJkiRJWoPBUg2rmneXpoOljAzIKTBYkiRJkiRJqsFgqYb2qUwAlq6sWD2YKrB5tyRJkiRJUg3NFiyFELYJIdwZQni02tjXQgj/CCE8GUI4orlqWZeCVDZQbSkcpIMlZyxJkiRJkiRVV69gKYRwVwhhTghhQo3xo0IIk0MIU0IIV6/rMWKMU2OMF9QYeyLGeBFwLnDKBtbeJHKzM8gI1XaFA4MlSZIkSZKkWmTV87h7gL8C91UNhBAygVuBw4EiYEwIYQSQCdxQ4/7nxxjnrOPxf55+rBYXQiA/lbV6VziAVD6sdFc4SZIkSZKk6uoVLMUYR4UQ+tYYHgpMiTFOBQghPAScGGO8ATiuPo8bQgjAjcCzMcZx9a66ia0dLBXAktktV5AkSZIkSVIrtDE9lnoCX1W7XpQeq1UIoXMI4XZgtxDCT9PDVwCHASeFEC6p434XhxDGhhDGzp07dyPKrb/2qawaS+EKXQonSZIkSZJUQ32XwtUm1DIW6zo4xjgfuKTG2C3ALev6JDHG4cBwgCFDhtT5+I0pP7eWGUsGS5IkSZIkSWvYmBlLRUDvatd7ATM2rpzWodalcCuLITZLriVJkiRJkrRJ2JhgaQzQP4TQL4SQA5wKjGicslpW+5yaS+EKgAily1qsJkmSJEmSpNamXsFSCOFB4H/AwBBCUQjhghhjOXA58DwwCXgkxjix6UptPvm5WSwtqRYs5eQnl6XuDCdJkiRJklSlvrvCnVbH+EhgZKNW1AqsvRSuMLlcuQQKerRMUZIkSZIkSa3MxiyF22y1T2WyrLSCWNVTKVWQXK4sbrmiJEmSJEmSWhmDpVrkp7KpqIyUlFUmA6uCJXeGkyRJkiRJqmKwVIv8VCbA6uVwBkuSJEmSJElrMViqRftU0npq1c5wqXTzboMlSZIkSZKkVQyWapGfDpZWz1iqat7trnCSJEmSJElVDJZqsXawZPNuSZIkSZKkmgyWapGfW2MpXFYKMnNcCidJkiRJklSNwVIt2tecsQTJrCWDJUmSJEmSpFUMlmqx1lI4MFiSJEmSJEmqwWCpFvk1d4UDyDFYkiRJkiRJqs5gqRbtcjIJAZaW1JixVOqucJIkSZIkSVUMlmoRQqB9ThZLV1asHkwVuCucJEmSJElSNQZLdchPZbF0ZdnqAXssSZIkSZIkrcFgqQ7tU5ksW2vGksGSJEmSJElSFYOlOhTkZrPEXeEkSZIkSZLqZLBUh8K8bIpX1FgKV14CFWV130mSJEmSJKkNMViqQ2Fu1trBEjhrSZIkSZIkKc1gqQ6FedkUlxgsSZIkSZIk1cVgqQ6FudkUrygnxpgMGCxJkiRJkiStwWCpDoV5WZRWVLKyvDIZMFiSJEmSJElag8FSHQpzswFW91nKMViSJEmSJEmqzmCpDoV56WCpqs/SqhlLxS1UkSRJkiRJUutisFSHwtwsABavKE8GcguTS2csSZIkSZIkAQZLdXLGkiRJkiRJ0roZLNVh7R5L+RAyoMRgSZIkSZIkCQyW6tRh1Yyl9FK4EJJZS85YkiRJkiRJAgyW6lSQ7rG0asYSQKrQHkuSJEmSJElpBkt1yM3OJJWVsbrHEiTBkkvhJEmSJEmSAIOldSrMy6a4alc4SHaGcymcJEmSJEkSYLC0ToW5WTVmLNljSZIktW4hhKNCCJNDCFNCCFev47g9QwgVIYSTmrM+SZK0eTFYWodkxpJL4SRJ0qYhhJAJ3AocDQwGTgshDK7juN8BzzdvhZIkaXNjsLQOhbnZq3eFA5fCSZKk1m4oMCXGODXGWAo8BJxYy3FXAI8Bc5qzOEmStPkxWFqHwrxslqyouRTOXeEkSVKr1RP4qtr1ovTYKiGEnsDXgdvX9UAhhItDCGNDCGPnzp3b6IVKkqTNg8HSOqzdY6kQKkqhrKTlipIkSapbqGUs1rj+Z+AnMcaKdT1QjHF4jHFIjHFI165dG6s+SZK0mclqrk8UQtgGuAboEGM8KT22P3BGuo7BMcZ9mque+qjaFS7GSAgBcjskN6wshuzcli1OkiRpbUVA72rXewEzahwzBHgohADQBTgmhFAeY3yiWSqUJEmblXrNWAoh3BVCmBNCmFBjvF67jgCk1/pfUGPs9RjjJcDTwL0bWnxTK8zNprSikpXllclAqiC5dDmcJElqncYA/UMI/UIIOcCpwIjqB8QY+8UY+8YY+wKPAt8xVJIkSQ1V3xlL9wB/Be6rGqi268jhJP87NiaEMALIBG6ocf/zY4zrag55OnBhPWtpNoV5yekpXlFGbnZmshQOoGRxC1YlSZJUuxhjeQjhcpLd3jKBu2KME0MIl6RvX2dfJUmSpA1Vr2ApxjgqhNC3xvCqXUcAQggPASfGGG8AjqtvASGEPsDiGGOr226tMDcbgOKSMroV5ia7woE7w0mSpFYrxjgSGFljrNZAKcZ4bnPUJEmSNl8b07x7vbuOVBdC6BxCuB3YLYTw02o3XQDcvY77tdiOJIV5SbC0uGpnuKoZSy6FkyRJkiRJ2qjm3fXZdWT1DTHOBy6pZfxX6/okMcbhwHCAIUOG1Pn4TaEwt2opXHkyUNVjqcQZS5IkSZIkSRszY6k+u45s0qpmLBWXpGcsVd8VTpIkSZIkqY3bmGBpvbuObOpW9VhatRTOXeEkSZIkSZKq1CtYCiE8CPwPGBhCKAohXBBjLAeqdh2ZBDwSY5zYdKU2v4KqpXAl6aVwmdmQleeucJIkSZIkSdR/V7jT6hhfa9eRzUludiaprIzVM5Yg2RnOpXCSJEmSJEkbtRSuTSjMy17dYwmSneFcCidJkiRJkmSwtD4d8rJX7woHSZ8ld4WTJEmSJEkyWFqfwtysNWcsuRROkiRJkiQJMFhar8K87DV7LLkUTpIkSZIkCTBYWq/C3OzVu8JBEiy5FE6SJEmSJMlgaX0K87LcFU6SJEmSJKkWBkvrkcxYKiPGmAykCqF0KVRWtGxhkiRJkiRJLcxgaT0K87Ipq4iUlFUmA6mC5NI+S5IkSZIkqY0zWFqPwtxsgNU7w+UWJpcuh5MkSZIkSW2cwdJ6FOZlAazus5SqCpacsSRJkiRJkto2g6X1WGvGUtVSOHeGkyRJkiRJbZzB0noU5qWDpRXlyUBuh+TSpXCSJEmSJKmNM1haj8Lc9FK4khpL4ZyxJEmSJEmS2jiDpfVYPWPJ5t2SJEmSJEnVGSytR8GqGUvppXBVPZYMliRJkiRJUhtnsLQeqaxMcrMzWFw1Yym7HYRMl8JJkiRJkqQ2z2CpHgpzs1cvhQshWQ63cknLFiVJkiRJktTCDJbqoTAve3XzbkiWw7kUTpIkSZIktXEGS/VQmJtF8Yry1QOpDi6FkyRJkiRJbZ7BUj2sNWPJpXCSJEmSJEkGS/WxRo8lSC+FW9xyBUmSJEmSJLUCBkv1UJiXRXFJ9aVwhS6FkyRJkiRJbZ7BUj10yEtmLMUYkwGXwkmSJEmSJBks1UdhbjbllZEVZRXJQNWucFVBkyRJkiRJUhtksFQPhXnZAKt3hksVQmU5lK1owaokSZIkSZJalsFSPRTmpoOlqp3hcguTS5fDSZIkSZKkNsxgqR4K87IAVu8Ml6oKlmzgLUmSJEmS2i6DpXpYa8ZSVbDkznCSJEmSJKkNM1iqh7V6LOU6Y0mSJEmSJMlgqR4Kc9NL4VbNWCpILg2WJEmSJElSG2awVA8FVUvhavZYcimcJEmSJElqwwyW6iEnK4O87EyKS2ouhXNXOEmSJEmS1HYZLNVTYV7W6hlLOS6FkyRJkiRJMliqp8Lc7NU9ljKzILu9S+EkSZIkSVKbZrBUT4V52at3hYNkOZwzliRJkiRJUhvWbMFSCOFrIYR/hBCeDCEcUddYa1WYm7V6xhIkDbwNliRJkiRJUhtWr2AphHBXCGFOCGFCjfGjQgiTQwhTQghXr+sxYoxPxBgvAs4FTqlrrLVKZixVD5YKXAonSZIkSZLatKx6HncP8FfgvqqBEEImcCtwOFAEjAkhjAAygRtq3P/8GOOc9L9/nr5fdbWNtSqFudksrh4s5RYaLEmSJEmSpDatXsFSjHFUCKFvjeGhwJQY41SAEMJDwIkxxhuA42o+RgghADcCz8YYx9U1Vsv9LgYuBujTp099ym0ShXlZFJeUE2MkhJAshVtc1GL1SJIkSZIktbSN6bHUE/iq2vWi9FhdrgAOA04KIVyyjrE1xBiHxxiHxBiHdO3adSPK3TiFudlUVEaWl1YkAy6FkyRJkiRJbVx9l8LVJtQyFus6OMZ4C3DL+sZaq8K8bACKS8pon8qC3A4275YkSZIkSW3axsxYKgJ6V7veC5ixceW0XoW56WBpRXkykCqEsuVQUd6CVUmSJEmSJLWcjQmWxgD9Qwj9Qgg5wKnAiMYpq/XpUG3GEpAshQNnLUmSJEmSpDarXsFSCOFB4H/AwBBCUQjhghhjOXA58DwwCXgkxjix6UptWYV5yarB4qqd4XILk0uDJUmSJEmS1EbVd1e40+oYHwmMbNSKWqmOeTkAzF9WmgykqoKlJS1UkSRJkiRJUsvamKVwbUqPDrmEADMWrUgGqpbCuTOcJEmSJElqowyW6iknK4NuBSmmL0wHSy6FkyRJkiRJbZzB0gbo2TGP6atmLHVILl0KJ0mSJEmS2iiDpQ3Qs1O7asFS1VK4xS1XkCRJkiRJUgsyWNoAPTvmMXNRCZWV0aVwkiRJkiSpzTNY2gA9O+VRWlHJ3KUrISsXMrJdCidJklqVEMJRIYTJIYQpIYSra7n9jBDCB+mPt0IIu7REnZIkafNgsLQBenXMA6Bo4QoIIVkO565wkiSplQghZAK3AkcDg4HTQgiDaxz2OXBgjHFn4DpgePNWKUmSNicGSxugZ6ckWFrVZym30KVwkiSpNRkKTIkxTo0xlgIPASdWPyDG+FaMcWH66migVzPXKEmSNiMGSxtgq/SMpekLqxp4F7oUTpIktSY9ga+qXS9Kj9XlAuDZJq1IkiRt1rJauoBNSX4qiw552UxftDwZyO3gUjhJktSahFrGYq0HhnAwSbC0Xx23XwxcDNCnT5/Gqk+SJG1mnLG0gXp2zKs2Y6nApXCSJKk1KQJ6V7veC5hR86AQws7AHcCJMcb5tT1QjHF4jHFIjHFI165dm6RYSZK06TNY2kA9O+UxY1FJciVljyVJktSqjAH6hxD6hRBygFOBEdUPCCH0AR4HzooxftICNUqSpM2IS+E2UM+Oefzvs/nEGAm5hS6FkyRJrUaMsTyEcDnwPJAJ3BVjnBhCuCR9++3AL4HOwG0hBIDyGOOQlqpZkiRt2gyWNlCvTnksXVlO8YpyOlQthaushAwnf0mSpJYXYxwJjKwxdnu1f18IXNjcdUmSpM2TacgG6pneGa5o0XIo7AmxEpas1bpAkiRJkiRps2ewtIF6dkqCpekLV0CXAcngPNsTSJIkSZKktsdgaQNVzViavmgFdOmfDM6b0oIVSZIkSZIktQyDpQ20RfsccrMzkhlL+d2TneGcsSRJkiRJktogg6UNFEKgZ8e8ZMZSCNB5O4MlSZIkSZLUJhksNUDPTu2SYAmSPkvzXQonSZIkSZLaHoOlBujZMTdZCgdJn6Xi6bByacsWJUmSJEmS1MwMlhqgZ8c85i8rZUVpxeoG3s5akiRJkiRJbYzBUgP07FR9Z7gByeC8T1uwIkmSJEmSpOZnsNQAPTu2A9LB0hbbQMiwgbckSZIkSWpzDJYaYNWMpYUrICsFHbeG+c5YkiRJkiRJbYvBUgN0L0iRmRGYUX1nOJfCSZIkSZKkNsZgqQGyMjPoUZibLIWDpIH3/ClQWdmyhUmSJEmSJDUjg6UG6tkpL1kKB0mwVF4Ci79q2aIkSZIkSZKakcFSA/XqmLd6xlLn/smly+EkSZIkSVIbYrDUQD075TGruITyisqkxxLYwFuSJEmSJLUpBksN1LNjHhWVkVnFJdC+C+R2hHmftHRZkiRJkiRJzcZgqYF6dsoDSPoshZD0WXIpnCRJkiRJakMMlhqoZ8d0sLRqZ7gBBkuSJEmSJKlNMVhqoK06VpuxBNB5O1g6C0qKW7AqSZIkSZKk5tNswVII4WshhH+EEJ4MIRyRHts/hHB7COGOEMJbzVVLY8jNzqRLfs6aM5aAvz3+HI+9W9SClUlqCpNmFrN4RVlLl6E2prIysry0vKXLkCRJkupUr2AphHBXCGFOCGFCjfGjQgiTQwhTQghXr+sxYoxPxBgvAs4FTkmPvR5jvAR4Gri3QV9BC+rZMY/pi1ZQURl5cno+AJ9MGMe1T01kSUnzvQGdt3QlL0ycxQ3PTuKkv73Fvje+zMsfz262zy9t7l7/dC7H/d8bnPS3t1iwrLSly1EbUVEZuei+sexz48tMnLG4pcuRJEmSalXfGUv3AEdVHwghZAK3AkcDg4HTQgiDQwg7hRCervHRrdpdf56+X3WnAw826CtoQT075fHxrCV8429v8aMXF1NBBpfsWMmSknL+NXpak3/+GCMX3zeWIde/yMX/fJe73vicihjJzc7gsvvf4/2vFjV5DRsrxkhFZaSkrIJlK8upqIyN8rgfFC1iRWlFozyW2rbP5i7lO/ePo3enPKYtWM5Zd77d5DOXyisqeeidaa0uTKiojI32MyqYU1yyzt9Tvx05iZc+nkNlZeTMO95m8qwlzVidJEmSVD9Z9TkoxjgqhNC3xvBQYEqMcSpACOEh4MQY4w3AcTUfI4QQgBuBZ2OM46qN9wEWxxhrbU4UQrgYuBigT58+9Sm32fTsmMfIJbOIMXLTKUPIeGMbBmbO5IABXbnzjamct29fcrMzm+zzj566gBc+ms0Zw/rw9d16smPPDuRmZzJnSQnfuO0tLrh3DI9fui99Ordrshoa6sOixZz2j9EsXbnmEo/uhSmuOXYwx++8Jcm3zIZ74r3pfO/h8Zy461b85dTdGqNcNZFFy0u58qHx7Ll1J644tH9Ll7OWRctLufDeseRkZvDPC4YxZc5SLv7nWM6/Zwz3nT+U9ql6/QrdIDMXr+C7D47nnS8WkBHgzL225oeHD6RDu+xG/1wbYsaiFZx/zxhWlldy2xm7M2jLwlqPmzJnCeOmLeLkPXo1+Ge4JcUYWbi8jM/nLePL+csoXlHGN/boRWFu453/FaUV3PrKFP4+6jN6dWrH387cne17rHk+H3xnGne+8Tnn7duXc/fpy7f+/j/OuGM0D128N9t1y2+0WiRJkqSNtTHvinoCX1W7XgQMW8fxVwCHAR1CCNvFGG9Pj18A3F3XnWKMw4HhAEOGDGlV/1V+xrCt6dguhzOHbZ286ZvUH+ZP4bKjtuWU4aN5eMxXnLNP3yb7/He9+Tmd2mXzi+MGrxFgdSvI5Z7zhvLNv73FuXe/w2OX7kOn9jlNVkdDPPPhTErKKrjikO3IysggKzOQmRF4+oMZXPngezz49jR+c+IO9O9esEGP+7/P5nPVo+9TkMriyfEzuGj/bdixZ4cm+irqL8bI+0WLaZ+TucFf0+ZqwbJSzrzjbT6aWcyoT+ayS++OHDCga7PXMeaLBTw/YRb79e/CAf27kpGRhCFlFZV85/5xTF+4gvsvGkbvLdrRe4t23HLqblz2wDguum8sd527Z6OGxy9/PJsfPvI+K8srufEbOzFpZjH/HP0lz3wwk6uP3p5v7t5rVX3NadLMYs69+x2Wr6wgLyeTr9/2Jtd/bSdO2qPXqmPKKiq5/dXP+L+Xp1BaUcmWHXLZv3/zP58bKsbI5NlLeOXjubwyeQ6TZhazpGTNwPuNKfP5x9l7NEpQ9t+PZnPtiIlMX7SCY3feknc+X8DXb32LG76xE1/brScAb302j188MYEDB3TlmmMGkZWZwQMX7cUpfx/N6f8YzcPf3pt+XdpvdC2SJElSYwgx1i+rSc9YejrGuGP6+snAkTHGC9PXzwKGxhivaKJaGTJkSBw7dmxTPfzGe+EX8PbtxJ/N5OTh7zBj0QpevepgcrLWXHE4de5S3pgyj2H9OjOge/5ab1ZijHw2dykTZxRz5A49an3j+uX8ZRx086tcdtB2/OjIgbWWM+aLBZxxx9vs1LMD9184rElnT22o4/7vddrnZPHwt/deY7yiMvLAO9O46bmPWV5awQX79eO7h/WnXc76M9Apc5bwjdveomtBinvOG8oJf32DwVsV8q8LhjXqzIklJWV8MnsJJWWVrCitYEVZBSvLK+nZMY9BWxbQsd3qEG/BslIeH1fEw2O+4tM5SwkBTt6jF1cduT1dC1KNVlNTWl5azg0jP+bkIb3YuVfHRnnMeUtXcuYdb/P5vGXcctpu3Pz8ZBatKOP57x3AFs0Ugr7z+QL+8tInvDll/qqx3lvkcdrQPpy8R2/+8tIn/Gv0NG4+eZc1AhSAx8cV8YNH3ueggV354eEDGbxVIZkbEfiUlldy8wuTGT5qKoO2LOTW03djm67JrJSJMxbziycmMG7aInbv05ErDu3PQQO6Nvh7etnKcn7/3MdMmbuUXXp1ZLc+ndi1d8c6vx/fnDKPb//zXfJTWdxz/p50bp/iygff439T53Pa0D786vjBfDp7KVc9+j4fz1rCcemwZPstC7nv/KENPicN9ensJdz8wmRmF6+kV6c8enVqR69OeWzZIZeKysiy0nKWraxgeWk5X8xfzqsfz2HG4hIAdtiqkN37dKJvl/b069KOrTu355WP53D9M5O45phBXHTANrV+zpKyCrIzM9b5PTBj0Qp++eQEXpw0hwHd87nuxB0Ztk1n5hSXcPkD7/HOFws4Z++tOXOvrTnp9v/RrSDFY9/ZZ42ZUp/MXsKpw0eTysrgt1/fie265bNVx7yN+t5rjUII78YYh7R0HVpTq38NJkmSNsrGvAbbmGBpb+DaGOOR6es/BUgvhWsSrf5Fzbh/wojL4cr3eGVOPufdM4Y/fm07vlEwCbbeF/K78kHRIs66851VPVp6dszj0EHdOHj7bixfWcHrn85l1CdzV73RuXC/fvz8uMFrfapfPzWRf43+kjd+cgjdC3PrLGnkhzO57IFxDOxeQGFeNsurvak6Zc8+fP+w/vV+gxpjZEVZBXnZmRsV1MxfupI9rn+Rq44cyGUHb1fnMb9/bjIPj/2KoX234L4Lhq4zGJu7ZCVfv+1NSsoq+M939qX3Fu24643P+c3TH3Hv+UM5sJFmwkyetYRz736HmennpzZbdshl0JaF5GRm8PLHcyitqGS3Ph05ZUhvps5bxt1vfk4qK5MrD92Oc/fptyp4XFJSxpfzl1NcUsbA7gV0zm8dwdN/3ivi+w+/T7ucTG4/c4+NnlU0p7iE0+94m6KFy7nznD3Zd7sufDSjmK/d+iYHDOha68yQ8opKVpRVUNCA5UgxRopLylm0vJSFy8uYtbiEf47+gjenzKdLfopLDtyGk4f05rVP5vLA218yeuoCMjMCFZWRbx+wDT89ZlCtj3v/21/yiycmUBmhMDeLvbbpzD7bduaggd3ouwGzSWKMXPzPd/nvR7M5a6+tuebYQWt9r1dWRh4bV7QqMOnfLZ8L9+/Hibv23KDAeML0xVz54Ht8Pn8ZA7sXMGXOUsrTPZN6dcpjx606sP2WBWzfo5BBWxYwbtpCfvzoB2zTJZ97zt+TLTvkAcnz8Yf/fsLfXv2MrTu346sFy+lakOK6E3fkiB16cNurU/j9c5N59rv717lkrr7npjJSr+BkwbJS/vTfT3jgnWm0y8lkp54dmL5oBTMWraCsova/c+1zMtmvfxcO2b4bBw3sVuvv0hgjl/5rHC9Oms3D396bPbbutMbt73y+gO/c/y49OuTy97OG0LNj3lqP8UHRIi64dyzLVpbz/cMGcO6+fcnOXP0fDmUVlfzu2Y+5443PycwIFOZm8eRl+9W6jPmjGcWcfsdoFi1P/obkZGbQe4s8BvYo4Ldf32mNYHtTZbDUOrX612CSJGmjtFSwlAV8AhwKTAfGAKfHGCc2pJD6aPUvaqaNhruOhNP/TdzuUP508284e8W9dIkLISefGYMv4Ovv7U52u0JuOW03Js9awkuT5vDGlLmUlFUCUJCbxb7bdmH/AV1498uFPPHedB67dB9267P6zcySkjL2vuFlDh/cnT+dsut6y3p4zDTuf3saedmZtE9l0T6VxaLlpbz+6Tx+ctT2XHrQtmvdJ8bIHa9/zuPvTad4RRlLSspYurKcyghbdcjlsMHdOWJwD4Zts8Uab5Dq48nx0/nuQ+N58rJ92aV3x/Ue+72Hx3Po9t3425l71Pq5lpeWc+rw0Xw6eykPXbzXqsdcWV7BYX98jfxUNs9csd9GLyF667Nk5kZedia/PmEHOuenyMvOJDc7g6zMDKYtWM6kmcV8PLOYSTOXsHB5KcfstCWnDu29Rv+UqXOXcv0zk3j54zn02aIdndrnMG3+MhYuL2Nw+IKDMt7nnxWHk99hC3bYqgM79izkyB16bNQb9I1xyT/f5d1pC+mSn+LT2Uv4w7d24cRde666PcbIG1Pmcftrn5GZkcHXdt2KI3fosVb/ofKKSj6YvpgfPfI+s4pLuOvcPdlrm86rbr/j9alc/8wk/t/Xd+SMYVuvGn/907n8asRE5i5ZyX3nD13jZ6EuK0orGPnhTB4e8xXjpi1cFZ5UqQqUzhi2NXk5awYzU+Ys5YG3p1EZI784bnDdocaCz1n29n282eEYXpqR4q2p8/hqwQoAdu/TkW/u0Yvjdt6KDnnrDsOqvu6fHzuIC/evfUZMldLySp7+YAb/eP1zJs0spkt+Dhfst816+7lVVkbuevNzfvfcx3Run+JPp+zK3tt2pqSsggnTFzP+q0W8N20Rk2YW8/n8ZVT/s7D3Np35+9l71Npj6LVxE3n6mSdot/2h/OC4PVZ9rYuXl7H3jS9x9I5b8odv7bLOr2ldzrnrHcZNW8gB/bty8PbdOHBA1zVmVpWUVTCneCXPT5zFLS9/yvLSCs4Y1ofvHTZg1cy3ysrInCUrmbl4BdmZGcnvwJxM2qWyaJedWa/fC4tXlHHc/71ORUXkmSv3X7W0+MF3pvHLJyewVcc85i8tJTc7g7+duQd7bt0J5kyCrtvz4sdzueLB9+icn8M95+3Jdt3qXgr79AczuPvF8fzkxCEM3bZbncctXlHGpJnFfDFvGZ/PX8Znc5bx4qTZa/3sNIayikrGfrFwrdmYTclgqXVq9a/BJEnSRmnyYCmE8CBwENAFmA38KsZ4ZwjhGODPQCZwV4zx/zWkiPpq9S9qli+A3/eDnU+FuR/DzPG8V7kdFXtfSb9Zz9H5y5EspAMZB11Fh/2+DVnJi/SSsgre+XwB7XIy2bV3R7IyV89gOfJPo2ifyuLpK/cjlZW8cbzzjc+57umPeOry/dip1zr6By2bB/M+gbmTISsXdjoJMpM3fpWVke89PJ4R78/gd9/ciVP2XN0YvbS8kp8+/iGPjStij607sfUW7SjIzaIgN5u8nEzGf7WI1z9NwrCC3CwOH9Sdnx07iC71nGHzo3+/z4uTZvPuzw9f8037qJvhld8m/66asRIymNVhF347axi5O53AjacMXeON4ITpi7nmiQl8WLSIv581hMMHd1/jc414P+nZ9MeTd+IbA/Mgv2GzbZ4cP50f/ft9+nZuzz3nD117VkJ5KWRkJh/19MrkOfztlc/Iycqg7xY5nLDkEYZ8MZyMWM7SVHfu7/p9/l08mM/mLiUrI/CTo7bngv361Wu2WIyR656eROf8nDpnhdXHitIKdrvuBb41pDc/OnIgF983ltFTF/CL4wZzwX79GD11Pn984RPe+WIBW3bIJSMEpi9aQV52Jkfs0J3DB3fny/nLefvzBbz7xQKWlVaQn8ri7vP2ZM++W6zxuSorI+fc/Q5jvljA01fsT15OJtc//RHPTpjF1p3bESMsXFbKvRcMZfc6wqUPixbz0JhpjBg/gyUry+nbuR1H7tCDrgUpOrbLoVO7bDq1z2HwloUbtzR0wuPw1HdhZTFkt4ODfgp7XcpXi8t4dsJMHn23iE9mLyUnK4MjBnfnikP6M7DH2oHC+K8WcfLtb3HwwG78/ax19PApX5kEFYu+hLxOxPbdeGduFreNns9rn86jV6c8rjlmEEft2GONx4gx8kHRYv7430947ZO5HD64O7//5s6191z77GVIdWBF5x34ZF4JH88qZkVpBacN67Pqdw9lJfDV28mxn70Esz5Mxnc5Hb7+tzUe7toRE7n/7S95/ceH0CNnBYQMyK1/v7PikjJ2/fULDOhewIJlpcxZshKAwVsWUhkjs4pLVs3aAThoYNKPqKl6mH1YtJhv/u1Nzuk9hx8f3IvrJnXnvtHTOHBAV245bTfmLinhovvepWjhcv6z/Svs+NlwpnfZl+Omn0Pvnj2545whdCuoe3YpMcKrN8JrN0JmDnTuD10HQtftodsg6Lk7FPZc/btxjbtGDrzpVbbt2p67z9v45YeVlZExXyxgxPszGPnhTBYuL2Onnh14+Nt71WtZ8sYyWGqdWv1rMEmStFGaZcZSa7BJvKj5XT9YsQAKe1J56LUc/t8ulJTD/GUrObRwOn/a4nFyvnoTOvSGoRfBbmdBuy3qfLhXJs/hvLvHcOUh2/GDIwZSURk56OZX6FGYy78v2WftO8z5GJ69CmZNSOqoruv2cNSNsO3BQBIgXXjfWN76dDYPH7qcPZjE4gEnc9Gzxbzz+QK+e2h/vldzqVxJMZQsoqQ88s4Xi3j1k3mM+GghW3Tuyv0X7rXevkExRva64SWG9N2CW0/ffc0bHz0fprwEe14IxOSNVvlK+PgpWDSNhTGfyd2PYdhJP6A4fztufmEy97/9JZ3a5fCbE3fk2J23XOvzVVZGvveX+7iw+DZ24lPCec9Cn3X1mF+73uGjpnLDsx8ztN8W/OOsIWvvzlU8A27dC0qXQLvO0L4rtO8Chb1g631gmwOh4zp2NJz3KfznEpg+Fnb8Jux2Jjz3M5g7CXY+hUUH/IarRhbx349mc9ig7tx88s7rnTlQFagBPHDhMPbZrku9v+bqnpswi0v+9e6qxygpq+AHj4xn5IezGNi9gMmzl9CtIMXlh2zHKXv2Jjsjg3enJTPtnv5g5qolnwO65zOsX2eG9tuCfbbtXOcyvznFJRz55yRMnbc0CRKuOKQ/F+zXj4XLSzl1+GjmLy3l3vOHsseWKcjOgxD4bO5Sbhj5MS9Omk0qK4Njd9qSb+3Zm2H9tlg7rFm5NAk5curYLbGyAj57BZbMgH4HQqdqM0DKVsBzP4V374aeQ+CI6+GtW2DySOi+Ixz3J+g9lBgjE6YX8+i7X/HE+BlJD6WTd1nje7RqFkxlJYy8cv81v69ihA8eTuqY9SHMmwyVazaUBiAzh9LsQuaXZlJcnk1mqh09unZhxo7f5pEFA3h2wiymL1pBKiuDnx87iDP32rr28OrjZ+Ch05N/Z7eDXnsm37td+sP8z2D2RJjzUfLvWAEZWdB7L9juEFg0Dd69B84dCX33XfWQXy1YzoE3vcIV+3Tn+5+dD1vuDKf8q/ZzXovnJ87i2/98l4cv3ouh/bZg4oxiXp08h9FTF5CXk0n3whQ9CnPpXpjLdt3y15zJtnxBEqKn1hEyrViU/Oz1GlJrWLOGxUXw/kMUj76XwuXTALin/Ahm7f0rrjp6h1UB+eIVZTz396s5ZdEdfJC9MwNLP6I4uwv5Zz9AXp896n788lIYcQV88BDs8A3o2Dv5D4G5H8PCL4H03+n87tBzD9hqd+iVvszrCMBvnvqIf739JeN/eXiDw58v5y/j4TFf8Z/3pjNzcQm52RkcNqg7g7cq5KbnJ3Pk4B7cdsbuZMTy5Ptz1zPWf+4awGCpddokXoNJkqQGM1hqTcbckYQvwy6BnHb8e+xXXPXoB2zfo4B/XTiMLu1zkv/pf+PP8MXrkJUHu5wKw76d/K90LX7w8Hg+++BN/tn/NVj4JafPOZPLTj+Jo3eqEaR89Q7cf3Lyv93bHwNdBkKXAdB1AMz8AJ7/WTLjYfvj4Mj/ByGTsrH3seitu+laOReAMrIYXnE8fb72C47fo9oSuaVz4c0/J19f+dr9hSbGfoxO7cPXTvs2nfvuXOebjU9nL+HwP41aa5YUkARLM9+HK95dc7yykjj1VSY+/VcGLHyVrBC5MuOnjFyxA2fv3ZfvHz6g9uVGKxbBK78ljvkHCyrbk5fKod0WPSm74GXmLitndnEJPTrkruobU5uH3pnG1Y9/yLE7b8kfTt6l9lkuI66A8Q/CPlfAioWwbG7ysWBqcgnQqR9sc1AyAyEjKz27KQuWzILX/whZKTj2D8msMkgCtdf/kHzkdSLufAofzljCO1PnkZ+TwcHbd6f79nvDdodC3pqzd+YvXcnhfxpF7055FJeUU1ZRyfPfO2CtpWn18YOHx/Py5DmMveawVTPpKpYvZNxd36dw/ng+2/XHHHLMKbWel9LySj6cvoi+ndvXv19URRkfjbyN8jH30CEvix5dOpNqVwg57YFI6aKZzJnxJVtULqBdWEl5z6H8teOP+et7ZeRmZ3LpQdty5l5b17387MNHk+eLAAOPSt7Eb3cYZOfCktnw3j9h3L1JWFKlywDY7nDovSe8dhPMmQj7fhcO+cWqGYBMehqe/XESMm5/LPTYOQllug5kTnZPLn34I979ciGXHrQtPzpiIBkBLntgHM9PnM0jtfTtYfTf4LmrkyBhy12gx07JR6d+ULI4+b5aOjv5WLGIyrIVfDVnPkWz59OncjrdwkIurbiKsN2hHLVjDw4f3L3uMHLZPLhtLyjoAfv/EL78H0x7KwmnqwKNTn2h2w7QfXASZvTbf3VoU7ocbh2WPEeXvL76nJB8jUd/8guO440kpDtnRP2+D4BfPDGBx8YVMf6XR6y5AULp8lWBYq0+fgb+cymk8uFb/0wCmJrmTIIHT4WFX8C2h8JRNyQ/m9VVVsKnz8Pbf4eprwKRuPU+3F+yH2UzJ3Bexsjkd+k3/rE6pHznHzDyR0zsfATHTz+bn+5SwoUzryUsm5v8fO9+1tq1rFgID5+V/D04+Bo44Ko1v7bS5UmoN30cTH8XZoxLZqJW6TIQeg1hata2/P1/Mzl7rz7ssFV62exWuyXfP2k3PDuJhctKGbRlYfLRo5DcnAyenzibh96ZxlufzScjwEEDu3Hirltx2KDuq35vVC3ZvPTAfvxkxZ+TYOncZ6DvfrU/DxvBYKl12iReg0mSpAYzWGrFKiojT70/g4MGdl37jd2sCfDO3+GDR5KwZqvdkjc52x2W/C96ZjbMeI/Sl24g57PnWRraUxpSFFQWk3HEdWTufenqNyCfvACPnA2FW8FZjydvBGsqK4H//TUJKyrLoSKZTVLW90BumD2MZxb25hd5j3BcHJXc/9g/JG8i3/q/5M1V+QrY+ZSkEXmsXP2xYgFLPniGgnnJDJnyTtuSNewi2OvStUqoWsb35tWHrL2crK5gKa2yMvKrB1/l9MlX0DNzMbNOf4kB/QfUfuI/+Dc8/1NYPh+GnM+lM48h9eWr/DnzFn5WdgEPVBwKQLeCFP/9wYG1BhGLlpdy8M2vMqB7AQ9etFftvVjmfgK3DYOhF8PRv1vzthiTGQdTX4Wpr8EXbySzmmra7nA44f+gcO0ZV8yaAE9/L73kKFBBoKQ8khnLyQ1lEDKh9zAYcGTyJrfLdlz+wDienziLZ67cn8UryvjW3//HmcO25rpDOifP/U4n12vWVllFJXtc91+O2KEHN5+8S/L1TBoBI38My+ZAfo9kVs/Op8AR/6/BywyBZJbQB48ky4AWfkFFj13ILOgOpctWfxAhvwcrUp15+vNKFpRmcXp4DiKM3PoqDjn58rpnzFWUw4u/Sr7/e++VhLiTRiTfH6nC5M33tP8lPxd994ch50O3wcmSryn/TZ67ilJo1wW+/nfof9jan2Pl0qT+j56ERV+xKpQJGVRueyh3xeO5fmJnDhzQjWHbbMHvn5vM1UdvzyUH1uhxNvm5JPTY/tgkGMmofw+zxcvL+M9bH/L1Dy6hcPmXhNMfSWbM1SVGeOQs+OR5uPhV6L7D6ttWLEqC6C22TUKadfl4JDx0Ghx+Hex75arhL1+5i61f+z6RQOh3wAYFSwff/Cr9urTnrnP3XD24fAH8cXAy++nw30CfvVbfVlEOL/8G3vwLbLlrcuzSWelA5+xqtT4Dj1+cBGG7nw1vD4eyZcnP8IE/SYL59x9Iwr35U5LlZ7udlfwHwBb9qKiMFK8oo9OHdyXhX8894PSHYcqL8J9vw8Bj4Fv3saAkJn2els2Hx85Pfg8MPCb5XuvQK3ncnPbw5OVJCH3irbDLKfU7OSWLYcZ7UDQGit5NLpfPW/u4zBRcMRY69uHDosUc/9c3yMvOZEVZxapDUlmBjPIV9O8IJ+3YkWMGFNClR++1fh/FGLnmiQn0efdGLsl6Gg75eRKCNQGDpdZpU3wNJkmS6s9gaVO3fEEyU+LjkckbhFiRvNnt0j/5H+rcjnyyzdl8c9zOZFLBk73uZ+t5o2DA0fC12+DTF+CJ70CPHeGMx9b/Br94RvLmK1WYLLvqtDUzF69g+KipnL9vP3ovHgtPfz95U5WVl4ReO34DDrw6mf1Uh/c/msSIh+/ghMy32KXyIzjyBtj7O2scc+7d7zBtwXJe/uFBaz/AeoIlSBpAf/bRuwwYcQJhq93h7Cchs8ZMnNdugleuT5YqHfsH2GpXps5dys3Pf8yPZv6QLVd+zsiDnqEi1ZGf/udDvrl7T35/0toNhn/55AT+NfpLRn53/zWab6/h4TOT5UpXjl//ea8oT3ryxMokwKha2lRH35S6LF5RxncfGEvxlNH8ZNtpDC17hzB7AoQMpg64gKPe348rDt+BKw7tDyRLZCa+NZJ/dvgbOSXzkmVg+3436QuUVfdMotc/nctZd77DP84ewuE9y2DkVcmSrx47wwm3QNdBSVD1xp+S4OHw65KAa+EXyceCz6F4OuTkQ/vOSSjTvkvyZrqsJHkzX7YieZP87j3JLIwtd0lmAm132DrPyeziEs6/Zwzb5y7kuspbaDdrDOz0LTj25rX7+CybB4+eB5+Pgj0vgiN/m/Q3qyhLxiY+Dl+Ngf6Hwx7nQZdaelKVLoOisUnYVJ8ArXR58vMz7xOY9QG8dz8sn8eCwkFct+BQniofyr4DtuTuc/dcM7Cc9SHceWRSw3nPpmdqNcCy+XDvccnzcMajayxRW8P7D8N/LobDroX9vt+wz1XlwdOSAPXyd5LgZMFUuP0APopbU1leyuC+W5JRz2CpaOFy9vvdK/zyuMGcv1+/1TcsmAq37JYEqrECBh4Lh/4ymbX36Pnw5RtJKHjUjclz9uj5MPUV2ONcOOp3ybLFV/5fEpifen8SxC+dm/y+ePfeZFlyrExmEW21G+x9OQw+cY1ZWGuY9BQ8dmGyBHbJzCSUPP2RZAZcdZUVSf+kcfclYVd1uR2TWjZm5k+MsHQOv/zPeMZ8sZCnr9yfzJIFcMdhSeB80p1c/dgHPDl+Bm9fcyglpRV8NLOY4kkvccQHPyS3ctmaj5eZgoN/Cntfscbv14o3/0rmf6/hnxVH0P/cv7HXtg1bYrs+Bkut02b7GkySJAEGS5uXFYvg89eSXkMzx8Og42HotyG3kMvuH8ebn83jtR8dRIcP7oQXfgG5hcmsi34HwCn3J9cbQ/nKZHbHgs9hr+8kS2DqYdy0hZx752j+mv0X9i8fTfjWfTD4BCDZpW2XX7/AqXv24doTdlj7zvUIllYZ/yA8cQkc8GM45JpkLEZ4+bok7Nj51GQGQM3QadYE+Pv+MOQCOPZmbnz2Y25/7TP+ecFQ9u/fNXkjXrAVk+aWcOwtr3PWXlvz6xN3rL2GorFwx6FJQHPQ1fU6P42lrCJpsP7ou0Wcumdvrj+kExWv/I7UB//ki4w+9Dz/PrJ77QYxUvbGLWS8dC1FYUu6nXUXeRPuT97gdt8xmX3To/av75r/fMh7741hxNCPyHr/geQN98E/S74fqp/XuZPhqe8ly6dqat81CVnKlq19W3VdByWPPej4De/ZUlGePOev/S5ZztVj5+TnIFWQfHz4KCydA8f/GXY9fcMeu7GUrUiWDr31V5j/KQuzu5Eaej7thp27embIklnwj0OS7+OLXq59BtuGWDoX7jk26Q901uNrzu4BWDwdbtsbum2fhFgb0Hi+Vgu/TJbE9T8MTrob7joK5n/K64c+Se5TF9O3+xZ0vez5ej1U1RLU/37/gDWbcVcFS8f+MQl/3vwLlC5NQvLylXD8X9ac9VNZkfxOeONPSfizfH7yu+H4v6wd/sx8P9k8IDMn+R7vs1f9vhe/GgMPnpI02z7zsfXP7iovTWb6LS5KQv7ew9bs47URqnbcfOzSfZLllS9fD6NuYtnZzzPk7kWcuOtW3PjNnZODSxYnz39WbrJELyc/OY857ZNeT5OeSsK1E29NZrJ98G94/ELKBp7AsTPOY86ycv7znX3p16WB4ec6GCy1Tm3iNZgkSW2YwVIbUVEZWbyibNU22sx4L2n63GOn5MX/OmafNKc3Pp3HBXe+zsudb6bnyilwzlPQeyhvTZnH6Xe8zZ3nDOHQQd3XvuOGBEuQzNIa/wCc/UTSv+X5n8Ho25LZCcf+qe4lRCOvSnpFfXsUJZ0Hc8wtr5Nbuogn+z9D9oRHiMffwiljB/Dp7CW88qODau9NEyPce3zSq+W749fdJLiJxBj5wwuf8NdXpnDo9t1on8pi6YRn+XuHe8gumZ/0y5n7MXz0JAu3PooDPjmJrw0bxK9P2IHFHzxF/vPfJ7NkEV9tfz5bDx6WzN4o3Aryu1M5dRSjH7qBfeJ7kJGdzFg7+Ge1L7GEpB/NR08kAc4W/ZJeQB37rH7zXro8eVO/fN7qHjnZ7VZftu+y8U2Av3oHXr0hCVRWFsPKJcllh95w8t3Jm+SWVlmZzDAcfVsSIIdMGHh0stTqtRuTpZXnP7tGX5yNsmQW3H1MMnOs/xHJ5+p/RBKy/OsbMG00XPIGdN52/Y9VH6//AV76DWx7SLKM8OR7qRx0IhP/396UkcNOP3uV7Mz1L+277IFxjP1iAaN/euiazcargqWv/z1ZmrZsPrx+c/K78Ng/1h2AfzQi+f0w7NvJLKTGbjhdujz5/bux4dxGWry8jD2u/y8XH7ANPz5q++Rn4JbdmZO9FUNnXcVTl++/eifRJy5Llvxd8OLafahiTH6en/lREkDtdkYy667PXnDGo0wrruSaJz7k9yftvM4edQ1lsNQ6tfXXYJIkbe4MltTqXP3YB7w4diJvdrmBVMVSuOC//G5MGf8YNZXxvzqC/NoaSW9osFS6LJnhsXxBsoxp/P1J0/Sjblz3G8cVC+H/9kia3p43kqmv3EOH135Bx7CcTCr4aIcfcsy7e/Dbr+/E6cPq2M3t0xfh/m/C0b9P3qy2oH/+7wt+OWIiMcLlB2/Hjw7oBs/+JJkhEzKSZU77XMl1z0zizjc+Jyczg9KKSjpRzHXZd3Nc5tu1Pu7s2JEFg85i0HFXQn635v2iGkvV77cm2Llqo83/LGkUnl4mBwFOezAJfxpT8cxkNtcnzyXLtQjJDpFzJyVLRfe8sPE+V3kp3L5vsgRwt7PgxL8CsPCvBzNx9komHf4vLjpgm3U+RGVlZI/r/8vB23fjj9/adc0bawZLWstpw0czf9lKXvh+0lsrvnsv4akr+V3B1fzkhz9NDpr8XDLLav8fJksJ67JsXvK7ZMKj0H0nOO+ZtZeaNgGDpdbJ12CSJG3eNuY1WMP2JJbW42fHDuKVyXO4lJ9xZ/wp4f6TeD9ex+5bd649VILVIUB95bSHk++B4QcnodK+30tClPWFCHmdkjdTT30Xbt+fbWZ/SFH7wVyw8FSeSP2Slz+eww5bFXLKnr1rv39lJbx4LXTcOunJ08LO2rsvPTrk8dKk2Vxx6HaQlQnfGA47fwtSHZLdzIAfHTGQyhhJZWXSs1MevTrl0avjcVz57Lt8/MlkfntoZ4ZsUQLFM3n8yxS/mNyP0V87CnLr6C+zKWiNgVKVztsmDagP/nnSuyor1fihEiRL6o7/c/J9O+v9JFT45DnY8ZvJktDGlJWThD5j70oC3rROeTls0T7y5xc/4fhdtqJHh9w6H2LijGIWLi9j//5N079nc3fY4O5c9/RHTJu/nD6d2zGm4zEUVN7EZeX/gvIfJIH8U1cmu/wd+JN1P1j7LnDSnUlg32W7ZgmVJEmStOkxWFKTKMzN5v99bScuvG8s/x56Eyd/cCF7lj1O9qE/bdxP1G1Q0vi2eHoyQ6K+QcJuZyXNeud+DEfdSKddzmfJX16GElhSUs6vz9qBzNp2gYPkf+9nf5hsM55Vxxbuzezwwd05fHCN5YXbrblzWV5OJr86fu3eVr87fX9O/Uc2Z75azIMXHcquu3bkzze9ytDt2lOwKYdKm4qsHNjha03/eTIykuWAW+2WNGZuKj13Tz5q2KZLe8q/iFz3zEfcevrat1d5fcpcAPbdzmCpIQ4b1I3rnv6IFyfN5vz9+vGvd4ooyTiH4SuuT3b3nPl+siz1jEfrv3y6957rP0aSJEltVv33sZY20GGDu3P8LltxzbvtKA855IXSpEH2OjVghsl2hybbhm/I7JSMzGRHue9PhL0upX1eiuu/ljSx3mGrQob03aLu+37476SH0I4nbXitrVBeTiZ3njOEbgW5XHjvWJ6fOItpC5Zz5A49Wro0bUZyszP4zkHb8cwHM3nj03l1HvfGp/PYvkcB3QpqmdW0CS3dbilbd25P/275vDhpNvOWruTZCTPZavdjkt5aL1+fBOMH/Bi23LmlS5UkSdJmwmBJTera4weTn8qiorKSVFYGO/ZsRUspcguT7cXT9t6mMwBH77Se3bgqypLdzupqDr4J6pKf4p7z9qQiRr5z/zgyQhIMSo0iHfp++8Bt2LpzO3755ARWllesecx798O1HXj/izns52yljXLooO688/kC7nrjc8oqImfu1QcOvw4qy2HLXWH/H7R0iZIkSdqMbD7vjNUqdc5Pce0JyfKrnp3y6l5e1opkbwI1NoVtuuZzx9lDyMrMYGi/LeiS3zp2GdTmIzc7k1+fsANT5y3jjtc/X/PGl34NQLuKYvZbb3+ltvkzWl+HD+5GeWXk9tc+Y1i/LdiuWwF02x7Ofx7OfAwyXeIqSZKkxmOPJTW5E3bZiooRGezWu2NLl6L1GNJ3C565Yj97K6nJHDSwG0fu0J3/e/lTDtm+G4O2LFzj9pzMDIb169xC1W0edu3dic7tc5i/rJQz99p69Q32SpIkSVITcMaSmlwIgayMQNeCTWUGTNvu49K/e8E6d+2SNtYvj9+BvOxMjv+/N7j+6Y9YUlK26rade3UgLyezBavb9GVmBI7asQc9CnPtlSZJkqQmZ7AkSWpWPTvm8eIPDuSkPXpx55ufc/DNr7G8NOm5NLTfOhrnq95+efxgnv/eAeRk+WdekiRJTctXnGo+693RqYVnCm3IrnKSNkyNn//O+Slu/ObOPPGdfenVKY+lK8sBGLaNwVJjSGVl0qGdS1olSZLU9AyW1LpsEuFO214qJzWmXXp35PFL96EgN2n5N7B74XruIUmSJKk1MVhSM9kUAqMNsEkEYFJrse6fl4yMQF520ldpU9g5UpIkSdJqBkuSpE2Lwa4kSZLUahgsSZIkSZIkqUEMliRJkiRJktQgBkuSJEmSJElqEIMlqaborm+SJEmSJNWHwZKa0XoCmxYPdOrZELjF65TaKH/2JEmSpFbHYEnNo967OG0quz1tKnVKrYC7uEmSJEmbLYMlSdImxqBKkiRJai0MliRJkiRJktQgBkuSJEmbkRDCUSGEySGEKSGEq2u5PYQQbknf/kEIYfeWqFOSJG0eDJYkSZI2EyGETOBW4GhgMHBaCGFwjcOOBvqnPy4G/tasRUqSpM2KwZIkSdLmYygwJcY4NcZYCjwEnFjjmBOB+2JiNNAxhLBlcxcqSZI2DwZLaj6bzFbhm0qd0iakvj//m8zvCanV6gl8Ve16UXpsQ4+RJEmqlxA3oRfxIYS5wJdN9PBdgHlN9Niqnee8ZXjem5/nvPl5zptfY53zrWOMXRvhcdqkEMLJwJExxgvT188ChsYYr6h2zDPADTHGN9LXXwJ+HGN8t8ZjXUyyVA5gR2BCM3wJqj9/z7VOPi+tj89J6+Tz0voMjDEWNOSOWY1dSVNqyheaIYSxMcYhTfX4WpvnvGV43puf57z5ec6bn+e81SgCele73guY0YBjiDEOB4aDz29r5HPSOvm8tD4+J62Tz0vrE0IY29D7uhROkiRp8zEG6B9C6BdCyAFOBUbUOGYEcHZ6d7i9gMUxxpnNXagkSdo8bFIzliRJklS3GGN5COFy4HkgE7grxjgxhHBJ+vbbgZHAMcAUYDlwXkvVK0mSNn0GS6sNb+kC2iDPecvwvDc/z3nz85w3P895KxFjHEkSHlUfu73avyNw2QY+rM9v6+Nz0jr5vLQ+Pietk89L69Pg52STat4tSZIkSZKk1sMeS5IkSZIkSWoQgyUghHBUCGFyCGFKCOHqlq5ncxRC6B1CeCWEMCmEMDGE8N30+BYhhP+GED5NX3Zq6Vo3NyGEzBDCeyGEp9PXPedNKITQMYTwaAjh4/T3+96e86YVQvh++vfKhBDCgyGEXM954wsh3BVCmBNCmFBtrM7zHEL4afrv6uQQwpEtU7U21PpeE6Ubft+Svv2DEMLuLVFnW1KP5+SM9HPxQQjhrRDCLi1RZ1tS3/cOIYQ9QwgVIYSTmrO+tqo+z0sI4aAQwvj064bXmrvGtqYev786hBCeCiG8n35O7PnXxGp7PVfj9gb9nW/zwVIIIRO4FTgaGAycFkIY3LJVbZbKgR/GGAcBewGXpc/z1cBLMcb+wEvp62pc3wUmVbvuOW9afwGeizFuD+xCcu49500khNATuBIYEmPckaRZ8al4zpvCPcBRNcZqPc/p3++nAjuk73Nb+u+tWrF6viY6Guif/rgY+FuzFtnG1PM5+Rw4MMa4M3Ad9i1pUvV975A+7nckjfTVxOrzvIQQOgK3ASfEGHcATm7uOtuSev6sXAZ8FGPcBTgI+ENIdjRV07mHtV/PVdegv/NtPlgChgJTYoxTY4ylwEPAiS1c02Ynxjgzxjgu/e8lJG+2e5Kc63vTh90LfK1FCtxMhRB6AccCd1Qb9pw3kRBCIXAAcCdAjLE0xrgIz3lTywLyQghZQDtgBp7zRhdjHAUsqDFc13k+EXgoxrgyxvg5ye5jQ5ujTm2U+rwmOhG4LyZGAx1DCFs2d6FtyHqfkxjjWzHGhemro4FezVxjW1Pf9w5XAI8Bc5qzuDasPs/L6cDjMcZpADFGn5umVZ/nJAIFIYQA5JO8zihv3jLbljpez1XXoL/zBktJuPFVtetF6TE1kRBCX2A34G2ge4xxJiThE9CtBUvbHP0Z+DFQWW3Mc950tgHmAnenlx/eEUJoj+e8ycQYpwM3A9OAmcDiGOMLeM6bS13n2b+tm6b6PG8+t81rQ8/3BcCzTVqR1vucpGfTfh24HTWX+vysDAA6hRBeDSG8G0I4u9mqa5vq85z8FRhE8p+CHwLfjTFWopbUoL/zBksQahlzq7wmEkLIJ/nfm+/FGItbup7NWQjhOGBOjPHdlq6lDckCdgf+FmPcDViGS7CaVLqnz4lAP2AroH0I4cyWrUr4t3VTVZ/nzee2edX7fIcQDiYJln7SpBWpPs/Jn4GfxBgrmr4cpdXneckC9iCZzX8k8IsQwoCmLqwNq89zciQwnuQ13K7AX9MrANRyGvR33mApSeB6V7veiyQxVSMLIWSThEr3xxgfTw/Prppal750Smrj2Rc4IYTwBcnU00NCCP/Cc96UioCiGOPb6euPkgRNnvOmcxjweYxxboyxDHgc2AfPeXOp6zz7t3XTVJ/nzee2edXrfIcQdiZZ9n5ijHF+M9XWVtXnORkCPJR+DXYSSZ+5rzVLdW1XfX9/PRdjXBZjnAeMIumHqaZRn+fkPJLliTHGOIWkZ9z2zVSfategv/MGSzAG6B9C6JduFHYqMKKFa9rspNfN3glMijH+sdpNI4Bz0v8+B3iyuWvbXMUYfxpj7BVj7Evyff1yjPFMPOdNJsY4C/gqhDAwPXQo8BGe86Y0DdgrhNAu/XvmUJIebp7z5lHXeR4BnBpCSIUQ+pE0gHynBerThqnPa6IRwNnpXWP2Ill+OrO5C21D1vuchBD6kITqZ8UYP2mBGtua9T4nMcZ+Mca+6ddgjwLfiTE+0eyVti31+f31JLB/CCErhNAOGMaaG9yocdXnOZlG8tqNEEJ3YCAwtVmrVE0N+juf1fR1tW4xxvIQwuUkOzZkAnfFGCe2cFmbo32Bs4APQwjj02M/A24EHgkhXEDyi8XdGZqe57xpXQHcn/4DOpXkf2Iy8Jw3iRjj2yGER4FxJM0e3yPZESkfz3mjCiE8SLJjS5cQQhHwK+r4fRJjnBhCeIQkWC0HLnNJSOtX12uiEMIl6dtvB0YCx5A0ZF9O8jtOTaSez8kvgc4ks2IAymOMQ1qq5s1dPZ8TNbP6PC8xxkkhhOeAD0j6j94RY6x1y3VtvHr+rFwH3BNC+JBkCdZP0rPJ1ETqeD2XDRv3dz7E6LJ4SZIkSZIkbTiXwkmSJEmSJKlBDJYkSZIkSZLUIAZLkiRJkiRJahCDJUmSJEmSJDWIwZIkSZIkSZIaxGBJkiRJkiRJDWKwJEmSJEmSpAYxWJIkSZIkSVKD/H/6pawiWFz+OQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = torch.utils.data.TensorDataset(tA, tb)\n",
    "BS = 50\n",
    "trainloader = torch.utils.data.DataLoader(data, batch_size=BS, shuffle=True)\n",
    "w = torch.zeros(d, requires_grad=True)\n",
    "hist_grad=[]\n",
    "hist_loss=[]\n",
    "for it in range(100):\n",
    "    loss=fun(tA,w,tb)\n",
    "    hist_loss.append(loss.item())    \n",
    "    print('loss=',loss.item())\n",
    "    for i,(xx,yy) in enumerate (trainloader):\n",
    "        # hist_loss.append((1/2*torch.mean(torch.norm(tA@w-tb)**2)).item())    \n",
    "        # print('loss=',1/2*torch.mean(torch.norm(tA@w-tb)**2))\n",
    "        loss = fun(xx,w,yy)\n",
    "        grad_f, = torch.autograd.grad(loss, w, create_graph=True)    \n",
    "        gd=dfun(xx,w,yy)\n",
    "        w=w-0.01*grad_f\n",
    "    hist_grad.append((torch.norm(grad_f)**2).item())\n",
    "# plt.plot(torch.tensor(hist_loss),label='loss')\n",
    "# plt.plot(torch.tensor(hist_grad),label='grad')\n",
    "fig,(ax1,ax2) = plt.subplots(1,2);fig.set_size_inches(20, 6)\n",
    "ax1.semilogy(torch.tensor(hist_grad),label='grad')\n",
    "ax1.semilogy(torch.tensor(hist_loss),label='loss')\n",
    "ax1.title.set_text('Loss & Grad')\n",
    "ax1.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_estimate(data_shape_cols, grad, weights, iters):\n",
    "    Ds = []\n",
    "    for j in range(iters):\n",
    "        v = torch.rand(d)\n",
    "        D = torch.autograd.grad( torch.sum(grad*v) , weights, retain_graph=True)    \n",
    "        D=torch.stack(D,dim=0)\n",
    "        Ds.append(D*v)\n",
    "\n",
    "    return torch.mean(torch.stack(Ds), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_estimate1(data_shape_cols, grad, weights, iters):\n",
    "    Ds = []\n",
    "    for j in range(iters):\n",
    "        v = torch.round(torch.rand(d)) * 2 - 1\n",
    "        D = torch.autograd.grad( torch.sum(grad*v) , weights, retain_graph=True)    \n",
    "        D = torch.stack(D,dim=0)\n",
    "        Ds.append(D*v)\n",
    "\n",
    "    return torch.mean(torch.stack(Ds), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute for v (lagrangian mutiplier)\n",
    "# the inverse of (v*B+D)\n",
    "def g_v(v,f,gradf,B,D):\n",
    "    D_inv=torch.linalg.inv(D)\n",
    "    inv=D_inv-1/(1+v*torch.trace(B@D_inv))*(D_inv@B@D_inv)\n",
    "    return -v*f+1/2*v**2*torch.dot(gradf,inv@gradf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dg_v(v,f,gradf,B,D):\n",
    "    D_inv=torch.linalg.inv(D)\n",
    "    a=torch.dot(gradf,D_inv@gradf)\n",
    "    b=torch.dot(gradf,D_inv@B@D_inv@gradf)\n",
    "    c=torch.trace(B@D_inv)\n",
    "    return -f+a*v-b/2*(c*v**2+2*v)/(1+c*v)**2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 14248.9342353893\n",
      "loss= 0.0008344226145675453\n",
      "loss= 1.6349064291372063e-10\n",
      "loss= 1.0658962971192813e-17\n",
      "loss= 6.834577360820205e-25\n",
      "loss= 1.3554849022992915e-28\n",
      "loss= 1.6492739597358984e-28\n",
      "loss= 2.816233431639012e-28\n",
      "loss= 2.892099664008314e-28\n",
      "loss= 1.7375277735074991e-28\n",
      "loss= 2.4618623218717607e-28\n",
      "loss= 2.7018486003819654e-28\n",
      "loss= 1.5588631044265836e-28\n",
      "loss= 3.2519095999385146e-28\n",
      "loss= 2.737131636963139e-28\n",
      "loss= 2.6853472326184556e-28\n",
      "loss= 2.2808711294180263e-28\n",
      "loss= 3.5651736609727653e-28\n",
      "loss= 1.8948069164859381e-28\n",
      "loss= 2.9462105917258175e-28\n",
      "loss= 2.820732403989101e-28\n",
      "loss= 2.595968675759333e-28\n",
      "loss= 2.296263161533568e-28\n",
      "loss= 2.544939235952848e-28\n",
      "loss= 2.796712205722703e-28\n",
      "loss= 4.25747614250198e-28\n",
      "loss= 2.117968271001976e-28\n",
      "loss= 2.189597457493626e-28\n",
      "loss= 2.8784794874416076e-28\n",
      "loss= 8.736018227740503e-29\n",
      "loss= 3.644306270527748e-28\n",
      "loss= 1.93757796869089e-28\n",
      "loss= 2.433173669420169e-28\n",
      "loss= 2.9247018061069013e-28\n",
      "loss= 1.5814812256934675e-28\n",
      "loss= 2.7870825560007674e-28\n",
      "loss= 1.329723663363168e-28\n",
      "loss= 1.2732399899541792e-28\n",
      "loss= 1.3976396569220397e-28\n",
      "loss= 2.8252467837787444e-28\n",
      "loss= 2.1901367178780544e-28\n",
      "loss= 2.6339017919439838e-28\n",
      "loss= 2.3508671273168356e-28\n",
      "loss= 1.77543007481304e-28\n",
      "loss= 1.7927018145543046e-28\n",
      "loss= 2.446886290624206e-28\n",
      "loss= 2.046847530015644e-28\n",
      "loss= 1.94860969541234e-28\n",
      "loss= 1.4420747125989418e-28\n",
      "loss= 2.552889474763279e-28\n",
      "loss= 1.6198765650647714e-28\n",
      "loss= 3.374968819665082e-28\n",
      "loss= 1.8864406768075202e-28\n",
      "loss= 1.4515811028044374e-28\n",
      "loss= 1.590109391844322e-28\n",
      "loss= 1.9550191902672607e-28\n",
      "loss= 1.2902806181021174e-28\n",
      "loss= 1.6045923850261145e-28\n",
      "loss= 2.709259578807968e-28\n",
      "loss= 2.522814152751728e-28\n",
      "loss= 2.640064767766023e-28\n",
      "loss= 1.9794245745225357e-28\n",
      "loss= 2.578666121138958e-28\n",
      "loss= 7.683998254918419e-29\n",
      "loss= 1.4842294672216899e-28\n",
      "loss= 1.8003901268922985e-28\n",
      "loss= 2.6295106716707804e-28\n",
      "loss= 1.975233750963549e-28\n",
      "loss= 2.759734350790468e-28\n",
      "loss= 2.8440900823546287e-28\n",
      "loss= 2.6436701086219163e-28\n",
      "loss= 2.8823775696490474e-28\n",
      "loss= 1.3928325357808487e-28\n",
      "loss= 3.2469638118413287e-28\n",
      "loss= 5.567601542751061e-28\n",
      "loss= 2.452679487896923e-28\n",
      "loss= 2.3206223234701784e-28\n",
      "loss= 2.1021910528975557e-28\n",
      "loss= 1.244243188711485e-28\n",
      "loss= 1.2693881300654045e-28\n",
      "loss= 1.2564458808391225e-28\n",
      "loss= 2.537913443515724e-28\n",
      "loss= 2.434190560430805e-28\n",
      "loss= 2.2885132194373544e-28\n",
      "loss= 2.647059745324037e-28\n",
      "loss= 1.070154529178434e-28\n",
      "loss= 1.878413400799314e-28\n",
      "loss= 1.26003581425546e-28\n",
      "loss= 2.5165279174132476e-28\n",
      "loss= 1.6499518870763227e-28\n",
      "loss= 2.6978426660976404e-28\n",
      "loss= 2.563751719649623e-28\n",
      "loss= 2.117983678441531e-28\n",
      "loss= 1.4079934563030653e-28\n",
      "loss= 2.674623654688107e-28\n",
      "loss= 2.392405584357379e-28\n",
      "loss= 1.4331383976569853e-28\n",
      "loss= 3.253927974520233e-28\n",
      "loss= 2.6107752251717823e-28\n",
      "loss= 1.8429300675039238e-28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f54301a18e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = torch.zeros(d, requires_grad=True)\n",
    "hist_grad=[]\n",
    "hist_loss=[]\n",
    "\n",
    "for step in range(100):\n",
    "    loss=fun(tA,w,tb)\n",
    "    hist_loss.append(loss.item())    \n",
    "    print('loss=',loss.item())\n",
    "    for i,(xx,yy) in enumerate(trainloader):\n",
    "        loss = fun(xx,w,yy)\n",
    "        grad_f, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "        # precond = torch.min((loss / (torch.linalg.norm(g) ** 2 + epsilon)), eta)\n",
    "        precond = loss / (torch.linalg.norm(grad_f) ** 2) \n",
    "        w = w - ( precond * grad_f )\n",
    "\n",
    "    #hist_loss.append(fun(tA,w,tb).item())\n",
    "    hist_grad.append((torch.norm(grad_f)**2).item()) \n",
    "fig,(ax1,ax2) = plt.subplots(1,2);fig.set_size_inches(20, 6)\n",
    "ax1.semilogy(torch.tensor(hist_grad),label='grad')\n",
    "ax1.semilogy(torch.tensor(hist_loss),label='loss')\n",
    "ax1.title.set_text('Loss & Grad')\n",
    "ax1.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPS-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "loss= 14248.9342353893\n",
      "loss= 11995.06766452509\n",
      "loss= 9588.700699331008\n",
      "loss= 7500.825710046813\n",
      "loss= 5368.835794903757\n",
      "loss= 3476.3326806704245\n",
      "loss= 1549.3854014822225\n",
      "loss= 15.59404427161522\n",
      "loss= 210.83068396073062\n",
      "loss= 46.72853967073647\n",
      "loss= 25.473369572591906\n",
      "loss= 46.67569088521682\n",
      "loss= 253.0540967150968\n",
      "loss= 20.6377101620081\n",
      "loss= 35.80435595812661\n",
      "loss= 185.50198559764254\n",
      "loss= 5.078718934536944\n",
      "loss= 14.398265159818262\n",
      "loss= 23.356935903804874\n",
      "loss= 182.75528254509408\n",
      "loss= 13.151632951948859\n",
      "loss= 246.13494869667417\n",
      "loss= 26.04440299719487\n",
      "loss= 6.890061700081105\n",
      "loss= 23.14809348670025\n",
      "loss= 13.225747657267556\n",
      "loss= 47.40753996021292\n",
      "loss= 14.10619260864967\n",
      "loss= 65.43623089480032\n",
      "loss= 67.67892751610162\n",
      "loss= 3.9364689763740346\n",
      "loss= 120.38162735648096\n",
      "loss= 121.44575536012451\n",
      "loss= 19.30691782689201\n",
      "loss= 11.62814280389116\n",
      "loss= 28.960863058340106\n",
      "loss= 4.986316723583485\n",
      "loss= 54.25113612129372\n",
      "loss= 7.80276209309569\n",
      "loss= 108.07320070612938\n",
      "loss= 13.463501188888007\n",
      "loss= 12.475566651046904\n",
      "loss= 15.84467592265318\n",
      "loss= 94.01949677656124\n",
      "loss= 12.704302301720695\n",
      "loss= 16.51985496540262\n",
      "loss= 24.947760680740938\n",
      "loss= 8.833122872278869\n",
      "loss= 652.2304087137418\n",
      "loss= 20.347997505048593\n",
      "loss= 4.268178047273234\n",
      "loss= 6.771808704007498\n",
      "loss= 132.40953794123797\n",
      "loss= 5.885134135772727\n",
      "loss= 15.689546012249618\n",
      "loss= 15.966679159322673\n",
      "loss= 17.424403067591495\n",
      "loss= 18.322820128690278\n",
      "loss= 7.9996538637429655\n",
      "loss= 96.3053850362474\n",
      "loss= 13.41443249590257\n",
      "loss= 26.983980652177806\n",
      "loss= 5.3508699020663455\n",
      "loss= 37.825122023658864\n",
      "loss= 7.564828037926571\n",
      "loss= 66.88201481051249\n",
      "loss= 7.521051015736529\n",
      "loss= 6.29172204811866\n",
      "loss= 59.64021578139982\n",
      "loss= 11.72912194633593\n",
      "loss= 2.688230498892043\n",
      "loss= 2.5807150757621\n",
      "loss= 22.56629105814983\n",
      "loss= 698.23623741609\n",
      "loss= 54.35877841377838\n",
      "loss= 32.20287032460466\n",
      "loss= 41.66641987827929\n",
      "loss= 60.15319408308757\n",
      "loss= 26.729492692998956\n",
      "loss= 105.81789803223106\n",
      "loss= 13.843531451788127\n",
      "loss= 11.792626384756401\n",
      "loss= 132.32787649832233\n",
      "loss= 21.88610395839433\n",
      "loss= 3.933004203433658\n",
      "loss= 15.590171500299668\n",
      "loss= 14.184404021530398\n",
      "loss= 136.16649831400474\n",
      "loss= 58.175015658118404\n",
      "loss= 189.98916513656744\n",
      "loss= 266.00318163400345\n",
      "loss= 64.73810841686232\n",
      "loss= 9.983896924152708\n",
      "loss= 7.029787565448974\n",
      "loss= 134.37568116799966\n",
      "loss= 44.20459124679211\n",
      "loss= 65.18848796956065\n",
      "loss= 3.301915506919482\n",
      "loss= 116.58999951370554\n",
      "loss= 31.893648449315393\n",
      "loss= 10.233512601799564\n",
      "loss= 14.802860933786135\n",
      "loss= 16.73188110156806\n",
      "loss= 55.35119689828716\n",
      "loss= 51.04393931027614\n",
      "loss= 24.910165659281663\n",
      "loss= 12.73629899819879\n",
      "loss= 11.459457853412465\n",
      "loss= 45.87522047772318\n",
      "loss= 32.94733357682172\n",
      "loss= 11.463668542373487\n",
      "loss= 3.8209600262083647\n",
      "loss= 32.96698499416815\n",
      "loss= 25.33264088948239\n",
      "loss= 9.869505611338925\n",
      "loss= 12.740588948762953\n",
      "loss= 12.494458591130865\n",
      "loss= 44.87436629262625\n",
      "loss= 2.83970716274054\n",
      "loss= 19.81862107495796\n",
      "loss= 22.730985535608347\n",
      "loss= 32.16818033634172\n",
      "loss= 7.91273513444088\n",
      "loss= 58.295037921756915\n",
      "loss= 11.249907681664206\n",
      "loss= 58.065964931983444\n",
      "loss= 3.292085113073556\n",
      "loss= 12.813879160352105\n",
      "loss= 18.248062592419565\n",
      "loss= 29.311446749971513\n",
      "loss= 5.5357831975916945\n",
      "loss= 2.643004567051323\n",
      "loss= 19.71191931467051\n",
      "loss= 74.76414622649673\n",
      "loss= 4.966581242902839\n",
      "loss= 46.81812785667988\n",
      "loss= 12.578058620040684\n",
      "loss= 21.227912373462434\n",
      "loss= 3.8797106397727\n",
      "loss= 37.07487450004114\n",
      "loss= 3.099429011928438\n",
      "loss= 4.927945082004268\n",
      "loss= 3.660474147750452\n",
      "loss= 6.824124569391088\n",
      "loss= 8.759968896965855\n",
      "loss= 10.844094466411654\n",
      "loss= 3.1187608890405167\n",
      "loss= 4.09730684373346\n",
      "loss= 47.72959572179382\n",
      "loss= 4.917112352700962\n",
      "loss= 0.9089015444856096\n",
      "loss= 15.701371585615867\n",
      "loss= 4.315524131730361\n",
      "loss= 7.063221996330568\n",
      "loss= 10.064637605451127\n",
      "loss= 44.863559757231066\n",
      "loss= 33.04231211696111\n",
      "loss= 21.276494690273402\n",
      "loss= 13.72713308267622\n",
      "loss= 15.458023065921834\n",
      "loss= 9.518561028436293\n",
      "loss= 5.592312886529927\n",
      "loss= 2.4568546037350245\n",
      "loss= 45.105319603739765\n",
      "loss= 3.5915925406519755\n",
      "loss= 1.449385592915034\n",
      "loss= 16.394573922394112\n",
      "loss= 2.5882237625413103\n",
      "loss= 18.838122025125028\n",
      "loss= 6.793731875464317\n",
      "loss= 5.644009080352915\n",
      "loss= 5.82622974621844\n",
      "loss= 4.0883872320013825\n",
      "loss= 0.9632159528526836\n",
      "loss= 9.173931143891707\n",
      "loss= 3.4172787939006857\n",
      "loss= 64.83361335800906\n",
      "loss= 2.547334724795433\n",
      "loss= 10.482984068790273\n",
      "loss= 2.9844926188682184\n",
      "loss= 2.7107570069774902\n",
      "loss= 1.1193074160427356\n",
      "loss= 3.3909787764833945\n",
      "loss= 10.686513353513416\n",
      "loss= 32.796781784885326\n",
      "loss= 58.103302720398815\n",
      "loss= 11.340773926751078\n",
      "loss= 7.682909334899828\n",
      "loss= 2.0218326907125794\n",
      "loss= 7.713598156282886\n",
      "loss= 0.6393272746710769\n",
      "loss= 16.646624209748992\n",
      "loss= 2.769019138904169\n",
      "loss= 6.2046704843091955\n",
      "loss= 54.41947439589865\n",
      "loss= 1.9572901953329338\n",
      "loss= 24.948780353564086\n",
      "loss= 56.649378277031175\n",
      "loss= 2.2697487942561843\n",
      "loss= 8.97717031649793\n",
      "loss= 3.6991762587878414\n",
      "loss= 31.49069157095522\n",
      "loss= 4.40767575382848\n",
      "loss= 2.5090236412394473\n",
      "loss= 7.190562185976317\n",
      "loss= 3.1063078867573832\n",
      "loss= 2.66755860909336\n",
      "loss= 1.5911080035178444\n",
      "loss= 2.298632426564321\n",
      "loss= 7.229556517598684\n",
      "loss= 2.1347735551503115\n",
      "loss= 24.992851128577737\n",
      "loss= 4.210287175622898\n",
      "loss= 9.034922074036682\n",
      "loss= 10.187846726517884\n",
      "loss= 2.0802633230960264\n",
      "loss= 5.089479149063758\n",
      "loss= 19.806350165869297\n",
      "loss= 4.833399873704616\n",
      "loss= 25.588629340128108\n",
      "loss= 2.870305491536399\n",
      "loss= 81.29237182512391\n",
      "loss= 7.103287227526316\n",
      "loss= 44.1080150101795\n",
      "loss= 1.994044423910628\n",
      "loss= 11.961538466990158\n",
      "loss= 11.308154256704215\n",
      "loss= 3.634335914238852\n",
      "loss= 29.215906132690836\n",
      "loss= 1.1830851598237142\n",
      "loss= 6.290419957889574\n",
      "loss= 3.046644115498453\n",
      "loss= 60.649669770715136\n",
      "loss= 37.13634243222533\n",
      "loss= 21.417038399794528\n",
      "loss= 44.81212839684562\n",
      "loss= 7.257537445379885\n",
      "loss= 6.5073809564439555\n",
      "loss= 1.4240543171488675\n",
      "loss= 1.8452538846307367\n",
      "loss= 0.7279121699687952\n",
      "loss= 1.0441617681122655\n",
      "loss= 1.411985312237207\n",
      "loss= 4.051271540731931\n",
      "loss= 46.37039026174192\n",
      "loss= 1.6158825577570008\n",
      "loss= 1.7538907836595805\n",
      "loss= 2.4671108758361897\n",
      "loss= 28.17899938074525\n",
      "loss= 0.8405226235407961\n",
      "loss= 3.5656632684083904\n",
      "loss= 0.9685922071780895\n",
      "loss= 8.344232961903822\n",
      "loss= 10.151217692224945\n",
      "loss= 9.969368539013029\n",
      "loss= 2.3097962429814536\n",
      "loss= 3.199048546777043\n",
      "loss= 28.09010176290012\n",
      "loss= 7.411581506901724\n",
      "loss= 28.399914558800507\n",
      "loss= 2.7410274799304832\n",
      "loss= 14.140134693428138\n",
      "loss= 13.449565257362337\n",
      "loss= 3.1323348326880054\n",
      "loss= 4.710555682304807\n",
      "loss= 49.97073312025897\n",
      "loss= 3.817246926786917\n",
      "loss= 1.3267999830139154\n",
      "loss= 2.9950635263635794\n",
      "loss= 9.413407817138474\n",
      "loss= 2.1932827325329276\n",
      "loss= 2.3790522398560507\n",
      "loss= 6.313482214911128\n",
      "loss= 0.5117711033895062\n",
      "loss= 0.6646394200639422\n",
      "loss= 1.5350585311257208\n",
      "loss= 36.7275166475354\n",
      "loss= 7.2359203711454185\n",
      "loss= 17.310541456061348\n",
      "loss= 7.604294732925782\n",
      "loss= 107.2746348901721\n",
      "loss= 43.563558486920925\n",
      "loss= 2.040189828169063\n",
      "loss= 6.4189300579676445\n",
      "loss= 0.8482584190668343\n",
      "loss= 49.54735673950525\n",
      "loss= 1.0506589655385994\n",
      "loss= 8.56694138811128\n",
      "loss= 0.4541891043844854\n",
      "loss= 1.9687060427642038\n",
      "loss= 24.89664254047977\n",
      "loss= 23.54349862817605\n",
      "loss= 1.0403238802390538\n",
      "loss= 6.1168057566193275\n",
      "loss= 2.942976335539806\n",
      "loss= 6.04174311034525\n",
      "loss= 1.9281444078729526\n",
      "loss= 5.521118438546423\n",
      "loss= 2.77102337533888\n",
      "loss= 2.3049571185730025\n",
      "loss= 0.6777807120673205\n",
      "loss= 5.4644917493265135\n",
      "loss= 61.32350712299548\n",
      "loss= 1.00719575071473\n",
      "loss= 0.5154457032361879\n",
      "loss= 5.45502441143221\n",
      "loss= 14.779768971466412\n",
      "loss= 2.726196730209007\n",
      "loss= 43.935723812361154\n",
      "loss= 1.7124415719811854\n",
      "loss= 106.06780411264292\n",
      "loss= 3.9993091813170603\n",
      "loss= 4.204750323341258\n",
      "loss= 4.854754701078895\n",
      "loss= 1.4109695000320106\n",
      "loss= 2.724640034889122\n",
      "loss= 1.0389138674272274\n",
      "loss= 1.078434935933734\n",
      "loss= 5.3381582029382715\n",
      "loss= 4.4107195691484\n",
      "loss= 95.62009853116658\n",
      "loss= 3.269326951625358\n",
      "loss= 0.6691619681763964\n",
      "loss= 16.624019822681394\n",
      "loss= 7.359837127764681\n",
      "loss= 1.645216765824557\n",
      "loss= 50.42391790445658\n",
      "loss= 2.290927994136602\n",
      "loss= 1.5801093039144622\n",
      "loss= 3.3700715031112747\n",
      "loss= 74.19509263537037\n",
      "loss= 3.0189605543188454\n",
      "loss= 0.4775215358615096\n",
      "loss= 0.38591088367073845\n",
      "loss= 2.500604670390829\n",
      "loss= 6.118892093719788\n",
      "loss= 1.8146905304029053\n",
      "loss= 24.62613624242623\n",
      "loss= 34.0254969119429\n",
      "loss= 1.5433800332370815\n",
      "loss= 8.725570177398861\n",
      "loss= 7.870015027334806\n",
      "loss= 6.912502808637373\n",
      "loss= 2.0658728696155886\n",
      "loss= 9.104230917417052\n",
      "loss= 16.709841693136624\n",
      "loss= 1.4050580388389673\n",
      "loss= 8.211475489258117\n",
      "loss= 0.9898676479015521\n",
      "loss= 8.985579995130914\n",
      "loss= 1.1777282262380149\n",
      "loss= 3.051686210639721\n",
      "loss= 5.680156406605168\n",
      "loss= 0.8170120166032289\n",
      "loss= 13.485352294223613\n",
      "loss= 1.4003837400194652\n",
      "loss= 1.2469976953006066\n",
      "loss= 1.7171183931593317\n",
      "loss= 2.971386825090551\n",
      "loss= 2.6398950753453265\n",
      "loss= 2.3516269515815917\n",
      "loss= 1.7322885430619317\n",
      "loss= 2.255859155366517\n",
      "loss= 3.870579606132768\n",
      "loss= 27.711857064821203\n",
      "loss= 5.869546135059717\n",
      "loss= 3.5827453436273715\n",
      "loss= 1.4456453823816666\n",
      "loss= 1.559062571919353\n",
      "loss= 21.489901993172598\n",
      "loss= 30.450647192121213\n",
      "loss= 2.0795558253633257\n",
      "loss= 3.373443666145391\n",
      "loss= 4.067314076242438\n",
      "loss= 1.5792917694350874\n",
      "loss= 0.9135742780097178\n",
      "loss= 3.6954985034743344\n",
      "loss= 19.067348926945247\n",
      "loss= 11.249406155364918\n",
      "loss= 12.632171592126149\n",
      "loss= 1.2968412576591624\n",
      "loss= 0.39818868685168246\n",
      "loss= 10.801002234207624\n",
      "loss= 2.4439290520411134\n",
      "loss= 1.7880592198783984\n",
      "loss= 7.971393947489555\n",
      "loss= 1.2511950447036704\n",
      "loss= 23.438873344626867\n",
      "loss= 4.855381410841965\n",
      "loss= 3.4724766384847583\n",
      "loss= 5.171756644957975\n",
      "loss= 6.105686223168741\n",
      "loss= 4.344724278676141\n",
      "loss= 10.367647934611282\n",
      "loss= 1.1521529181231989\n",
      "loss= 4.285756673073819\n",
      "loss= 38.85810858277797\n",
      "loss= 8.33890782959664\n",
      "loss= 9.487434511131646\n",
      "loss= 1.3552135553618585\n",
      "loss= 4.197927480903822\n",
      "loss= 1.156948620691137\n",
      "loss= 25.13895515570286\n",
      "loss= 6.115394595608097\n",
      "loss= 7.4760629156909495\n",
      "loss= 2.4605372079688994\n",
      "loss= 5.8844069963474235\n",
      "loss= 11.01078078236571\n",
      "loss= 0.9669099354948509\n",
      "loss= 0.6046070757064714\n",
      "loss= 6.2808698577452065\n",
      "loss= 9.078295773536853\n",
      "loss= 2.1036031802103\n",
      "loss= 1.3346865839840403\n",
      "loss= 3.528161809445211\n",
      "loss= 26.81355902686578\n",
      "loss= 11.716791686478482\n",
      "loss= 3.7669013823252535\n",
      "loss= 1.524235693874632\n",
      "loss= 2.0508632134567506\n",
      "loss= 3.367636815125661\n",
      "loss= 1.5104918510833973\n",
      "loss= 1.2458958675214309\n",
      "loss= 13.001723644104304\n",
      "loss= 4.82687914400219\n",
      "loss= 8.925081533138124\n",
      "loss= 5.5163130172629185\n",
      "loss= 2.3883776675462696\n",
      "loss= 1.13302226115136\n",
      "loss= 0.7706595980109446\n",
      "loss= 16.535623893661242\n",
      "loss= 7.563474068264214\n",
      "loss= 1.7142587060842207\n",
      "loss= 1.4539767066760065\n",
      "loss= 0.4396020588904781\n",
      "loss= 7.54757487400114\n",
      "loss= 11.959912140026189\n",
      "loss= 17.037392957876193\n",
      "loss= 0.4383912077711689\n",
      "loss= 20.59632546624651\n",
      "loss= 3.3480070818635563\n",
      "loss= 5.045058421713765\n",
      "loss= 1.8123137355558927\n",
      "loss= 2.1201291759023437\n",
      "loss= 4.464782792183177\n",
      "loss= 0.598572831113047\n",
      "loss= 14.655206505611117\n",
      "loss= 109.81773762946051\n",
      "loss= 4.229262870084172\n",
      "loss= 2.542717019699283\n",
      "loss= 12.70251968389386\n",
      "loss= 2.2111506714755347\n",
      "loss= 25.78185404722285\n",
      "loss= 3.6699046065376106\n",
      "loss= 1.721358810777145\n",
      "loss= 2.4952355645943642\n",
      "loss= 7.56459968874483\n",
      "loss= 4.2066120792962005\n",
      "loss= 11.93793043697738\n",
      "loss= 1.8684852946693666\n",
      "loss= 10.843994283670602\n",
      "loss= 3.158609444812546\n",
      "loss= 13.642492768779526\n",
      "loss= 5.027383810168568\n",
      "loss= 4.046257632814824\n",
      "loss= 1.9900611993010489\n",
      "loss= 5.084355483111878\n",
      "loss= 2.8153525816755063\n",
      "loss= 43.64936889791569\n",
      "loss= 11.866904911263372\n",
      "loss= 23.17516432775785\n",
      "loss= 5.2320457161895035\n",
      "loss= 0.7821816199308793\n",
      "loss= 1.3752140365363383\n",
      "loss= 0.858534128269926\n",
      "loss= 5.195760229655546\n",
      "loss= 0.7896350615915434\n",
      "loss= 6.825454878257626\n",
      "loss= 8.34289326522986\n",
      "loss= 3.6130103483234457\n",
      "loss= 1.1369542009602396\n",
      "loss= 9.580293401392682\n",
      "loss= 1.303442139619202\n",
      "loss= 0.9781568740863223\n",
      "loss= 1.530847886383608\n",
      "loss= 0.8415121564031335\n",
      "loss= 5.399566632518972\n",
      "loss= 27.876691233987774\n",
      "loss= 1.3286473227523696\n",
      "loss= 28.86807498817676\n",
      "loss= 7.57004263196792\n",
      "loss= 6.973965373547281\n",
      "loss= 24.918203501083433\n",
      "loss= 1.4438365658689025\n",
      "loss= 2.821758567555413\n",
      "loss= 6.635863660002596\n",
      "loss= 1.6909268578541992\n",
      "loss= 1.1567373164099337\n",
      "loss= 74.79118823980652\n",
      "loss= 3.95723143221773\n",
      "loss= 4.803107082786099\n",
      "loss= 3.6422088440623925\n",
      "loss= 4.020647451851696\n",
      "loss= 4.433773760751213\n",
      "loss= 15.025179879109515\n",
      "loss= 9.534760781255404\n",
      "loss= 2.7002364772344167\n",
      "loss= 3.3950442235930645\n",
      "loss= 8.634931092761626\n",
      "loss= 10.081005653688406\n",
      "loss= 6.350653570871923\n",
      "loss= 1.6787169074295603\n",
      "loss= 50.12871066533067\n",
      "loss= 3.2301454461903516\n",
      "loss= 8.050762216381202\n",
      "loss= 16.926500996666327\n",
      "loss= 0.90631473097865\n",
      "loss= 2.0854732545178227\n",
      "loss= 4.97890329214772\n",
      "loss= 6.971291225853591\n",
      "loss= 1.5469411230811259\n",
      "loss= 0.5226663453932067\n",
      "loss= 1.992683817688698\n",
      "loss= 0.7893048760373861\n",
      "loss= 1.2256681129831517\n",
      "loss= 2.681116335982862\n",
      "loss= 1.549408693484763\n",
      "loss= 8.036382850495928\n",
      "loss= 13.70150471378799\n",
      "loss= 8.395900945244389\n",
      "loss= 0.7444485229814858\n",
      "loss= 1.8428465860071155\n",
      "loss= 4.471956818786514\n",
      "loss= 2.2665364942527075\n",
      "loss= 8.269729353239144\n",
      "loss= 3.5592032688876474\n",
      "loss= 1.3557337558848621\n",
      "loss= 2.013685145623843\n",
      "loss= 39.00425290078915\n",
      "loss= 4.7458213162402485\n",
      "loss= 65.84904822752506\n",
      "loss= 4.225935802545816\n",
      "loss= 9.074133859202446\n",
      "loss= 4.265270667116203\n",
      "loss= 2.9233321771983367\n",
      "loss= 4.4789623239408245\n",
      "loss= 5.35007511989807\n",
      "loss= 3.6033535128652887\n",
      "loss= 1.4457446475757143\n",
      "loss= 6.507080035536547\n",
      "loss= 55.21597892268543\n",
      "loss= 12.206848305578935\n",
      "loss= 8.461945062543041\n",
      "loss= 8.84455337169537\n",
      "loss= 1.222282473184261\n",
      "loss= 46.21225120796416\n",
      "loss= 0.7824192511420439\n",
      "loss= 1.5344088870007677\n",
      "loss= 1.6670422588061748\n",
      "loss= 121.70621507386922\n",
      "loss= 14.240862888896276\n",
      "loss= 2.128841109464221\n",
      "loss= 3.757514405505719\n",
      "loss= 2.4555946511493802\n",
      "loss= 3.847646551617471\n",
      "loss= 0.476890583366599\n",
      "loss= 3.2682656243463386\n",
      "loss= 1.7389414036896857\n",
      "loss= 4.505637827069651\n",
      "loss= 62.08014038299274\n",
      "loss= 3.6062393331957243\n",
      "loss= 1.2922847947444371\n",
      "loss= 0.9634948907442763\n",
      "loss= 1.7487027260402765\n",
      "loss= 0.9747221147413039\n",
      "loss= 7.011033938766243\n",
      "loss= 1.5015241477487664\n",
      "loss= 5.6429004134787055\n",
      "loss= 17.0710567851783\n",
      "loss= 0.879397087483867\n",
      "loss= 10.929579182691512\n",
      "loss= 1.8185158038397713\n",
      "loss= 12.011556865791333\n",
      "loss= 1.8304993431440533\n",
      "loss= 19.02525144873928\n",
      "loss= 27.43986060888536\n",
      "loss= 2.848378083477337\n",
      "loss= 2.974271430777228\n",
      "loss= 7.311428415935301\n",
      "loss= 5.1415413143917625\n",
      "loss= 10.684280924239173\n",
      "loss= 2.8860603854297917\n",
      "loss= 11.96791359444204\n",
      "loss= 5.611245548066986\n",
      "loss= 35.45475352910979\n",
      "loss= 2.3055851966624465\n",
      "loss= 0.8499782706182238\n",
      "loss= 0.6731173383304573\n",
      "loss= 3.7985156299205487\n",
      "loss= 3.115287409218555\n",
      "loss= 90.33869957527834\n",
      "loss= 4.702630383266346\n",
      "loss= 2.634119101215504\n",
      "loss= 12.839454491167606\n",
      "loss= 0.7642255741758627\n",
      "loss= 5.9048070441001395\n",
      "loss= 1.73504646116578\n",
      "loss= 2.368037201749751\n",
      "loss= 1.0398729261411088\n",
      "loss= 0.5783894045184681\n",
      "loss= 5.122314028712205\n",
      "loss= 10.86909421332298\n",
      "loss= 22.622601545607044\n",
      "loss= 3.5297744147385037\n",
      "loss= 1.557095294281918\n",
      "loss= 2.2319861146248434\n",
      "loss= 1.5279960561394665\n",
      "loss= 2.1608889113161975\n",
      "loss= 4.050406272116807\n",
      "loss= 8.017024061221107\n",
      "loss= 6.801052272687616\n",
      "loss= 11.587466376471184\n",
      "loss= 1.930529260488865\n",
      "loss= 13.824940580755037\n",
      "loss= 2.0724285493080807\n",
      "loss= 0.2937410565607375\n",
      "loss= 5.542121860569354\n",
      "loss= 11.609015018424225\n",
      "loss= 5.15367677467291\n",
      "loss= 3.0951938209134338\n",
      "loss= 4.216745968633545\n",
      "loss= 9.526111965773106\n",
      "loss= 16.633418836454442\n",
      "loss= 7.017252329390887\n",
      "loss= 5.971676130803856\n",
      "loss= 9.985344108764378\n",
      "loss= 1.826515190117066\n",
      "loss= 7.259776370811693\n",
      "loss= 0.496433377352847\n",
      "loss= 0.6574482105444558\n",
      "loss= 8.8752758866946\n",
      "loss= 0.7262085595650787\n",
      "loss= 9.980997371635137\n",
      "loss= 0.6770743535046356\n",
      "loss= 1.1374120258669254\n",
      "loss= 3.706803215783845\n",
      "loss= 2.762082075717732\n",
      "loss= 0.6952304051770071\n",
      "loss= 2.3756122844307965\n",
      "loss= 5.066418473884859\n",
      "loss= 5.359123968584524\n",
      "loss= 1.3481645003576186\n",
      "loss= 3.462972406653324\n",
      "loss= 3.816301212220647\n",
      "loss= 7.452857447551806\n",
      "loss= 1.1639592800321183\n",
      "loss= 1.1693747253866267\n",
      "loss= 51.42560951366166\n",
      "loss= 4.788030026727549\n",
      "loss= 18.386651186787017\n",
      "loss= 1.6862068917224113\n",
      "loss= 5.915933814345524\n",
      "loss= 5.80623618027213\n",
      "loss= 1.51604716250122\n",
      "loss= 7.348207280149496\n",
      "loss= 3.584895053169972\n",
      "loss= 1.3211432501775058\n",
      "loss= 1.398372883268324\n",
      "loss= 3.154172644748529\n",
      "loss= 1.8994221830746716\n",
      "loss= 5.774090152812296\n",
      "loss= 1.6426698539896072\n",
      "loss= 3.107914102020306\n",
      "loss= 1.1176975689025268\n",
      "loss= 8.763390692163043\n",
      "loss= 2.381352188973878\n",
      "loss= 130.90303298059365\n",
      "loss= 25.141566149630687\n",
      "loss= 173.2970504853029\n",
      "loss= 57.24054530256895\n",
      "loss= 12.367163138651772\n",
      "loss= 32.30460510217663\n",
      "loss= 1.7104713920771804\n",
      "loss= 1.9350771742458786\n",
      "loss= 2.152993214810334\n",
      "loss= 4.800885741803607\n",
      "loss= 1.2192567052991756\n",
      "loss= 1.160374727341505\n",
      "loss= 10.164547249993872\n",
      "loss= 17.912372460521404\n",
      "loss= 8.59190061620985\n",
      "loss= 10.117483506431007\n",
      "loss= 10.778900776259821\n",
      "loss= 2.3191399003948425\n",
      "loss= 1.0454413272309602\n",
      "loss= 2.3735963363205266\n",
      "loss= 1.0895479524093712\n",
      "loss= 2.2305996231837817\n",
      "loss= 6.8394626708238375\n",
      "loss= 1.4394591152792182\n",
      "loss= 7.808367530038978\n",
      "loss= 14.856837411910384\n",
      "loss= 3.7175137365664086\n",
      "loss= 12.224437087341338\n",
      "loss= 2.343955105118204\n",
      "loss= 43.726640142096244\n",
      "loss= 50.492530914808384\n",
      "loss= 1.5165013556942992\n",
      "loss= 2.8921057362610214\n",
      "loss= 2.4553077409932027\n",
      "loss= 5.091691907994524\n",
      "loss= 3.5851857275788066\n",
      "loss= 4.461647390078313\n",
      "loss= 1.5716465265080528\n",
      "loss= 19.549484470538705\n",
      "loss= 3.6274234682163096\n",
      "loss= 12.953297988799978\n",
      "loss= 6.2574627775207246\n",
      "loss= 1.1956080352636438\n",
      "loss= 1.7914606337475283\n",
      "loss= 2.9333463831108317\n",
      "loss= 13.443171660872107\n",
      "loss= 1.0147050596318719\n",
      "loss= 12.532874773128919\n",
      "loss= 1.8009477842975719\n",
      "loss= 1.808193609360298\n",
      "loss= 110.18685664679724\n",
      "loss= 9.124789194143437\n",
      "loss= 15.274677748393255\n",
      "loss= 1.8575775800625105\n",
      "loss= 0.8462639352605366\n",
      "loss= 2.0424193699216846\n",
      "loss= 1.1110571880891256\n",
      "loss= 11.963889350508753\n",
      "loss= 0.7492246838241047\n",
      "loss= 6.424658534321105\n",
      "loss= 16.030413881647085\n",
      "loss= 86.12756050331787\n",
      "loss= 1.3069997554128832\n",
      "loss= 6.758352119918464\n",
      "loss= 6.347070351093347\n",
      "loss= 3.989152264158237\n",
      "loss= 1.580444984512021\n",
      "loss= 1.5694780726182336\n",
      "loss= 59.58900585824162\n",
      "loss= 0.6138644029277016\n",
      "loss= 1.5359037729572278\n",
      "loss= 47.56449053847433\n",
      "loss= 0.8241907208379063\n",
      "loss= 7.669790855170875\n",
      "loss= 2.5723333323181214\n",
      "loss= 10.481197221817144\n",
      "loss= 0.71695737138315\n",
      "loss= 0.8552806067171593\n",
      "loss= 0.9781584155087553\n",
      "loss= 1.9412170452037762\n",
      "loss= 2.255881658785149\n",
      "loss= 11.985400675819681\n",
      "loss= 2.5040665271964033\n",
      "loss= 8.34369907637157\n",
      "loss= 0.6111514454293008\n",
      "loss= 3.5965498551886586\n",
      "loss= 4.610108042612445\n",
      "loss= 1.7330613481303094\n",
      "loss= 1.0834842538086524\n",
      "loss= 1.1038172277539262\n",
      "loss= 1.1291512591531296\n",
      "loss= 2.538066468478698\n",
      "loss= 2.6601950758383346\n",
      "loss= 79.7251947145819\n",
      "loss= 1.098667501211803\n",
      "loss= 1.6313922479043832\n",
      "loss= 17.921083681545376\n",
      "loss= 2.114828852683768\n",
      "loss= 1.5896899041692714\n",
      "loss= 0.8353288856215071\n",
      "loss= 1.194256697443663\n",
      "loss= 0.6891874105533781\n",
      "loss= 1.5122970254544967\n",
      "loss= 11.690056419979568\n",
      "loss= 0.5942912029390747\n",
      "loss= 2.491991213304943\n",
      "loss= 5.527822841702803\n",
      "loss= 10.037787024101378\n",
      "loss= 2.365481316721367\n",
      "loss= 87.15109509015036\n",
      "loss= 1.474877449604582\n",
      "loss= 2.533444030116858\n",
      "loss= 1.764369371052012\n",
      "loss= 1.631833246728272\n",
      "loss= 16.08965181782944\n",
      "loss= 21.965180007044076\n",
      "loss= 0.933984045158321\n",
      "loss= 7.649487676034878\n",
      "loss= 19.488713427582898\n",
      "loss= 1.9677240979198949\n",
      "loss= 88.46092862197176\n",
      "loss= 1.6221101838838738\n",
      "loss= 4.33334779952604\n",
      "loss= 7.3700782956292805\n",
      "loss= 8.028486512423799\n",
      "loss= 28.184767620791586\n",
      "loss= 2.1507693886756543\n",
      "loss= 0.7905542005232261\n",
      "loss= 0.6565046561631249\n",
      "loss= 3.186531363462403\n",
      "loss= 20.491220442019667\n",
      "loss= 8.161145614655213\n",
      "loss= 2.3794375748958156\n",
      "loss= 0.7018174573852461\n",
      "loss= 6.675887153127603\n",
      "loss= 2.1384396239296994\n",
      "loss= 0.9329054135868017\n",
      "loss= 1.2103401349699827\n",
      "loss= 3.4139411231446286\n",
      "loss= 23.901466514292053\n",
      "loss= 2.4396743913982832\n",
      "loss= 1.8263212761299932\n",
      "loss= 7.590642766665489\n",
      "loss= 7.496664249915342\n",
      "loss= 3.2673769364809186\n",
      "loss= 7.381157574719104\n",
      "loss= 2.2394284658816925\n",
      "loss= 6.784502990796176\n",
      "loss= 5.003061673923924\n",
      "loss= 7.898346640475014\n",
      "loss= 4.657204531322283\n",
      "loss= 11.505282400019397\n",
      "loss= 23.944501572830998\n",
      "loss= 4.286797626037795\n",
      "loss= 5.04065186725858\n",
      "loss= 1.7530149649771678\n",
      "loss= 6.934071686531732\n",
      "loss= 5.822064589542659\n",
      "loss= 4.205076035132405\n",
      "loss= 93.96685521328959\n",
      "loss= 1.165457076839249\n",
      "loss= 5.558926712840223\n",
      "loss= 1.1702459691551554\n",
      "loss= 12.323418446829368\n",
      "loss= 2.6470647703019115\n",
      "loss= 0.8489370516293171\n",
      "loss= 5.826118219258396\n",
      "loss= 3.707664515769395\n",
      "loss= 2.053126453295494\n",
      "loss= 34.85327353185644\n",
      "loss= 23.043991132233792\n",
      "loss= 6.420935324714287\n",
      "loss= 0.9296387222588678\n",
      "loss= 6.413722718830019\n",
      "loss= 2.2510232351693973\n",
      "loss= 57.760475894624285\n",
      "loss= 10.425805283022708\n",
      "loss= 1.1493583006688979\n",
      "loss= 7.40923207450469\n",
      "loss= 1.4314874833946554\n",
      "loss= 1.2992586093604566\n",
      "loss= 1.858134359537855\n",
      "loss= 34.07252314565623\n",
      "loss= 18.835307556025658\n",
      "loss= 2.920927319135115\n",
      "loss= 16.719843039495103\n",
      "loss= 20.419424690781426\n",
      "loss= 1.9697531738643486\n",
      "loss= 1.621536235545268\n",
      "loss= 5.709334408157314\n",
      "loss= 2.146380495822711\n",
      "loss= 1.4460593311154204\n",
      "loss= 2.040272518676712\n",
      "loss= 15.377974990083983\n",
      "loss= 4.487286434941243\n",
      "loss= 19.197699141682374\n",
      "loss= 11.006824122289846\n",
      "loss= 5.35517299360268\n",
      "loss= 3.3792419351052136\n",
      "loss= 2.072695163441789\n",
      "loss= 5.274502995446773\n",
      "loss= 1.26051526273667\n",
      "loss= 3.1349177359934335\n",
      "loss= 24.21130365120505\n",
      "loss= 10.858645015330104\n",
      "loss= 5.584678747373846\n",
      "loss= 0.7980013946746553\n",
      "loss= 19.95922021280797\n",
      "loss= 1.5655219645945009\n",
      "loss= 1.074564816464176\n",
      "loss= 1.2657619272167853\n",
      "loss= 1.511738713582328\n",
      "loss= 11.763750560427448\n",
      "loss= 2.439718387188587\n",
      "loss= 4.095754463996491\n",
      "loss= 1.6265886148046045\n",
      "loss= 2.633200947121839\n",
      "loss= 3.8725419515455552\n",
      "loss= 2.8781561812243788\n",
      "loss= 1.4196712383005516\n",
      "loss= 31.52346503262843\n",
      "loss= 19.049556851863553\n",
      "loss= 5.365047702038113\n",
      "loss= 5.780476438727798\n",
      "loss= 12.898991223930318\n",
      "loss= 2.7601153321559186\n",
      "loss= 1.7495146803419146\n",
      "loss= 0.763555796292916\n",
      "loss= 12.01207053481559\n",
      "loss= 9.177728688845542\n",
      "loss= 6.424470848588201\n",
      "loss= 2.0673814890264848\n",
      "loss= 3.4196187883040126\n",
      "loss= 1.3006630991387647\n",
      "loss= 6.290937908559396\n",
      "loss= 4.695638491063961\n",
      "loss= 2.2635255687560476\n",
      "loss= 0.7539730244951371\n",
      "loss= 4.180368982907688\n",
      "loss= 20.126749929183422\n",
      "loss= 2.065269525709011\n",
      "loss= 7.557435109325603\n",
      "loss= 3.222077393490147\n",
      "loss= 13.110289346375867\n",
      "loss= 2.4659962247350213\n",
      "loss= 10.211753654689174\n",
      "loss= 1.3446448677041851\n",
      "loss= 6.7844858078739225\n",
      "loss= 2.0420894074444895\n",
      "loss= 12.672746328253096\n",
      "loss= 0.7680112706908425\n",
      "loss= 1.387791617398712\n",
      "loss= 50.95400084926102\n",
      "loss= 5.848407584850442\n",
      "loss= 1.8575973068328044\n",
      "loss= 2.8880395080906514\n",
      "loss= 0.8948529368663917\n",
      "loss= 27.558984088958535\n",
      "loss= 2.491856135166159\n",
      "loss= 1.0710138333865378\n",
      "loss= 0.8189968561985589\n",
      "loss= 85.03734420265721\n",
      "loss= 6.097165024150583\n",
      "loss= 0.8597227799313505\n",
      "loss= 2.775701653054795\n",
      "loss= 0.6592602392774508\n",
      "loss= 2.0615916451614718\n",
      "loss= 7.173280372619273\n",
      "loss= 2.766020481121334\n",
      "loss= 1.77028337321737\n",
      "loss= 14.641763635143066\n",
      "loss= 4.591589792920219\n",
      "loss= 6.37280977011045\n",
      "loss= 2.0005395992662365\n",
      "loss= 1.4997139106563504\n",
      "loss= 3.2760121629527785\n",
      "loss= 62.47996411127407\n",
      "loss= 2.2583958533114354\n",
      "loss= 5.246372086156908\n",
      "loss= 3.3427472944838112\n",
      "loss= 2.9680806445538614\n",
      "loss= 1.6576785438202655\n",
      "loss= 22.382265317890756\n",
      "loss= 7.587519784675181\n",
      "loss= 1.2048191627154217\n",
      "loss= 10.365868194770918\n",
      "loss= 5.0405789915451\n",
      "loss= 27.363547710227998\n",
      "loss= 8.468881258664021\n",
      "loss= 6.857262867019638\n",
      "loss= 2.3000694568415048\n",
      "loss= 2.087098254776568\n",
      "loss= 1.1933302427971029\n",
      "loss= 1.7679613065203785\n",
      "loss= 1.384372659662101\n",
      "loss= 1.2004895802046909\n",
      "loss= 5.035731138610445\n",
      "loss= 175.9128080644602\n",
      "loss= 61.53837064147113\n",
      "loss= 154.9241663931968\n",
      "loss= 45.4809891056092\n",
      "loss= 67.30000867690315\n",
      "loss= 2.012394054280272\n",
      "loss= 1.642172567498398\n",
      "loss= 4.994245392750612\n",
      "loss= 21.609445383811234\n",
      "loss= 35.635876847208394\n",
      "loss= 1.237277641575722\n",
      "loss= 1.417157866694771\n",
      "loss= 0.9239057359155998\n",
      "loss= 14.094046198013762\n",
      "loss= 5.423377727983703\n",
      "loss= 2.2631327645961083\n",
      "loss= 17.79024416265772\n",
      "loss= 4.492498343730363\n",
      "loss= 11.139635227545016\n",
      "loss= 5.110096456660036\n",
      "loss= 1.384277457905084\n",
      "loss= 1.294523656414486\n",
      "loss= 3.171598844233676\n",
      "loss= 8.89940454083799\n",
      "loss= 5.131689008838329\n",
      "loss= 8.441570133300797\n",
      "loss= 8.938204650255674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5317787d00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = torch.zeros(d, requires_grad=True)\n",
    "alpha = 1e-1\n",
    "beta = 0.999\n",
    "\n",
    "data = torch.utils.data.TensorDataset(tA, tb)\n",
    "BS = 50\n",
    "trainloader = torch.utils.data.DataLoader(data, batch_size=BS, shuffle=True)\n",
    "\n",
    "loss=fun(tA,w,tb)\n",
    "grad_f, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "hist_grad=[]\n",
    "hist_loss=[]\n",
    "# Ds = []\n",
    "# for j in range(100):\n",
    "#     z = rademacher(train_data.shape[1]).to(device=device)\n",
    "#     hvp = torch.autograd.grad(g,  w,  grad_outputs = z, retain_graph = True)[0]\n",
    "#     Ds.append( (hvp*z) ) \n",
    "\n",
    "# Dk = torch.mean(torch.stack(Ds), 0)\n",
    "\n",
    "Dk = diag_estimate1(d, grad_f, w, 100)\n",
    "print(Dk.shape)\n",
    "for step in range(1000):\n",
    "    loss=fun(tA,w,tb)\n",
    "    print('loss=',loss.item())\n",
    "    hist_loss.append(loss.item())    \n",
    "    grad_f, = torch.autograd.grad(loss, w, create_graph=True) \n",
    "\n",
    "    # print(f\"Loss: {loss.item()} | GradNorm^2: {(torch.linalg.norm(g) ** 2).item()}\")\n",
    "\n",
    "    \n",
    "    for i,(xx,yy) in enumerate (trainloader):\n",
    "        #print('loss=',lgstc(X,y,w).item())\n",
    "        loss = fun(xx,w,yy)\n",
    "\n",
    "        grad_f, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "            \n",
    "        #print(f\"Loss: {loss.item()} | GradNorm^2: {(torch.linalg.norm(g) ** 2).item()}\")\n",
    "\n",
    "        # if i%1 == 0: print(f\"Accuracy: {np.mean(trainX.dot(w.cpu().data.numpy())*trainY > 0)}\")\n",
    "\n",
    "        vk = diag_estimate1(d, grad_f, w, 1)\n",
    "\n",
    "        # print(vk)\n",
    "\n",
    "        # Smoothing and Truncation        \n",
    "        Dk = beta * Dk + (1 - beta) * vk\n",
    "        Dk_hat = torch.abs(Dk)\n",
    "        Dk_hat[Dk_hat < alpha] = alpha\n",
    "\n",
    "\n",
    "        Dk_hat_inv = 1 / Dk_hat\n",
    "        # print(torch.norm(Dk_hat_inv).item(), torch.norm(w).item() , torch.norm(g).item() , loss.item() )\n",
    "        gnorm = ((grad_f * Dk_hat_inv).flatten()).dot(grad_f)\n",
    "        #print(gnorm)\n",
    "        if gnorm.item() < 1e-13:\n",
    "            continue\n",
    "        precond = (loss / (gnorm ** 2)) * Dk_hat_inv\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            w.sub_((precond * grad_f).flatten())\n",
    "    hist_grad.append((torch.norm(grad_f) ** 2).item())\n",
    "\n",
    "fig,(ax1,ax2) = plt.subplots(1,2);fig.set_size_inches(20, 6)\n",
    "ax1.semilogy(torch.tensor(hist_grad),label='grad')\n",
    "ax1.semilogy(torch.tensor(hist_loss),label='loss')\n",
    "ax1.title.set_text('Loss & Grad')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 14248.9342353893\n",
      "302512458734428.06 -1646234370498277.2 -3249782373.99776 -1604.3646054466094\n",
      "coeffienct (A=2.710090551908828e+30,B=5.349907808777133e+24, C=2.6376050094551685e+18)\n",
      "DET= 9.639966415723925e+45\n",
      "v= 5.441874938196126\n",
      "155720989401103.75 -895409602731140.6 -1770507513.8095438 -871.3802580840764\n",
      "coeffienct (A=8.017591837786845e+29,B=1.5853306508024665e+24, C=7.939701042995871e+17)\n",
      "DET= -1.1006006232628226e+46\n",
      "v1= -1.0546164663796396e-06\n",
      "v2= 5.7500913273434415\n",
      "v3= -9.227653354046495e-07\n",
      "v1v2v3= 5.595779101040698e-12\n",
      "v= 5.7500913273434415\n",
      "24715427809280.418 -243150426719086.28 -466721745.4792404 -223.69816342298375\n",
      "coeffienct (A=5.912216461935657e+28,B=1.1348364133151637e+23, C=5.465227602546566e+16)\n",
      "DET= -1.5368863380044546e+43\n",
      "v1= -1.008604450707629e-06\n",
      "v2= 9.838003858807708\n",
      "v3= -9.121503255305013e-07\n",
      "v1v2v3= 9.050952512300319e-12\n",
      "v= 9.838003858807708\n",
      "23702792390733.78 -146479340651688.56 -302707582.1664569 -155.32872456095376\n",
      "coeffienct (A=2.145621876279835e+28,B=4.434044018153004e+22, C=2.337453282719349e+16)\n",
      "DET= -1.3347241260685053e+43\n",
      "v1= -1.1182693631677533e-06\n",
      "v2= 6.179836840323462\n",
      "v3= -9.482630489291604e-07\n",
      "v1v2v3= 6.553182511174379e-12\n",
      "v= 6.179836840323462\n",
      "8776410841541.883 -61852698538029.266 -124742368.74907951 -62.7401830519462\n",
      "coeffienct (A=3.8257596008071606e+27,B=7.715657084859102e+21, C=3918709675532924.0)\n",
      "DET= -1.4560013488252053e+41\n",
      "v1= -1.057888136036583e-06\n",
      "v2= 7.047609478947168\n",
      "v3= -9.588424624356116e-07\n",
      "v1v2v3= 7.148729040233e-12\n",
      "v= 7.047609478947168\n",
      "2817997176268.557 -22791503550428.8 -45008311.81648011 -22.261888415147453\n",
      "coeffienct (A=5.194530145890954e+26,B=1.0258076631695612e+21, C=503602406010254.0)\n",
      "DET= 1.963403330667745e+39\n",
      "v= 8.087839585966057\n",
      "2287290527325.7764 -12885106551249.139 -25413834.439979035 -12.261957697810269\n",
      "coeffienct (A=1.6602614522351178e+26,B=3.274602170548721e+20, C=171873086553079.8)\n",
      "DET= -2.3038367862251328e+39\n",
      "v1= -1.129758825686861e-06\n",
      "v2= 5.633351298678938\n",
      "v3= -8.423370520709272e-07\n",
      "v1v2v3= 5.360909578962205e-12\n",
      "v= 5.633351298678938\n",
      "460699219990.6152 -3754897547207.286 -7571882.51588662 -3.801410696366806\n",
      "coeffienct (A=1.4099266055104401e+25,B=2.843165884840689e+19, C=14511681735243.695)\n",
      "DET= -3.352340632202146e+36\n",
      "v1= -1.0655198615662355e-06\n",
      "v2= 8.150433760881404\n",
      "v3= -9.501344033778262e-07\n",
      "v1v2v3= 8.2513938192564e-12\n",
      "v= 8.150433760881404\n",
      "222998244503.22174 -1677438728873.8403 -3261757.4026492583 -1.5721100509818682\n",
      "coeffienct (A=2.8138028712244097e+24,B=5.471401346594845e+18, C=2727706497030.796)\n",
      "DET= -2.5489359909700947e+35\n",
      "v1= -1.0637640061661025e-06\n",
      "v2= 7.52220792691781\n",
      "v3= -8.810303611500278e-07\n",
      "v1v2v3= 7.04987635433675e-12\n",
      "v= 7.52220792691781\n",
      "158493600002.1053 -939806486961.3381 -1840168.9202142563 -0.8920050075493707\n",
      "coeffienct (A=8.832371078996021e+23,B=1.729403960715763e+18, C=871285377431.8135)\n",
      "DET= -2.9122749444329554e+34\n",
      "v1= -1.0752068200604913e-06\n",
      "v2= 5.9296198539495455\n",
      "v3= -8.827479144224308e-07\n",
      "v1v2v3= 5.628019096906892e-12\n",
      "v= 5.9296198539495455\n",
      "67959361652.94852 -424433562308.46716 -840486.9340951575 -0.41684117449564617\n",
      "coeffienct (A=1.8014402017072203e+23,B=3.567311184660708e+17, C=175654132560.58038)\n",
      "DET= 2.28308161932787e+32\n",
      "v= 6.245404408782087\n",
      "38442321412.157425 -251950178476.18387 -503913.0316452492 -0.2517255965299045\n",
      "coeffienct (A=6.347895054894108e+22,B=1.2696106535174205e+17, C=63661416543.706055)\n",
      "DET= -1.5175845121507984e+31\n",
      "v1= -1.0325789064265724e-06\n",
      "v2= 6.553981292166801\n",
      "v3= -9.67585445005612e-07\n",
      "v1v2v3= 6.5481372425728705e-12\n",
      "v= 6.553981292166801\n",
      "18393288602.331146 -108291603831.21255 -217151.9870902082 -0.10788494633244503\n",
      "coeffienct (A=1.1727083442753797e+22,B=2.351575481636399e+16, C=12105883894.47165)\n",
      "DET= -4.958705910562374e+30\n",
      "v1= -1.0981358896337202e-06\n",
      "v2= 5.887562743981657\n",
      "v3= -9.072141818479112e-07\n",
      "v1v2v3= 5.8654517234493785e-12\n",
      "v= 5.887562743981657\n",
      "8638334455.91891 -54129519928.59933 -106661.32115136158 -0.051665816807223874\n",
      "coeffienct (A=2.9300076918291285e+21,B=5773530125632810.0, C=2986699848.2719326)\n",
      "DET= -5.56854667632342e+29\n",
      "v1= -1.1110298851732205e-06\n",
      "v2= 6.26620064626011\n",
      "v3= -8.590990657708352e-07\n",
      "v1v2v3= 5.9809928720487226e-12\n",
      "v= 6.26620064626011\n",
      "4276338490.524726 -26511997996.81398 -53289.10502833547 -0.02697068219593889\n",
      "coeffienct (A=7.028867214298215e+20,B=1412801683785137.2, C=694588697.6666539)\n",
      "DET= 1.4379969308541284e+28\n",
      "v= 6.199697860914036\n",
      "660482440.2190709 -6289919304.236459 -12624.961497878256 -0.006286085825991132\n",
      "coeffienct (A=3.956310986950259e+19,B=79410026407390.23, C=40772735.06794195)\n",
      "DET= -4.881083155667416e+25\n",
      "v1= -1.0899486570167938e-06\n",
      "v2= 9.523221583079582\n",
      "v3= -9.169150483452865e-07\n",
      "v1v2v3= 9.517415518126635e-12\n",
      "v= 9.523221583079582\n",
      "292831034.63138145 -2694660810.7230854 -5482.320215849217 -0.0027429608919058\n",
      "coeffienct (A=7.261201701027298e+18,B=14773000666500.494, C=7881787.2868152)\n",
      "DET= -3.561146774735808e+24\n",
      "v1= -1.1438138258580332e-06\n",
      "v2= 9.20210321929626\n",
      "v3= -8.899386560261595e-07\n",
      "v1v2v3= 9.367042995830911e-12\n",
      "v= 9.20210321929626\n",
      "67324057.93728681 -703467886.1724325 -1434.251160968599 -0.0007300479264797596\n",
      "coeffienct (A=4.948673565547353e+17,B=1008950074795.0377, C=516380.5778039221)\n",
      "DET= -1.393104209074314e+21\n",
      "v1= -3.4829961211117704\n",
      "v2= 6.965989183979561\n",
      "v3= -4.469359612235972e-13\n",
      "v1v2v3= 1.084378970679112e-11\n",
      "v= 6.965989183979561\n",
      "70068991.600216 -588139979.9859388 -1190.8104270440872 -0.0005992800586180854\n",
      "coeffienct (A=3.459088863745179e+17,B=700363598647.3013, C=360647.7881120823)\n",
      "DET= -2.831976242312129e+21\n",
      "v1= -1.0921870229434114e-06\n",
      "v2= 8.393728929491166\n",
      "v3= -9.329363337998362e-07\n",
      "v1v2v3= 8.552714188286365e-12\n",
      "v= 8.393728929491166\n",
      "59124913.72319699 -378190025.14442235 -738.4220214864566 -0.00035748372093842806\n",
      "coeffienct (A=1.4302782609615374e+17,B=279264033098.90564, C=139676.74958486768)\n",
      "DET= -6.407490715117462e+20\n",
      "v1= -1.0642291840458307e-06\n",
      "v2= 6.396459914635763\n",
      "v3= -8.882002740515545e-07\n",
      "v1v2v3= 6.046245117786504e-12\n",
      "v= 6.396459914635763\n",
      "loss= 0.0011563096946412437\n",
      "11753593.721945684 -99020379.77779879 -194.36296210446392 -9.33397307273235e-05\n",
      "coeffienct (A=9805042464729376.0,B=19245904196.017387, C=10049.354283090132)\n",
      "DET= -7.910851210985144e+18\n",
      "v1= -1.1243598775534884e-06\n",
      "v2= 8.424691646738363\n",
      "v3= -8.383715173611893e-07\n",
      "v1v2v3= 7.941378010458582e-12\n",
      "v= 8.424691646738363\n",
      "6515273.312441142 -57945982.71481074 -117.2035645367798 -5.926054712324996e-05\n",
      "coeffienct (A=3357739203624913.0,B=6791479199.650396, C=3434.943622304896)\n",
      "DET= -3463244044689408.0\n",
      "v1= -2.9646247859989114\n",
      "v2= 5.929246538046053\n",
      "v3= -5.174444986573768e-13\n",
      "v1v2v3= 9.095634869237161e-12\n",
      "v= 5.929246538046053\n",
      "5989806.329153972 -44750973.208319664 -89.36828856699066 -4.46623535236393e-05\n",
      "coeffienct (A=2002651208987965.8,B=3999320295.00441, C=1990.6396435222623)\n",
      "DET= 1.6111755665743872e+16\n",
      "v= 7.4711906714287695\n",
      "1359516.5020964383 -12506626.343170982 -26.43152644565133 -1.3921849532894646e-05\n",
      "coeffienct (A=156415810289987.5,B=330569395.278261, C=176.27947990587722)\n",
      "DET= -338488551088736.0\n",
      "v1= -1.115690803801676e-06\n",
      "v2= 9.199321374245386\n",
      "v3= -9.9772948725947e-07\n",
      "v1v2v3= 1.0240294627852256e-11\n",
      "v= 9.199321374245386\n",
      "1431888.1401342184 -9380252.366663076 -19.25201583097082 -9.831997160600988e-06\n",
      "coeffienct (A=87989217162487.66,B=180588893.7663802, C=93.96026965169489)\n",
      "DET= -152537910783524.0\n",
      "v1= -1.0964913260264339e-06\n",
      "v2= 6.550969340795144\n",
      "v3= -9.559207417504273e-07\n",
      "v1v2v3= 6.8664561742088195e-12\n",
      "v= 6.550969340795144\n",
      "919576.7785317835 -6029919.4497459 -11.926098216361195 -5.8965879204170145e-06\n",
      "coeffienct (A=36359961471312.836,B=71913460.39570418, C=35.563968100915844)\n",
      "DET= -290751193560.0\n",
      "v1= -1.0077145264187452e-06\n",
      "v2= 6.557278749612168\n",
      "v3= -9.70401854201981e-07\n",
      "v1v2v3= 6.412284496604663e-12\n",
      "v= 6.557278749612168\n",
      "272697.0060925963 -1879785.6719492527 -4.155028439248438 -2.2836136404376953e-06\n",
      "coeffienct (A=3533597571657.1504,B=7810568.531252306, C=4.386148726275353)\n",
      "DET= -330185723662.0\n",
      "v1= -1.18669272614904e-06\n",
      "v2= 6.8933146778775\n",
      "v3= -1.023707473503466e-06\n",
      "v1v2v3= 8.374179361772229e-12\n",
      "v= 6.8933146778775\n",
      "127543.93133470569 -910676.1680600314 -1.8146870428425341 -8.970340773733469e-07\n",
      "coeffienct (A=829331777429.4612,B=1652593.2721053038, C=0.8423663948557056)\n",
      "DET= -21113451654.134277\n",
      "v1= -1.0832120641868565e-06\n",
      "v2= 7.140099985035798\n",
      "v3= -9.093506065118398e-07\n",
      "v1v2v3= 7.033138056716439e-12\n",
      "v= 7.140099985035798\n",
      "73821.8880765079 -537364.6598621298 -1.0586577145457774 -5.078488510628378e-07\n",
      "coeffienct (A=288761012125.0764,B=568885.5801005608, C=0.30205608122902305)\n",
      "DET= -8419091896.852112\n",
      "v1= -1.1440234563563973e-06\n",
      "v2= 7.2792070116261485\n",
      "v3= -8.260956328741463e-07\n",
      "v1v2v3= 6.879380415419758e-12\n",
      "v= 7.2792070116261485\n",
      "17727.324125332983 -126226.58087196597 -0.27031611241715797 -1.4494795101850734e-07\n",
      "coeffienct (A=15933164094.570988,B=34121.10175087362, C=0.018181947847935448)\n",
      "DET= 1821916.737707138\n",
      "v= 7.12045528940857\n",
      "11563.690676598175 -88807.90073701924 -0.18666267558665792 -9.687010882767369e-08\n",
      "coeffienct (A=7886849708.844586,B=16577.13044639011, C=0.009034461429713005)\n",
      "DET= -3404168.049788296\n",
      "v1= -1.1695370036426156e-06\n",
      "v2= 7.679894553225471\n",
      "v3= -9.326616024925213e-07\n",
      "v1v2v3= 8.37709270654506e-12\n",
      "v= 7.679894553225471\n",
      "5053.334927838131 -35657.47685276443 -0.07583650346466307 -3.9885932878628284e-08\n",
      "coeffienct (A=1271456805.1871862,B=2704.140180898612, C=0.0014844800726340436)\n",
      "DET= -79145.01470363699\n",
      "v1= -1.1760680273590808e-06\n",
      "v2= 7.05622882896367\n",
      "v3= -9.511227524171406e-07\n",
      "v1v2v3= 7.892992142456685e-12\n",
      "v= 7.05622882896367\n",
      "1120.331072523152 -11854.249839400636 -0.0243864731403513 -1.247283524478017e-08\n",
      "coeffienct (A=140523321.21770084,B=289.0834710709013, C=0.0001511317566331576)\n",
      "DET= -460.29742927524785\n",
      "v1= -1.1088774936941442e-06\n",
      "v2= 10.581025943910827\n",
      "v3= -9.488716173618745e-07\n",
      "v1v2v3= 1.1133169070004896e-11\n",
      "v= 10.581025943910827\n",
      "1181.525832265501 -8246.993867570915 -0.017909342162126494 -9.713997275386353e-09\n",
      "coeffienct (A=68012971.33280347,B=147.69833827933488, C=8.041070880098619e-05)\n",
      "DET= -20.361933216896432\n",
      "v1= -1.1141178550466301e-06\n",
      "v2= 6.979954401490413\n",
      "v3= -1.057233792805285e-06\n",
      "v1v2v3= 8.221569948039458e-12\n",
      "v= 6.979954401490413\n",
      "706.846492105532 -3967.978738117018 -0.008460226203411421 -4.510879599708148e-09\n",
      "coeffienct (A=15744873.206392366,B=33.570026391291776, C=1.787820438734601e-05)\n",
      "DET= 0.32880898836742745\n",
      "v= 5.613637882508108\n",
      "248.60407674187675 -1657.6291551396218 -0.003353316086995152 -1.6655936226685186e-09\n",
      "coeffienct (A=2747736.916913046,B=5.55855823886216, C=2.9619191306506e-06)\n",
      "DET= -0.5522428219920705\n",
      "v1= -1.1480327897185648e-06\n",
      "v2= 6.667749297516559\n",
      "v3= -8.752401833539485e-07\n",
      "v1v2v3= 6.6997840280708214e-12\n",
      "v= 6.667749297516559\n",
      "144.7091492741194 -903.8265911629874 -0.0019112972842955057 -1.0123409445383302e-09\n",
      "coeffienct (A=816903.336639918,B=1.7274826276188537, C=9.081153139649816e-07)\n",
      "DET= 0.005608836199246348\n",
      "v= 6.245817225165744\n",
      "57.70991770252156 -307.7255150869843 -0.0006701925529553276 -3.5932455171676514e-10\n",
      "coeffienct (A=94695.10866582101,B=0.20623553519495194, C=1.1743805975545574e-07)\n",
      "DET= -0.0006500477810120059\n",
      "v1= -1.2231278590336318e-06\n",
      "v2= 5.332283479575919\n",
      "v3= -9.546657668965116e-07\n",
      "v1v2v3= 6.2263916848570536e-12\n",
      "v= 5.332283479575919\n",
      "18.59233663191667 -121.03649053823564 -0.0002523273645436459 -1.3052807101662736e-10\n",
      "coeffienct (A=14649.846115878316,B=0.03054084051252146, C=1.627311999980748e-08)\n",
      "DET= -6.950625359444383e-06\n",
      "v1= -1.1357054018424674e-06\n",
      "v2= 6.510022472930621\n",
      "v3= -9.495585893497007e-07\n",
      "v1v2v3= 7.020530748811605e-12\n",
      "v= 6.510022472930621\n",
      "5.274884307406708 -37.79205396438793 -7.798387149708901e-05 -3.969481597646752e-11\n",
      "coeffienct (A=1428.2405769149095,B=0.002947172564439939, C=1.5810383312071654e-09)\n",
      "DET= -1.1552875618804948e-07\n",
      "v1= -1.1497767826171302e-06\n",
      "v2= 7.164529617462759\n",
      "v3= -9.135233173565764e-07\n",
      "v1v2v3= 7.525248643032833e-12\n",
      "v= 7.164529617462759\n",
      "loss= 3.1126468309027985e-10\n",
      "1.949689425783663 -16.370481716421615 -3.852511830087282e-05 -2.2470070018448748e-11\n",
      "coeffienct (A=267.9928969637417,B=0.0006306751390543396, C=3.8064712888505996e-10)\n",
      "DET= -3.4305920473804307e-09\n",
      "v1= -1.2870067350456518e-06\n",
      "v2= 8.39645847599548\n",
      "v3= -1.0665028620681113e-06\n",
      "v1v2v3= 1.1524948395007614e-11\n",
      "v= 8.39645847599548\n",
      "2.792900247150668 -18.382050720672677 -3.974064599040116e-05 -2.1151007261719334e-11\n",
      "coeffienct (A=337.9001216723629,B=0.0007305151019217321, C=4.129222788996652e-10)\n",
      "DET= -8.151212996661985e-09\n",
      "v1= -1.214426413534803e-06\n",
      "v2= 6.581709023610934\n",
      "v3= -9.474706096580855e-07\n",
      "v1v2v3= 7.573133799997946e-12\n",
      "v= 6.581709023610934\n",
      "2.117159373370681 -12.453669347694213 -2.6152873428640648e-05 -1.3717594286167334e-11\n",
      "coeffienct (A=155.09404633110174,B=0.0003256994995533884, C=1.7146963811725584e-10)\n",
      "DET= -9.850532827067345e-11\n",
      "v1= -1.0792239432488385e-06\n",
      "v2= 5.8822561732464305\n",
      "v3= -1.0206313315838546e-06\n",
      "v1v2v3= 6.479245000969324e-12\n",
      "v= 5.8822561732464305\n",
      "0.39497939467857135 -3.3369715068097023 -7.424650081853679e-06 -4.125001812203604e-12\n",
      "coeffienct (A=11.135387635011199,B=2.477586043479452e-05, C=1.3830388299384397e-11)\n",
      "DET= -7.278930470193231e-13\n",
      "v1= -1.1467465499009866e-06\n",
      "v2= 8.448472073691496\n",
      "v3= -1.0779635816728159e-06\n",
      "v1v2v3= 1.0443587356146696e-11\n",
      "v= 8.448472073691496\n",
      "0.37135457489682033 -2.539417613146642 -5.60384272540545e-06 -3.0263109102888036e-12\n",
      "coeffienct (A=6.448648056997288,B=1.4230507032707896e-05, C=8.34785160574387e-12)\n",
      "DET= -4.274032580659622e-12\n",
      "v1= -1.2626860313598355e-06\n",
      "v2= 6.838258107729573\n",
      "v3= -9.438085337891019e-07\n",
      "v1v2v3= 8.149383674967932e-12\n",
      "v= 6.838258107729573\n",
      "0.10487397788903244 -0.8145883587011903 -1.775124585685084e-06 -9.3313429476233e-13\n",
      "coeffienct (A=0.6635547526246287,B=1.4459967034968913e-06, C=8.707062938489233e-13)\n",
      "DET= -7.337957705688071e-14\n",
      "v1= -1.2925143616573745e-06\n",
      "v2= 7.7673089515212155\n",
      "v3= -8.862789866558556e-07\n",
      "v1v2v3= 8.89767236396509e-12\n",
      "v= 7.7673089515212155\n",
      "0.04410459451253045 -0.3847996757970357 -8.33399092043886e-07 -4.464636603369939e-13\n",
      "coeffienct (A=0.14807090076369087,B=3.2069187764791956e-07, C=1.7915683136107414e-13)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.04109019072013966 -0.298189875295799 -6.255834296507966e-07 -3.255273880492355e-13\n",
      "coeffienct (A=0.08891727884495147,B=1.865427652585314e-07, C=1.0014771371034712e-13)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.019105255075124953 -0.10766980827657106 -2.3779395526760192e-07 -1.3140911002821188e-13\n",
      "coeffienct (A=0.011592801243656083,B=2.5603252168431312e-08, C=1.4099584114213052e-14)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.008805851926634193 -0.051840867782263995 -1.0782033891091937e-07 -5.5030121357372194e-14\n",
      "coeffienct (A=0.0026874784207679943,B=5.589504295003766e-09, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.0027160557805783383 -0.019883811896928637 -4.358928182139175e-08 -2.3771221141988078e-14\n",
      "coeffienct (A=0.0003953663307252034,B=8.667216615344278e-10, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.001438041178393945 -0.009599007418646402 -2.2185146514920596e-08 -1.2819662646690342e-14\n",
      "coeffienct (A=9.214103913269137e-05,B=2.129555518973052e-10, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.0007162896457216206 -0.0050902326793890226 -1.0863786092255199e-08 -5.792310649502171e-15\n",
      "coeffienct (A=2.591049207517242e-05,B=5.529923632943867e-11, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.0003426570232146476 -0.001807267098468549 -4.0622400187467555e-09 -2.283149051549121e-15\n",
      "coeffienct (A=3.266218541072145e-06,B=7.341559772996792e-12, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.0204292562055543e-05 -0.0001568924594874976 -3.442622517636847e-10 -1.8791064787192052e-16\n",
      "coeffienct (A=2.4615264710761837e-08,B=5.4012185557323956e-14, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.5910997364658406e-05 -9.32202621126882e-05 -2.0568196352067006e-10 -1.1375586350949106e-16\n",
      "coeffienct (A=8.690027086173827e-09,B=1.9173742840972435e-14, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.14171836805011e-06 -3.5257074399811756e-05 -7.22604430027607e-11 -3.696106317998166e-17\n",
      "coeffienct (A=1.2430624098624027e-09,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.0170448789922465e-06 -1.2316872761291589e-05 -2.6428435975784234e-11 -1.4177053585945584e-17\n",
      "coeffienct (A=1.5170551453987103e-10,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.532754169394894e-07 -3.51430802821388e-06 -7.707893959093766e-12 -4.2316404259594954e-18\n",
      "coeffienct (A=1.235037371093326e-11,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.1135531978590005e-07 -2.7106576717130874e-06 -5.828381850813543e-12 -3.111662239946714e-18\n",
      "coeffienct (A=7.347672205824655e-12,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "loss= 1.159668954332682e-17\n",
      "1.6788472927392542e-07 -1.125148967293592e-06 -2.515182914796086e-12 -1.4050890907506536e-18\n",
      "coeffienct (A=1.2659614653842451e-12,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.7357909375826464e-08 -3.3246765814101387e-07 -7.240600205405748e-13 -3.944583696513342e-19\n",
      "coeffienct (A=1.1053482485787596e-13,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.518156369993277e-08 -2.9535857814808804e-07 -6.501092772979679e-13 -3.579683144118546e-19\n",
      "coeffienct (A=8.723679730779972e-14,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.801114205128679e-09 -4.6433178004564945e-08 -1.1013803587264297e-13 -6.463205733917016e-20\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.7027757950870666e-09 -2.4402608237574548e-08 -5.503264525181712e-14 -3.0492531358165215e-20\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.171364434307601e-09 -2.5657949499110026e-08 -5.6156590341214766e-14 -3.015672827605639e-20\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.528202039036176e-10 -4.3305115888476464e-09 -1.0031581088082254e-14 -5.803224000604373e-21\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.94864227703757e-10 -1.9084201513641217e-09 -4.245442489541694e-15 -2.3603190030676085e-21\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.4698313631630132e-10 -1.2036916300193234e-09 -2.7761292678443837e-15 -1.6005494168900585e-21\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.946109947226425e-11 -5.629721079952139e-10 -1.2628913720004983e-15 -7.092774867050291e-22\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.7926588104267363e-11 -2.8221972411640505e-10 -6.405596829898238e-16 -3.635347907663048e-22\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.5257083225038848e-11 -1.0510819059380789e-10 -2.4099242965308126e-16 -1.3825680040231178e-22\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.960704558484541e-12 -4.118228697548944e-11 -9.669162916496432e-17 -5.677725126432551e-23\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.1185769264498613e-12 -1.4126283932807852e-11 -3.1552251086523884e-17 -1.770826795329758e-23\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "8.80955158358332e-13 -6.5654720938844274e-12 -1.446364529081598e-17 -7.963506341520679e-24\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "7.35894014206005e-13 -4.67800365013887e-12 -1.0780323731723985e-17 -6.213545429893605e-24\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.347183924175531e-13 -1.5295402410481976e-12 -3.4244282390716608e-18 -1.9036814044544482e-24\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.541821205829033e-14 -4.885219260130785e-13 -1.0756988485439065e-18 -5.896827957683427e-25\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.402632967226403e-14 -2.1093202396702888e-13 -4.606688239473817e-19 -2.517972272426901e-25\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.538946076562995e-15 -5.5257594334363144e-14 -1.271132960228602e-19 -7.386918168392843e-26\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "loss= 3.8203580997865915e-25\n",
      "3.4974308835624284e-15 -2.6741603894169068e-14 -6.239443879161427e-20 -3.542599296834218e-26\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.536881277709204e-15 -1.3651924464487654e-14 -3.098185179917322e-20 -1.7323631997686298e-26\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.1290862280137126e-15 -8.160940098045038e-15 -1.967228616248648e-20 -1.1707694235562984e-26\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.03815535863097e-16 -2.7676254859952167e-15 -6.116894302758289e-21 -3.339864509382746e-27\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.3009478969777396e-16 -1.1100748726876174e-15 -2.508095201824217e-21 -1.414402951157986e-27\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.886553053717022e-17 -5.297195481559764e-16 -1.225506203560302e-21 -7.057470132849918e-28\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.0053522128874614e-17 -3.8637798829792945e-16 -8.706291605239941e-22 -4.875776691848056e-28\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.908671095444988e-17 -2.1310499079473202e-16 -5.223530206592643e-22 -3.1411455169769164e-28\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.470034371210939e-17 -1.0815495616018084e-16 -2.5460732103732686e-22 -1.4974798652390736e-28\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.531678550410344e-18 -7.229957002357099e-17 -1.7322726065414103e-22 -1.0358729761683411e-28\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.573594296991909e-18 -4.9975600671262117e-17 -1.1691479725795212e-22 -6.838437972134646e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.0263520139520992e-18 -2.7240851596515945e-17 -6.493963108275267e-23 -3.8419991274592096e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.8287085407848394e-18 -3.329455508948884e-17 -7.6165962065616e-23 -4.3116178850985926e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.7078750394964658e-18 -2.4463839247351455e-17 -6.218407254537085e-23 -3.935676359954205e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.2478497534548186e-18 -1.6228876923548706e-17 -3.9308119707028793e-23 -2.3715130963206667e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.169215146027231e-18 -1.6025074313623023e-17 -3.647097722286205e-23 -2.0732250665339714e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "9.872745206240144e-19 -1.6916613938880053e-17 -3.955141649709819e-23 -2.3172789090867225e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "8.95579179765858e-19 -1.505806788573747e-17 -3.471146233388486e-23 -1.9992693566695015e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.1322911955392498e-18 -1.3333583973698305e-17 -3.132112281449678e-23 -1.8402645804608913e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "9.172008890607336e-19 -9.034716036754892e-18 -2.2185678123564598e-23 -1.3620176566706532e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "loss= 1.4600706019992961e-28\n",
      "8.398047672024631e-19 -9.784509667029353e-18 -2.306988189392291e-23 -1.3620176566706532e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.764507518544542e-19 -1.0486972012325176e-17 -2.4643229736162505e-23 -1.4495319133436095e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "9.38796127841882e-19 -1.4378563703431003e-17 -3.3896449207649356e-23 -1.9968041663406864e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "8.208481679760869e-19 -1.030695863416713e-17 -2.4081809471500317e-23 -1.4051584874249276e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.3175406224311044e-19 -5.203394480204225e-18 -1.2348735905917112e-23 -7.296963373294358e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.5002896836896774e-19 -4.7766202307261584e-18 -1.193580984836936e-23 -7.444874793023299e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "9.707460431498677e-20 -2.331809156241112e-18 -5.833848534102162e-24 -3.660807638291258e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.159387947449439e-19 -4.556440366556719e-18 -1.0662292836957245e-23 -6.2246055802595456e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.950771812645309e-19 -5.81669121087061e-18 -1.3901612060937198e-23 -8.258387601532467e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.76110867056621e-19 -3.2315182625456664e-18 -7.657292036575587e-24 -4.535950205020817e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.6346379755015315e-19 -4.176235795465283e-18 -1.0785267850693678e-23 -6.964162678904245e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.223174784805635e-19 -2.2970239805188508e-18 -5.671606885992087e-24 -3.50057026691824e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.6424796642237378e-19 -2.7223250642858023e-18 -6.6695159995053e-24 -4.055238090901764e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.222126176928344e-20 -1.4376336564402574e-18 -3.5578575656274284e-24 -2.194019392645939e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.343761439114391e-21 -1.9343749132613782e-19 -4.784006698881348e-25 -2.958228394578794e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.2910694884595585e-20 -7.742064738375655e-19 -2.0662981531303735e-24 -1.3805065841367708e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.006956836220255e-20 -1.079436152222889e-18 -2.769857709989516e-24 -1.7749370367472766e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.953216440420269e-20 -2.9381131815587544e-18 -6.979262591818163e-24 -4.141519752410312e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "8.88165544617218e-21 -1.6666727741945718e-19 -4.052842720127261e-25 -2.4651903288156623e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.7867128404418475e-20 -6.467870982970595e-19 -1.5984195511082547e-24 -9.86076131526265e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "loss= 0.0\n",
      "4.0546974091981e-20 -6.391678248595912e-19 -1.5881626282789973e-24 -9.86076131526265e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.51718554000956e-20 -1.2187641907303957e-18 -2.9918213877917692e-24 -1.8365667949676678e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.1054569272384236e-21 -1.2246272045709637e-19 -3.108038941656434e-25 -1.9721522630525295e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.274332973194023e-21 -1.2943781520860719e-19 -3.198756070827487e-25 -1.9721522630525295e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.2873346822425694e-20 -7.933046981394679e-19 -1.9800079944575477e-24 -1.232595164407831e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.777196543862827e-20 -1.1510449803232274e-18 -2.8994235285262287e-24 -1.8242408433235894e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.0 0.0 0.0 -0.0\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.0997773031659893e-21 -2.938560727286818e-20 -7.611102181419052e-26 -4.930380657631324e-32\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.0 0.0 0.0 -0.0\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.23091086572517e-20 -1.1948544337742214e-18 -2.9125629243809306e-24 -1.7749370367472766e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.0429695540992419e-19 -1.7240638686252798e-18 -4.373169551586784e-24 -2.7610131682735413e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.518226536175209e-21 -1.270718940123676e-19 -3.1679362213854154e-25 -1.9721522630525295e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "8.738908808834744e-20 -2.056383709245651e-18 -5.1386229803899696e-24 -3.20474742746036e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.194513546525838e-20 -2.0413232315653817e-18 -5.386780953316133e-24 -3.5498740734945524e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.0 0.0 0.0 -0.0\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.3875633951380203e-20 -5.010718013723588e-19 -1.2578813457474371e-24 -7.888609052210118e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.783467101222726e-21 -1.1547537075808618e-19 -3.017630787112226e-25 -1.9721522630525295e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.2820755902810974e-20 -5.432482677213718e-19 -1.3092677312331314e-24 -7.888609052210118e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.8177592648879936e-20 -5.905943832537486e-19 -1.526172801007747e-24 -9.86076131526265e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.9540143120182195e-20 -6.175409332439728e-19 -1.5638452017414011e-24 -9.86076131526265e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "loss= 0.0\n",
      "1.4763219011293787e-21 -3.3065975037111637e-20 -8.079399413031895e-26 -4.930380657631324e-32\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "7.452946528843675e-20 -1.9512165622487896e-18 -4.97386073761797e-24 -3.1554436208840472e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.1465267221566308e-21 -3.023719596735839e-20 -7.724948267673277e-26 -4.930380657631324e-32\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.7143546692797484e-21 -1.1540122312251436e-19 -3.017073999800542e-25 -1.9721522630525295e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.0 0.0 0.0 -0.0\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.123537642238661e-20 -2.296955905273886e-19 -6.027146956348209e-25 -3.94430452610506e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "0.0 0.0 0.0 -0.0\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.7406815430863205e-21 -1.2142182255390917e-19 -3.097726701933998e-25 -1.9721522630525295e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.6621301220595714e-20 -4.744363976088603e-19 -1.2226592502668141e-24 -7.888609052210118e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.469494738603415e-20 -2.4895514733695504e-18 -6.2658977606143004e-24 -3.94430452610506e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.844814322060585e-21 -1.4841232391042897e-19 -3.8248745183030597e-25 -2.4651903288156623e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.215330701962801e-19 -2.4564836576927233e-18 -6.750241045116353e-24 -4.634557818173445e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.6535262326900653e-20 -6.576760092029235e-19 -1.6129611546275956e-24 -9.86076131526265e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.3406066254475009e-19 -2.785236498305746e-18 -6.983774818111602e-24 -4.3757128336478006e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.0206331900826009e-19 -2.2257658017155195e-18 -5.8887470755670875e-24 -3.895000719528746e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.634364356734553e-20 -5.682899357401604e-19 -1.5062620692976319e-24 -9.98402083170343e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.173976937509479e-20 -9.999068647759111e-19 -2.5151613588131894e-24 -1.577721810442024e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.760932058936023e-21 -1.1393284150418443e-19 -2.998017563333303e-25 -1.9721522630525295e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.091581985261529e-20 -1.0714744265795459e-18 -2.7582161827489898e-24 -1.7749370367472766e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.9472990049840924e-20 -1.0338864317243887e-18 -2.7116955761071916e-24 -1.7749370367472766e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "loss= 1.0433918066712289e-29\n",
      "1.6419061192605844e-20 -3.918989497766422e-19 -1.0402677532582264e-24 -6.902532920683853e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.3404565456173604e-19 -1.8407799187358016e-18 -4.856565079290314e-24 -3.20474742746036e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.1245512963209445e-20 -9.242854299890239e-19 -2.4623606898966712e-24 -1.6393515686624155e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.26445627325841e-19 -4.103277783096634e-18 -1.098120665497308e-23 -7.346267179870671e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.3683178504161565e-19 -1.6228663329819838e-18 -4.3187930111237645e-24 -2.8719467330702458e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "8.07918903740139e-20 -2.4305083972890664e-18 -6.237662932001245e-24 -4.0059342843254506e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.1329434496450972e-19 -2.5060577876698076e-18 -6.327415014034984e-24 -3.993608332681372e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "8.38278436430396e-20 -1.3103630935518143e-18 -3.410256227659729e-24 -2.218671295934096e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.1304047163835765e-19 -4.156775968160981e-18 -1.1054473903974174e-23 -7.346267179870671e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.0418210106372847e-19 -1.512929975765898e-18 -4.2315266255990514e-24 -2.9582283945787946e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.1980523779551617e-19 -2.43002249662481e-18 -6.783283793167966e-24 -4.73316543132607e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "7.837949416804648e-20 -1.2305771919656119e-18 -3.304572722988193e-24 -2.218671295934096e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.132193172285777e-19 -2.676645772888907e-18 -7.374729589992403e-24 -5.0782920773602635e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.641651841329838e-19 -6.9286974265373656e-18 -1.8459375616715972e-23 -1.2301299740790153e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.9836845351621907e-19 -6.489637485419681e-18 -1.7898662609587575e-23 -1.2338277595722389e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.8799196905489164e-19 -5.568752963836521e-18 -1.5358663779225432e-23 -1.0600318413907346e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.008248323865446e-19 -2.2016420488155258e-18 -6.038342721597171e-24 -4.141519752410312e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.68194777163443e-20 -1.3812667727728117e-18 -3.798820034815444e-24 -2.6131017485446016e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "7.991280067474936e-20 -1.2957664042221492e-18 -3.5415451728150764e-24 -2.4158865222393487e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.4263500922819526e-20 -5.574886652717053e-19 -1.4829093349406795e-24 -9.86076131526265e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "loss= 1.5752566201132082e-29\n",
      "4.555396879740661e-20 -6.345234780695511e-19 -1.7763127865214697e-24 -1.2449211160519093e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "8.776522057132596e-20 -1.524732688810047e-18 -4.1917961866314e-24 -2.8719467330702458e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.780607551020654e-20 -9.055345726216827e-19 -2.536383089900389e-24 -1.7749370367472766e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "7.244417162723828e-20 -2.224355776230179e-18 -6.075656166563125e-24 -4.141519752410312e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "8.829118714158021e-21 -1.3284802248537943e-19 -3.6195602996198766e-25 -2.4651903288156623e-31\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "9.972378116192335e-20 -1.1959097575984567e-18 -3.326845281225005e-24 -2.3172789090867222e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.0906628723637532e-19 -2.7534356645247248e-18 -7.814525673832207e-24 -5.522026336547083e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.951456779935776e-19 -5.024068587742199e-18 -1.3404354024255723e-23 -8.936314941956774e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "6.578963953271552e-20 -9.146381291404434e-19 -2.4954208663779225e-24 -1.7009813268828067e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.2784532061769455e-19 -6.103466668182331e-18 -1.7204938951890122e-23 -1.2128736417773058e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "2.8461136572656503e-19 -5.23200038450798e-18 -1.4734469849856792e-23 -1.0378451284313937e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.8636973995136052e-19 -4.3341490126133365e-18 -1.2039543544591455e-23 -8.344669263041017e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.8908832577273073e-19 -2.885286658669693e-18 -8.438261494571169e-24 -6.1629758220391554e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "1.0953317636154879e-19 -1.2407315674420002e-18 -3.637850084037654e-24 -2.662405555120915e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "5.597073561469287e-20 -1.1767023542000183e-18 -3.34677406896525e-24 -2.3789086673071134e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.2915990695407836e-19 -3.3705711256668406e-18 -9.429321641237237e-24 -6.582058177937819e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.173384914093721e-19 -4.494662193336157e-18 -1.2608650950382268e-23 -8.837707328804148e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "3.4698839077584184e-19 -5.01043268126722e-18 -1.4098803255685667e-23 -9.910065121838961e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.846020702327655e-19 -4.737086958566551e-18 -1.3614188748283486e-23 -9.762153702110021e-30\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n",
      "4.978126080307976e-19 -7.798337661743085e-18 -2.209182117539779e-23 -1.5641632636335375e-29\n",
      "coeffienct (A=0,B=0, C=0)\n",
      "DET= 0\n",
      "v= 7.7673089515212155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_532296/1343726560.py:113: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  v1= -cc/bb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f53175a8280>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sk = torch.ones(d,1)\n",
    "w = torch.zeros(d, requires_grad=True)\n",
    "#w1 = torch.zeros(d,1).double()\n",
    "fvalN = []\n",
    "data = torch.utils.data.TensorDataset(tA, tb)\n",
    "BS = 50\n",
    "trainloader = torch.utils.data.DataLoader(data, batch_size=BS, shuffle=True)\n",
    "#H = d2lgstc(X,y,np.array(w1),lmd)\n",
    "#H1=torch.diag(H,0)\n",
    "#print(H1)\n",
    "loss = fun(tA,w,tb)\n",
    "grad_f, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "\n",
    "#print(torch.norm(Dk-H1))\n",
    "alpha = 1e-4\n",
    "beta = 0.999\n",
    "v=torch.zeros(1,requires_grad=True)\n",
    "gamma=0.01\n",
    "hist_d=[]\n",
    "hist_gap=[]\n",
    "hist_grad=[]\n",
    "hist_gradd=[]\n",
    "hist_loss=[]\n",
    "Dk = diag_estimate1(d, grad_f, w, 100)\n",
    "Dk_hat = torch.abs(Dk)\n",
    "Dk_hat[Dk_hat < alpha] = alpha\n",
    "D=torch.diagflat(Dk_hat)\n",
    "\n",
    "\n",
    "#print(B)\n",
    "for it in range(10):\n",
    "    loss=fun(tA,w,tb)\n",
    "    print('loss=',loss.item())\n",
    "    hist_loss.append(loss.item())    \n",
    "    grad_f, = torch.autograd.grad(loss, w, create_graph=True) \n",
    "    hist_d.append((torch.norm(grad_f)**2).item())\n",
    "    #hist_grad.append(grad_f)  \n",
    "    \n",
    "    \n",
    "    #print('prime=',0.5*torch.dot(dk,D@dk))\n",
    "    #print('dual=',-g_v(v,loss.item(),grad_f,B,D))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,(xx,yy) in enumerate (trainloader):\n",
    "        # print('loss=',fun(tA,w,tb).item())\n",
    "        loss = fun(xx,w,yy)\n",
    "        # print('sampleloss=',loss.item())\n",
    "        # hist_loss.append(loss.item())   \n",
    "        grad_f, = torch.autograd.grad(loss, w, create_graph=True) \n",
    "        #print(grad_f)\n",
    "        hist_gradd.append(grad_f)\n",
    "        \n",
    "# generate random vector sk from unit sphere\n",
    "        sk= torch.randn(d,1)\n",
    "        sk=sk/sk.norm()\n",
    "\n",
    "        vk = diag_estimate1(d, grad_f, w, 1)\n",
    "        Dk = beta * Dk + (1 - beta) * vk\n",
    "        Dk_hat = torch.abs(Dk)\n",
    "        Dk_hat[Dk_hat < alpha] = alpha\n",
    "\n",
    "        D=torch.diagflat(Dk_hat)\n",
    "        \n",
    "        yk=D@sk\n",
    "        B=yk.T*yk/sk.T*yk\n",
    "        \n",
    "        # \n",
    "        # D=torch.diagflat(Dk_hat)\n",
    "\n",
    "        # print(Dk_hat)\n",
    "        # print(torch.norm(Dk_hat-H1))\n",
    "        \n",
    "        # this is much faster for find the lagrangian multiplier\n",
    "        #st=time.time()\n",
    "        D_inv=torch.linalg.inv(D)\n",
    "        a=torch.dot(grad_f,D_inv@grad_f)\n",
    "        a=a.detach().numpy()\n",
    "        b=torch.dot(grad_f,D_inv@B@D_inv@grad_f)\n",
    "        b=b.detach().numpy()\n",
    "        c=torch.trace(B@D_inv)\n",
    "        c=c.detach().numpy()\n",
    "\n",
    "        aa=2*a*c**2\n",
    "        bb=4*a*c-2*c**2*loss.item()-b*c\n",
    "        cc=2*a-2*b-4*c*loss.item()\n",
    "        dd=-2*loss.item()\n",
    "\n",
    "        print(aa,bb,cc,dd)\n",
    "        # print('-d/a=', -d/a)\n",
    "        AA=bb*bb-3*aa*cc\n",
    "        if abs(AA) < 1e-14: AA=0\n",
    "        BB=bb*cc-9*aa*dd\n",
    "        if abs(BB) < 1e-14: BB=0\n",
    "        CC=cc*cc-3*bb*dd\n",
    "        if abs(CC) < 1e-14: CC=0\n",
    "        DET=-18*aa*bb*cc*dd+4*bb**3*dd+4*aa*cc**3+27*aa**2*dd**2-bb**2*cc**2\n",
    "        print(\"coeffienct (A={},B={}, C={})\".format(AA,BB,CC))\n",
    "        if abs(DET)< 1e-14:\n",
    "            DET=0\n",
    "        print('DET=',DET)\n",
    "        # print('det=',-18*a*b*c*d+4*b**3*d+4*a*c**3+27*a**2*d**2-b**2*c**2)\n",
    "        third = 1./3.\n",
    "        sqr3 = math.sqrt(3)\n",
    "        if DET>0:\n",
    "            Y1=np.cbrt(AA*bb+1.5*aa*(-BB+math.sqrt(DET)))\n",
    "            Y2=np.cbrt(AA*bb+1.5*aa*(-BB-math.sqrt(DET)))\n",
    "            v=(-bb-Y1-Y2)/(3*aa)\n",
    "        \n",
    "        elif DET==0:\n",
    "            if (AA==0)&(BB==0):\n",
    "                v1= -cc/bb\n",
    "                v2 = v1\n",
    "                v3 = v1\n",
    "                \n",
    "            if (AA!=0)&(BB!=0):\n",
    "                K=(bb*cc-9*aa*dd)/(bb*bb-3*aa*cc)\n",
    "                K=round(K,14)\n",
    "                v1= -bb/aa + K\n",
    "                v2= -0.5*K\n",
    "                v3=v2\n",
    "            \n",
    "        elif DET<0:\n",
    "            sqA=math.sqrt(AA)\n",
    "            T=(AA*bb-1.5*aa*BB)/(AA**(3/2))\n",
    "            # print('T=',T)\n",
    "            if -1< T <1 : \n",
    "                T=T\n",
    "            else:\n",
    "                T=1\n",
    "            # print('T=',T)\n",
    "            theta=math.acos(T)\n",
    "            csth=math.cos(theta/3)\n",
    "            snth=sqr3*math.sin(theta/3)\n",
    "            v1=(-bb-2*sqA*csth)/(3*aa)\n",
    "            v2=(-bb+sqA*(csth+snth))/(3*aa)\n",
    "            v3=-dd/aa/v1/v2\n",
    "            print('v1=',v1)\n",
    "            print('v2=',v2)\n",
    "            print('v3=',v3)\n",
    "            print('v1v2v3=',v1*v2*v3)\n",
    "            v1=np.max([v1,v2,v3])\n",
    "            v3=np.min([v1,v2,v3])\n",
    "            #v1=torch.tensor(v1,dtype=torch.float64)\n",
    "            #v3=torch.tensor(v3,dtype=torch.float64)\n",
    "            if v3<0:\n",
    "                v=v1\n",
    "            else:\n",
    "                if g_v(v1,loss.item(),grad_f,B,D)>g_v(v3,loss.item(),grad_f,B,D):\n",
    "                    print('gv1=',g_v(v1,loss.item(),grad_f,B,D))\n",
    "                    print('gv3=',g_v(v3,loss.item(),grad_f,B,D))\n",
    "                    v=v3\n",
    "                else:\n",
    "                    v=v1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #p=np.array([a,b,c,d])\n",
    "        #p=np.array([2*c*2 ,(4*a-2*c*2*loss.item()-b)/a,(2*a-2*b-4*c*loss.item())/a*c,(-2*loss.item())/a*c ])\n",
    "\n",
    "        #p=np.array([1 ,(4*a*c-b*c-2*c**2*loss.item())/2*a*c**2, (2*a-2*b-4*c*loss.item())/2*a*c**2, -loss.item()/a*c**2 ])\n",
    "        #p=np.array([a ,(4*a*c-b*c-2*c**2*loss.item())/2*c**2, (2*a-2*b-4*c*loss.item())/2*c**2, -loss.item()/c**2 ])\n",
    "\n",
    "        #print(p)\n",
    "        #roots = fqs.cubic_roots(p)\n",
    "        #print(roots)\n",
    "        #print('time=:', time.time() - st)\n",
    "\n",
    "        #arg=torch.argmin(torch.tensor([g_v(torch.tensor(roots[0][0].real),loss.item(),grad_f,B,D),g_v(torch.tensor(roots[0][1].real),loss.item(),grad_f,B,D),g_v(torch.tensor(roots[0][2].real),loss.item(),grad_f,B,D)]))\n",
    "        #print('arg=',arg)\n",
    "        \n",
    "        \n",
    "        #v=roots[0][0].real\n",
    "        print('v=',v)\n",
    "        #print('prime=', -g_v(v,loss.item(),grad_f,B,D))\n",
    "        \n",
    "        D_inv=torch.linalg.inv(D)\n",
    "        dk=v*(D_inv-1/(1+v*torch.trace(B@D_inv))*(D_inv@B@D_inv))@grad_f\n",
    "        w=w-dk\n",
    "        #hist_g.append(0.5*torch.dot(dk,D@dk))\n",
    "        \n",
    "        #print('dual=',0.5*torch.dot(dk,D@dk))\n",
    "        #print(-g_v(v,loss.item(),grad_f,B,D))\n",
    "        hist_gap.append(0.5*torch.dot(dk,D@dk)+g_v(v,loss.item(),grad_f,B,D))\n",
    "\n",
    "fig,(ax1,ax2) = plt.subplots(1,2);fig.set_size_inches(20, 6)\n",
    "ax1.semilogy(torch.tensor(hist_d),label='grad')\n",
    "ax1.semilogy(torch.tensor(hist_loss),label='loss')\n",
    "ax1.title.set_text('Loss & Grad')\n",
    "ax1.legend()\n",
    "ax2.plot(torch.tensor(hist_gap),label='gap')\n",
    "ax2.title.set_text('dual gap')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1644,  0.2248, -3.5159,  0.4204, -0.3749,  0.3374, -0.4104,  0.2001,\n",
       "         0.3023, -1.1248, -1.4284, -0.6655,  1.1863, -0.5691,  0.7205, -1.6708,\n",
       "        -0.8384,  1.5804, -0.7533, -0.6955], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5135e-32, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm((w-xopt)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import mpmath\n",
    "sys.modules['sympy.mpmath'] = mpmath\n",
    "import sympy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "from datasets import get_dataset\n",
    "\n",
    "from loss_fns import get_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_reg(w, X, y):\n",
    "    return torch.mean(torch.log(1 + torch.exp(-y * (X @ w))))\n",
    "\n",
    "def nllsq(w, X, y):\n",
    "    return torch.mean( ( y - (1/(1 + torch.exp(-X @ w ))) )**2 )\n",
    "\n",
    "def rademacher_old(weights):\n",
    "    return torch.round(torch.rand_like(weights)) * 2 - 1\n",
    "\n",
    "def diag_estimate_old(weights, grad, iters):\n",
    "    Ds = []\n",
    "    for j in range(iters):\n",
    "        z = rademacher_old(weights)\n",
    "        with torch.no_grad():\n",
    "            hvp = torch.autograd.grad(grad, weights, grad_outputs=z, retain_graph=True)[0]\n",
    "        Ds.append((hvp*z))\n",
    "\n",
    "    return torch.mean(torch.stack(Ds), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUBIC ROOT SOLVER\n",
    "\n",
    "# Date Created   :    24.05.2017\n",
    "# Created by     :    Shril Kumar [(shril.iitdhn@gmail.com),(github.com/shril)] &\n",
    "#                     Devojoyti Halder [(devjyoti.itachi@gmail.com),(github.com/devojoyti)]\n",
    "\n",
    "# Project        :    Classified \n",
    "# Use Case       :    Instead of using standard numpy.roots() method for finding roots,\n",
    "#                     we have implemented our own algorithm which is ~10x faster than\n",
    "#                     in-built method.\n",
    "\n",
    "# Algorithm Link :    www.1728.org/cubic2.htm\n",
    "\n",
    "# This script (Cubic Equation Solver) is an independent program for computation of roots of Cubic Polynomials. This script, however,\n",
    "# has no relation with original project code or calculations. It is to be also made clear that no knowledge of it's original project \n",
    "# is included or used to device this script. This script is complete freeware developed by above signed users, and may further be\n",
    "# used or modified for commercial or non-commercial purpose.\n",
    "\n",
    "\n",
    "# Libraries imported for fast mathematical computations.\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Main Function takes in the coefficient of the Cubic Polynomial\n",
    "# as parameters and it returns the roots in form of numpy array.\n",
    "# Polynomial Structure -> ax^3 + bx^2 + cx + d = 0\n",
    "\n",
    "def solve(a, b, c, d):\n",
    "\n",
    "    if (a == 0 and b == 0):                     # Case for handling Liner Equation\n",
    "        return np.array([(-d * 1.0) / c])                 # Returning linear root as numpy array.\n",
    "\n",
    "    elif (a == 0):                              # Case for handling Quadratic Equations\n",
    "\n",
    "        D = c * c - 4.0 * b * d                       # Helper Temporary Variable\n",
    "        if D >= 0:\n",
    "            D = math.sqrt(D)\n",
    "            x1 = (-c + D) / (2.0 * b)\n",
    "            x2 = (-c - D) / (2.0 * b)\n",
    "        else:\n",
    "            D = math.sqrt(-D)\n",
    "            x1 = (-c + D * 1j) / (2.0 * b)\n",
    "            x2 = (-c - D * 1j) / (2.0 * b)\n",
    "            \n",
    "        return np.array([x1, x2])               # Returning Quadratic Roots as numpy array.\n",
    "\n",
    "    f = findF(a, b, c)                          # Helper Temporary Variable\n",
    "    g = findG(a, b, c, d)                       # Helper Temporary Variable\n",
    "    h = findH(g, f)                             # Helper Temporary Variable\n",
    "\n",
    "    if f == 0 and g == 0 and h == 0:            # All 3 Roots are Real and Equal\n",
    "        if (d / a) >= 0:\n",
    "            x = (d / (1.0 * a)) ** (1 / 3.0) * -1\n",
    "        else:\n",
    "            x = (-d / (1.0 * a)) ** (1 / 3.0)\n",
    "\n",
    "        return np.array([x, x, x])              # Returning Equal Roots as numpy array.\n",
    "\n",
    "    elif h <= 0:                                # All 3 roots are Real\n",
    "\n",
    "        i = math.sqrt(((g ** 2.0) / 4.0) - h)   # Helper Temporary Variable\n",
    "        j = i ** (1 / 3.0)                      # Helper Temporary Variable\n",
    "        k = math.acos(-(g / (2 * i)))           # Helper Temporary Variable\n",
    "        L = j * -1                              # Helper Temporary Variable\n",
    "        M = math.cos(k / 3.0)                   # Helper Temporary Variable\n",
    "        N = math.sqrt(3) * math.sin(k / 3.0)    # Helper Temporary Variable\n",
    "        P = (b / (3.0 * a)) * -1                # Helper Temporary Variable\n",
    "\n",
    "        x1 = 2 * j * math.cos(k / 3.0) - (b / (3.0 * a))\n",
    "        x2 = L * (M + N) + P\n",
    "        x3 = L * (M - N) + P\n",
    "\n",
    "        return np.array([x1, x2, x3])           # Returning Real Roots as numpy array.\n",
    "\n",
    "    elif h > 0:                                 # One Real Root and two Complex Roots\n",
    "        R = -(g / 2.0) + math.sqrt(h)           # Helper Temporary Variable\n",
    "        if R >= 0:\n",
    "            S = R ** (1 / 3.0)                  # Helper Temporary Variable\n",
    "        else:\n",
    "            S = (-R) ** (1 / 3.0) * -1          # Helper Temporary Variable\n",
    "        T = -(g / 2.0) - math.sqrt(h)\n",
    "        if T >= 0:\n",
    "            U = (T ** (1 / 3.0))                # Helper Temporary Variable\n",
    "        else:\n",
    "            U = ((-T) ** (1 / 3.0)) * -1        # Helper Temporary Variable\n",
    "\n",
    "        x1 = (S + U) - (b / (3.0 * a))\n",
    "        x2 = -(S + U) / 2 - (b / (3.0 * a)) + (S - U) * math.sqrt(3) * 0.5j\n",
    "        x3 = -(S + U) / 2 - (b / (3.0 * a)) - (S - U) * math.sqrt(3) * 0.5j\n",
    "\n",
    "        # return np.array([x1, x2, x3])           # Returning One Real Root and two Complex Roots as numpy array.\n",
    "        return np.array([x1, 0, 0])\n",
    "\n",
    "\n",
    "# Helper function to return float value of f.\n",
    "def findF(a, b, c):\n",
    "    return ((3.0 * c / a) - ((b ** 2.0) / (a ** 2.0))) / 3.0\n",
    "\n",
    "\n",
    "# Helper function to return float value of g.\n",
    "def findG(a, b, c, d):\n",
    "    return (((2.0 * (b ** 3.0)) / (a ** 3.0)) - ((9.0 * b * c) / (a **2.0)) + (27.0 * d / a)) /27.0\n",
    "\n",
    "\n",
    "# Helper function to return float value of h.\n",
    "def findH(g, f):\n",
    "    return ((g ** 2.0) / 4.0 + (f ** 3.0) / 27.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\min \\frac{1}{2} \\| w - w^t \\|^2_D \\\\ \n",
    "s.t. \\quad f_i + \\langle \\nabla f_i, w - w^t \\rangle + \\frac{1}{2} \\langle B(w-w^t), (w-w^t) \\rangle = 0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farshed.abdukhakimov/projects/sps2/datasets\n",
      "Loss: 0.6931471805599453 | GradNorm^2: 25.480627894208755\n",
      "Dk norm:  tensor(17.0638, device='cuda:0', dtype=torch.float64)\n",
      "g_norm_l2: 23.480871674484938\n",
      "yk norm: 662.7077438736083\n",
      "D_hat_inv: 257.8698209098789\n",
      "g_norm_D: 2562.9620529092554\n",
      "loss:  tensor(0.6931, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 23.480871674484938\n",
      "D_inv norm: 257.8698209098789\n",
      "B norm: 551.3513345936288\n",
      "a: 2562.9620529092554\n",
      "b: 6568774.484652822\n",
      "c: 2562.9620529092545\n",
      "plms: 33671039476.567455 -16818350895.372658 -13139529.08488325 -1.3862943611198906\n",
      "lmds:  [ 5.00270144e-01 -7.79937910e-04 -1.05519886e-07]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(257.8698, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(551.3513, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(128.9421, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 20.289372475039656\n",
      "yk norm: 130.82940608719318\n",
      "D_hat_inv: 257.977619394025\n",
      "g_norm_D: 1982.6427008726073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4045360/101860013.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lmd_max = torch.tensor(lmd_max, dtype=torch.float64, device=device).reshape(1)\n",
      "/tmp/ipykernel_4045360/101860013.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lmd_min = torch.tensor(lmd_min, dtype=torch.float64, device=device).reshape(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.5785, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 20.289372475039656\n",
      "D_inv norm: 257.977619394025\n",
      "B norm: 525.4859025126791\n",
      "a: 1982.6427008726073\n",
      "b: 5017793.10448088\n",
      "c: 2530.8610080234994\n",
      "plms: 25398673828.91969 -12686676806.341005 -10037477.479313642 -1.1570283265377317\n",
      "lmds:  [ 5.00291478e-01 -7.89818223e-04 -1.15287632e-07]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(257.9776, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(525.4859, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.0006, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 17.122080446842546\n",
      "yk norm: 677.56176010045\n",
      "D_hat_inv: 258.31275555479584\n",
      "g_norm_D: 1442.4879362078536\n",
      "loss:  tensor(0.5395, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 17.122080446842546\n",
      "D_inv norm: 258.31275555479584\n",
      "B norm: 409.9270482856592\n",
      "a: 1442.4879362078536\n",
      "b: 2909496.8307625838\n",
      "c: 2016.9990734281903\n",
      "plms: 11736904823.580772 -5861204181.687788 -5820461.446423227 -1.079019030751594\n",
      "lmds:  [ 5.00373523e-01 -9.90896776e-04 -1.85418377e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.3128, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(409.9270, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.1879, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 24.915241335634292\n",
      "yk norm: 2168.357386750947\n",
      "D_hat_inv: 258.3557392565013\n",
      "g_norm_D: 2938.159304398273\n",
      "loss:  tensor(0.5138, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 24.915241335634292\n",
      "D_inv norm: 258.3557392565013\n",
      "B norm: 924.210022529229\n",
      "a: 2938.159304398273\n",
      "b: 12852604.858302902\n",
      "c: 4374.373043375564\n",
      "plms: 112444176458.63605 -56190342090.78023 -25708324.07195208 -1.027652862012313\n",
      "lmds:  [ 5.00174776e-01 -4.57064049e-04 -3.99770448e-08]\n",
      "lmd_max: tensor([0.5002], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.3557, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(924.2100, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.1595, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 12.338968589906663\n",
      "yk norm: 46.01546039269657\n",
      "D_hat_inv: 258.48880325560447\n",
      "g_norm_D: 764.6132771697545\n",
      "loss:  tensor(0.3057, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 12.338968589906663\n",
      "D_inv norm: 258.4888032556045\n",
      "B norm: 425.82777240821\n",
      "a: 764.6132771697545\n",
      "b: 1635158.7979096055\n",
      "c: 2138.543557551353\n",
      "plms: 6993716625.686003 -3493113594.5479054 -3271403.1552828318 -0.6113473837666812\n",
      "lmds:  [ 5.00399340e-01 -9.34593214e-04 -1.86913493e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.4888, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(425.8278, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.2800, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 11.822763073210288\n",
      "yk norm: 96.79814675672294\n",
      "D_hat_inv: 258.57253858187977\n",
      "g_norm_D: 718.7474750538354\n",
      "loss:  tensor(0.3810, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 11.822763073210288\n",
      "D_inv norm: 258.57253858187977\n",
      "B norm: 301.4434137876131\n",
      "a: 718.7474750538354\n",
      "b: 1114090.550338664\n",
      "c: 1550.0444718156637\n",
      "plms: 3453779797.309034 -1724264172.9674227 -2229105.6495879577 -0.7619277716497154\n",
      "lmds:  [ 5.00529210e-01 -1.28911514e-03 -3.41899151e-07]\n",
      "lmd_max: tensor([0.5005], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.5725, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(301.4434, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.3565, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 29.082561778739077\n",
      "yk norm: 18.25644240167724\n",
      "D_hat_inv: 258.3593146455061\n",
      "g_norm_D: 4130.262370056762\n",
      "loss:  tensor(1.2928, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 29.082561778739077\n",
      "D_inv norm: 258.3593146455061\n",
      "B norm: 319.99678787686383\n",
      "a: 4130.262370056762\n",
      "b: 6454098.385055982\n",
      "c: 1562.636415508704\n",
      "plms: 20170818331.528793 -10065906595.08676 -12908017.233117849 -2.585690332631909\n",
      "lmds:  [ 5.00312202e-01 -1.27887196e-03 -2.00347915e-07]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.3593, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(319.9968, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.1951, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 19.313439835873083\n",
      "yk norm: 896.0223235500305\n",
      "D_hat_inv: 258.4234467316972\n",
      "g_norm_D: 1816.3242981451112\n",
      "loss:  tensor(0.4195, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 19.313439835873083\n",
      "D_inv norm: 258.4234467316972\n",
      "B norm: 715.5833833013094\n",
      "a: 1816.3242981451112\n",
      "b: 6328893.254149473\n",
      "c: 3484.451130567786\n",
      "plms: 44105438509.327934 -22037591349.94565 -12660001.362173796 -0.8390851603344132\n",
      "lmds:  [ 5.00230820e-01 -5.73747819e-04 -6.62860945e-08]\n",
      "lmd_max: tensor([0.5002], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.4234, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(715.5834, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.2080, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 10.239502011839514\n",
      "yk norm: 167.50791379819327\n",
      "D_hat_inv: 258.51052183530936\n",
      "g_norm_D: 508.16849438972963\n",
      "loss:  tensor(0.3036, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 10.239502011839514\n",
      "D_inv norm: 258.51052183530936\n",
      "B norm: 295.58049940127023\n",
      "a: 508.16849438972963\n",
      "b: 728003.6877169888\n",
      "c: 1432.6029570000474\n",
      "plms: 2085880471.460594 -1041274377.9039818 -1456730.748556033 -0.607185020222884\n",
      "lmds:  [ 5.00596455e-01 -1.39467382e-03 -4.16937744e-07]\n",
      "lmd_max: tensor([0.5006], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5006], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5006], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.5105, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(295.5805, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5006], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.3483, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 11.863576895471418\n",
      "yk norm: 488.2782389377341\n",
      "D_hat_inv: 258.6305185138452\n",
      "g_norm_D: 680.2361041859835\n",
      "loss:  tensor(0.3378, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 11.863576895471418\n",
      "D_inv norm: 258.6305185138452\n",
      "B norm: 350.24298269624893\n",
      "a: 680.2361041859835\n",
      "b: 1151482.922131528\n",
      "c: 1692.7694884843993\n",
      "plms: 3898390314.190216 -1946525086.6440713 -2303892.583929259 -0.6755827920264246\n",
      "lmds:  [ 5.00495885e-01 -1.18050753e-03 -2.93308054e-07]\n",
      "lmd_max: tensor([0.5005], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.6305, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(350.2430, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.3804, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 13.364773688557914\n",
      "yk norm: 509.71575980364037\n",
      "D_hat_inv: 258.72488198739273\n",
      "g_norm_D: 873.8387085592775\n",
      "loss:  tensor(0.3444, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 13.364773688557914\n",
      "D_inv norm: 258.72488198739273\n",
      "B norm: 434.41585751880336\n",
      "a: 873.8387085592775\n",
      "b: 1857141.5621098846\n",
      "c: 2125.268134632999\n",
      "plms: 7893847566.909378 -3942606514.197871 -3715463.356877545 -0.6888330999702605\n",
      "lmds:  [ 5.00393701e-01 -9.40431026e-04 -1.85432765e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.7249, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(434.4159, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.3992, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 14.988000574473435\n",
      "yk norm: 325.0080703462985\n",
      "D_hat_inv: 258.7150607826331\n",
      "g_norm_D: 1089.182040815219\n",
      "loss:  tensor(0.3987, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 14.988000574473435\n",
      "D_inv norm: 258.7150607826331\n",
      "B norm: 458.5416915263053\n",
      "a: 1089.182040815219\n",
      "b: 2421544.0304685207\n",
      "c: 2223.268415861934\n",
      "plms: 10767484721.119339 -5377997768.294345 -4844455.453029904 -0.7974197243110455\n",
      "lmds:  [ 5.00365660e-01 -8.99008554e-04 -1.64634707e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.7151, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(458.5417, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.3875, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 7.1904771644331955\n",
      "yk norm: 93.74660425510902\n",
      "D_hat_inv: 258.85272577685043\n",
      "g_norm_D: 254.36140945717676\n",
      "loss:  tensor(0.1918, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 7.1904771644331955\n",
      "D_inv norm: 258.85272577685043\n",
      "B norm: 244.55457130945118\n",
      "a: 254.36140945717676\n",
      "b: 306029.1585009737\n",
      "c: 1203.1273106799463\n",
      "plms: 736384076.9138471 -367523161.60718024 -612472.5884153671 -0.38358128193947505\n",
      "lmds:  [ 5.00752635e-01 -1.66033498e-03 -6.26518721e-07]\n",
      "lmd_max: tensor([0.5008], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5008], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5008], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.8527, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(244.5546, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5008], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.5565, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.918296135121485\n",
      "yk norm: 58.54433980265497\n",
      "D_hat_inv: 259.00479669117357\n",
      "g_norm_D: 41.496964206080705\n",
      "loss:  tensor(0.0635, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 2.918296135121485\n",
      "D_inv norm: 259.00479669117357\n",
      "B norm: 129.88829734574966\n",
      "a: 41.496964206080705\n",
      "b: 26262.977176872984\n",
      "c: 632.8891204293102\n",
      "plms: 33243105.050652385 -16567376.326945791 -52603.733327521106 -0.1270150623526591\n",
      "lmds:  [ 5.01525482e-01 -3.15276310e-03 -2.41640263e-06]\n",
      "lmd_max: tensor([0.5015], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5015], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5015], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.0048, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(129.8883, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5015], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.8329, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 32.688897490281384\n",
      "yk norm: 157.61927281763812\n",
      "D_hat_inv: 259.0666290184998\n",
      "g_norm_D: 5193.734094919855\n",
      "loss:  tensor(2.1861, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 32.688897490281384\n",
      "D_inv norm: 259.0666290184998\n",
      "B norm: 135.24991579643782\n",
      "a: 5193.734094919855\n",
      "b: 3414254.4118513754\n",
      "c: 657.3795172130508\n",
      "plms: 4488921833.810772 -2232693358.280047 -6823869.812751362 -4.372251559359204\n",
      "lmds:  [ 5.00416324e-01 -3.03714934e-03 -6.40863419e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.0666, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(135.2499, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.5779, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 44.089446563753306\n",
      "yk norm: 68.30017047043278\n",
      "D_hat_inv: 259.16036342556356\n",
      "g_norm_D: 9677.519334895178\n",
      "loss:  tensor(3.1008, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.089446563753306\n",
      "D_inv norm: 259.16036342556356\n",
      "B norm: 91.62827652324452\n",
      "a: 9677.519334895178\n",
      "b: 4414569.093614912\n",
      "c: 456.16742688354725\n",
      "plms: 4027565248.467895 -1997414814.4637585 -8815441.012441663 -6.201521139161389\n",
      "lmds:  [ 5.00310893e-01 -4.37413577e-03 -7.03596104e-07]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.1604, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(91.6283, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.5945, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.156997874632896\n",
      "yk norm: 47.122234473258324\n",
      "D_hat_inv: 259.34063403569144\n",
      "g_norm_D: 413.8119333051336\n",
      "loss:  tensor(0.2642, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 9.156997874632896\n",
      "D_inv norm: 259.34063403569144\n",
      "B norm: 277.32206637776443\n",
      "a: 413.8119333051336\n",
      "b: 566349.1091794784\n",
      "c: 1368.6147343698472\n",
      "plms: 1550227471.2405427 -773838001.061779 -1133316.8186975552 -0.5283532936223672\n",
      "lmds:  [ 5.00637336e-01 -1.45980335e-03 -4.66349382e-07]\n",
      "lmd_max: tensor([0.5006], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5006], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5006], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.3406, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(277.3221, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5006], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(129.7709, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.07243724079820282\n",
      "yk norm: 4.3198968024081505\n",
      "D_hat_inv: 259.4551516279384\n",
      "g_norm_D: 0.025614234252202724\n",
      "loss:  tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.07243724079820282\n",
      "D_inv norm: 259.4551516279384\n",
      "B norm: 3.001378710092167\n",
      "a: 0.025614234252202724\n",
      "b: 0.37528374431562916\n",
      "c: 14.651374724714099\n",
      "plms: 10.996845532124153 -4.747199952104009 -0.8017065013215681 -0.003493442872020762\n",
      "lmds:  [ 0.56233577 -0.1261709  -0.00447745]\n",
      "lmd_max: tensor([0.5623], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5623], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5623], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.4552, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3.0014, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5623], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(145.8316, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.027532710327372745\n",
      "yk norm: 1.4483601804477282\n",
      "D_hat_inv: 259.5697795156921\n",
      "g_norm_D: 0.0035818450583900486\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.027532710327372745\n",
      "D_inv norm: 259.5697795156921\n",
      "B norm: 1.28698636850955\n",
      "a: 0.0035818450583900486\n",
      "b: 0.021781591392029214\n",
      "c: 6.081109326884034\n",
      "plms: 0.2649124771368917 -0.08888023120600544 -0.05072265505909532 -0.0011776767709548964\n",
      "lmds:  [ 0.64369216 -0.28385376 -0.02433049]\n",
      "lmd_max: tensor([0.6437], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.6437], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.6437], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.5698, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1.2870, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.6437], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(167.0098, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 4.0900278332865625\n",
      "yk norm: 170.3893801334448\n",
      "D_hat_inv: 259.9369471155255\n",
      "g_norm_D: 79.78613074500356\n",
      "loss:  tensor(0.0867, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 4.0900278332865625\n",
      "D_inv norm: 259.9369471155255\n",
      "B norm: 184.61186596639885\n",
      "a: 79.78613074500356\n",
      "b: 70252.51780523728\n",
      "c: 880.5103988532079\n",
      "plms: 123716144.94626313 -61711561.79154182 -140650.96658848377 -0.17348076746005062\n",
      "lmds:  [ 5.01084604e-01 -2.26761888e-03 -1.23408147e-06]\n",
      "lmd_max: tensor([0.5011], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5011], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5011], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.9369, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(184.6119, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5011], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.1862, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 51.91165881768557\n",
      "yk norm: 10.834069810369845\n",
      "D_hat_inv: 260.12848823368137\n",
      "g_norm_D: 13109.573156674258\n",
      "loss:  tensor(3.2421, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 51.91165881768557\n",
      "D_inv norm: 260.12848823368137\n",
      "B norm: 109.59988388420933\n",
      "a: 13109.573156674258\n",
      "b: 6989681.445997824\n",
      "c: 533.1738388781395\n",
      "plms: 7453430578.195928 -3700599863.97766 -13960058.190950526 -6.484231562050409\n",
      "lmds:  [ 5.00240333e-01 -3.74368095e-03 -4.64541771e-07]\n",
      "lmd_max: tensor([0.5002], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.1285, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(109.5999, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.0635, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.05512848532290124\n",
      "yk norm: 4.319517427967626\n",
      "D_hat_inv: 260.24340406803884\n",
      "g_norm_D: 0.014807654178371526\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.05512848532290124\n",
      "D_inv norm: 260.24340406803884\n",
      "B norm: 2.7997436054763405\n",
      "a: 0.014807654178371526\n",
      "b: 0.20199409209687696\n",
      "c: 13.641194591910121\n",
      "plms: 5.510881433419427 -2.35123342444206 -0.43357136808039676 -0.0021698426719348107\n",
      "lmds:  [ 0.5667079  -0.13490486 -0.00515016]\n",
      "lmd_max: tensor([0.5667], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5667], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5667], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.2434, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2.7997, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5667], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(147.4127, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 31.990857133751707\n",
      "yk norm: 32.212536737711446\n",
      "D_hat_inv: 260.25836190941624\n",
      "g_norm_D: 4878.284619104959\n",
      "loss:  tensor(1.9259, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 31.990857133751707\n",
      "D_inv norm: 260.25836190941624\n",
      "B norm: 174.59792187565085\n",
      "a: 4878.284619104959\n",
      "b: 4059958.441615404\n",
      "c: 832.2512437497552\n",
      "plms: 6757810925.213474 -3365333594.5933223 -8116571.75710688 -3.851867547469247\n",
      "lmds:  [ 5.00391928e-01 -2.39977663e-03 -4.74661702e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.2584, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(174.5979, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.1708, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 3.421475590793107\n",
      "yk norm: 92.40009747967123\n",
      "D_hat_inv: 260.3765226403585\n",
      "g_norm_D: 57.18128003695254\n",
      "loss:  tensor(0.0954, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 3.421475590793107\n",
      "D_inv norm: 260.3765226403585\n",
      "B norm: 116.95793284497766\n",
      "a: 57.18128003695254\n",
      "b: 32667.09668263061\n",
      "c: 571.2900561428494\n",
      "plms: 37324774.995687865 -18593986.617355444 -65437.81991797687 -0.1907867207258436\n",
      "lmds:  [ 5.01662217e-01 -3.49188548e-03 -2.91796152e-06]\n",
      "lmd_max: tensor([0.5017], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5017], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5017], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.3765, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(116.9579, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5017], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.5585, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 42.32943416159711\n",
      "yk norm: 0.001626205946063534\n",
      "D_hat_inv: 260.4918760176828\n",
      "g_norm_D: 9038.639170287572\n",
      "loss:  tensor(11.1920, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 42.32943416159711\n",
      "D_inv norm: 260.4918760176828\n",
      "B norm: 0.02469882348926385\n",
      "a: 9038.639170287572\n",
      "b: 1126.1531060235043\n",
      "c: 0.12459321417824394\n",
      "plms: 280.6220702725623 4363.953912284561 15819.394350067763 -22.38395765434967\n",
      "lmds:  [ 1.41441739e-03 -9.79482288e+00 -5.75759189e+00]\n",
      "lmd_max: tensor([0.0014], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0014], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0014], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.4919, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0247, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0014], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.3684, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 3.1975785468033493\n",
      "yk norm: 68.1225953661071\n",
      "D_hat_inv: 260.59230888685096\n",
      "g_norm_D: 50.33130247301372\n",
      "loss:  tensor(0.0820, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 3.1975785468033493\n",
      "D_inv norm: 260.59230888685096\n",
      "B norm: 119.64768202695082\n",
      "a: 50.33130247301372\n",
      "b: 29644.094205957706\n",
      "c: 588.9792782901271\n",
      "plms: 34919514.421979025 -17398071.442261785 -59380.70954090742 -0.1639987526376692\n",
      "lmds:  [ 5.01623503e-01 -3.38725158e-03 -2.76405715e-06]\n",
      "lmd_max: tensor([0.5016], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5016], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5016], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.5923, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(119.6477, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5016], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.6576, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 17.0379333797569\n",
      "yk norm: 120.01083783172412\n",
      "D_hat_inv: 260.27759647560515\n",
      "g_norm_D: 1427.1943046791657\n",
      "loss:  tensor(0.4571, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 17.0379333797569\n",
      "D_inv norm: 260.27759647560515\n",
      "B norm: 500.9181553542589\n",
      "a: 1427.1943046791657\n",
      "b: 3514788.113189049\n",
      "c: 2462.725714127044\n",
      "plms: 17311918132.11749 -8647444793.745565 -7031224.880968207 -0.9142396925560844\n",
      "lmds:  [ 5.00319964e-01 -8.11649452e-04 -1.30046474e-07]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.2776, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(500.9182, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.1576, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.8395584144095565\n",
      "yk norm: 2.570919406519653\n",
      "D_hat_inv: 260.37253763156815\n",
      "g_norm_D: 3.5243491797840836\n",
      "loss:  tensor(0.0196, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.8395584144095565\n",
      "D_inv norm: 260.37253763156815\n",
      "B norm: 35.67645994874171\n",
      "a: 3.5243491797840836\n",
      "b: 628.6917731768647\n",
      "c: 178.38521131308022\n",
      "plms: 224298.6296179002 -110879.6714402283 -1264.2947913641344 -0.03912864543875317\n",
      "lmds:  [ 5.05491036e-01 -1.11205069e-02 -3.10334567e-05]\n",
      "lmd_max: tensor([0.5055], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5055], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5055], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.3725, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(35.6765, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5055], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(131.5511, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.005922248590602394\n",
      "yk norm: 0.1322661953708642\n",
      "D_hat_inv: 260.4878189717027\n",
      "g_norm_D: 0.00017415405707176936\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.005922248590602394\n",
      "D_inv norm: 260.4878189717027\n",
      "B norm: 0.26060795480181015\n",
      "a: 0.00017415405707176936\n",
      "b: 0.00022536246995974473\n",
      "c: 1.294040883967878\n",
      "plms: 0.0005832564996797848 0.0001591270169940134 -0.0007989861824150113 -0.00026914503446876854\n",
      "lmds:  [ 1.1956605  -1.12561639 -0.34286921]\n",
      "lmd_max: tensor([1.1957], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1.1957], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1.1957], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.4878, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.2606, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1.1957], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(311.3343, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.2459112181248346\n",
      "yk norm: 47.64173283329285\n",
      "D_hat_inv: 260.59005058178064\n",
      "g_norm_D: 7.567195066538413\n",
      "loss:  tensor(0.0371, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 1.2459112181248346\n",
      "D_inv norm: 260.59005058178064\n",
      "B norm: 41.09919979622317\n",
      "a: 7.567195066538413\n",
      "b: 1516.104135688166\n",
      "c: 200.352194222172\n",
      "plms: 607509.5805088672 -300666.7217428194 -3046.7850410605315 -0.07414732824021181\n",
      "lmds:  [ 5.04851342e-01 -9.91010705e-03 -2.43949827e-05]\n",
      "lmd_max: tensor([0.5049], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5049], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5049], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.5901, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(41.0992, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5049], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(131.4959, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.4517330318747127\n",
      "yk norm: 11.164983340342461\n",
      "D_hat_inv: 260.7050110272615\n",
      "g_norm_D: 1.006352783763527\n",
      "loss:  tensor(0.0097, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.4517330318747127\n",
      "D_inv norm: 260.7050110272615\n",
      "B norm: 20.846408504086767\n",
      "a: 1.006352783763527\n",
      "b: 103.45894645048742\n",
      "c: 102.80584315926947\n",
      "plms: 21272.368444424133 -10428.260144331472 -208.91102399785507 -0.019482533975239757\n",
      "lmds:  [ 5.09504300e-01 -1.91849774e-02 -9.36958707e-05]\n",
      "lmd_max: tensor([0.5095], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5095], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5095], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.7050, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(20.8464, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5095], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(132.7659, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 25.05656950207749\n",
      "yk norm: 230.59681045713486\n",
      "D_hat_inv: 260.69425883148955\n",
      "g_norm_D: 3010.7397875572096\n",
      "loss:  tensor(0.7891, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 25.05656950207749\n",
      "D_inv norm: 260.69425883148955\n",
      "B norm: 522.6052559632402\n",
      "a: 3010.7397875572096\n",
      "b: 7545308.378229647\n",
      "c: 2506.131021157295\n",
      "plms: 37819062781.75871 -18889261978.26539 -15092505.334910091 -1.5781413579603996\n",
      "lmds:  [ 5.00261768e-01 -7.97620698e-04 -1.04578260e-07]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.6943, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(522.6053, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.3540, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 26.603014435150286\n",
      "yk norm: 402.42531414882137\n",
      "D_hat_inv: 260.6764222976105\n",
      "g_norm_D: 3510.401763369328\n",
      "loss:  tensor(1.3198, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 26.603014435150286\n",
      "D_inv norm: 260.6764222976105\n",
      "B norm: 258.0302746563146\n",
      "a: 3510.401763369328\n",
      "b: 4492857.1717633335\n",
      "c: 1279.86979115776\n",
      "plms: 11500544340.252762 -5736624676.4581585 -8985450.375810418 -2.639657509369703\n",
      "lmds:  [ 5.00374761e-01 -1.56114981e-03 -2.93825316e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.6764, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(258.0303, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.3718, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.3953914332496566\n",
      "yk norm: 6.039442252554565\n",
      "D_hat_inv: 260.79162112355556\n",
      "g_norm_D: 0.7773519024812605\n",
      "loss:  tensor(0.0092, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.3953914332496566\n",
      "D_inv norm: 260.7916211235555\n",
      "B norm: 16.949428458549733\n",
      "a: 0.7773519024812605\n",
      "b: 65.51426588108939\n",
      "c: 84.27877473763401\n",
      "plms: 11042.924112587589 -5389.832938759999 -132.56898320589173 -0.018362602317789557\n",
      "lmds:  [ 5.11554056e-01 -2.33345234e-02 -1.39302745e-04]\n",
      "lmd_max: tensor([0.5116], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5116], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5116], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.7916, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(16.9494, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5116], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(133.3429, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 29.77733769347196\n",
      "yk norm: 134.8937001379887\n",
      "D_hat_inv: 260.84073366197646\n",
      "g_norm_D: 4301.393949951662\n",
      "loss:  tensor(1.4292, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 29.77733769347196\n",
      "D_inv norm: 260.84073366197646\n",
      "B norm: 279.24362886964144\n",
      "a: 4301.393949951662\n",
      "b: 5826798.245347344\n",
      "c: 1354.6302229333874\n",
      "plms: 15786314012.165485 -7875095016.109707 -11652737.81320891 -2.8583853670984865\n",
      "lmds:  [ 5.00331177e-01 -1.47508708e-03 -2.45337997e-07]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.8407, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(279.2436, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.4450, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 35.67559937547314\n",
      "yk norm: 996.0867090821423\n",
      "D_hat_inv: 261.0660143863975\n",
      "g_norm_D: 6275.05489306786\n",
      "loss:  tensor(1.2070, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 35.67559937547314\n",
      "D_inv norm: 261.0660143863975\n",
      "B norm: 543.0954049906472\n",
      "a: 6275.05489306786\n",
      "b: 16802295.964493096\n",
      "c: 2677.633303742861\n",
      "plms: 89980774507.74199 -44940486068.82631 -33604969.65273806 -2.414041071256701\n",
      "lmds:  [ 5.00192074e-01 -7.46578102e-04 -7.18427369e-08]\n",
      "lmd_max: tensor([0.5002], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.0660, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(543.0954, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.5177, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 20.804584214806056\n",
      "yk norm: 1003.1449207194864\n",
      "D_hat_inv: 260.89894731874733\n",
      "g_norm_D: 2083.682868988452\n",
      "loss:  tensor(0.7823, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 20.804584214806056\n",
      "D_inv norm: 260.8989473187474\n",
      "B norm: 364.7911236289996\n",
      "a: 2083.682868988452\n",
      "b: 3659227.6013427493\n",
      "c: 1756.1346094471487\n",
      "plms: 12852192469.12455 -6416284624.008225 -7319783.201397791 -1.564619369354148\n",
      "lmds:  [ 5.00374800e-01 -1.13800501e-03 -2.13792212e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.8989, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(364.7911, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.4841, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.4951387960191427\n",
      "yk norm: 17.555184313298906\n",
      "D_hat_inv: 261.0151872740903\n",
      "g_norm_D: 1.2010923513909229\n",
      "loss:  tensor(0.0126, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.4951387960191427\n",
      "D_inv norm: 261.0151872740903\n",
      "B norm: 19.290352418169206\n",
      "a: 1.2010923513909229\n",
      "b: 113.51128811933842\n",
      "c: 94.50671131814872\n",
      "plms: 21455.157075291034 -10499.125446165026 -229.3944876365925 -0.025257973926454288\n",
      "lmds:  [ 5.10308259e-01 -2.08455246e-02 -1.10667828e-04]\n",
      "lmd_max: tensor([0.5103], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5103], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5103], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.0152, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(19.2904, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5103], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(133.1337, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.10950204133564863\n",
      "yk norm: 0.8451894663405836\n",
      "D_hat_inv: 261.12841948169057\n",
      "g_norm_D: 0.06091835280472286\n",
      "loss:  tensor(0.0026, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.10950204133564863\n",
      "D_inv norm: 261.12841948169057\n",
      "B norm: 4.689226746773616\n",
      "a: 0.06091835280472286\n",
      "b: 1.451286335754223\n",
      "c: 23.82346647497843\n",
      "plms: 69.14934273087006 -31.668393962387892 -3.0240983617967103 -0.005107619333091418\n",
      "lmds:  [ 0.53931464 -0.07962357 -0.00172007]\n",
      "lmd_max: tensor([0.5393], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5393], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5393], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.1284, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(4.6892, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5393], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.7619, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.16336211561040337\n",
      "yk norm: 1.2255178115768826\n",
      "D_hat_inv: 261.2452620386431\n",
      "g_norm_D: 0.13699895407927487\n",
      "loss:  tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.16336211561040337\n",
      "D_inv norm: 261.2452620386431\n",
      "B norm: 5.369216836473918\n",
      "a: 0.13699895407927487\n",
      "b: 3.7760935776389863\n",
      "c: 27.56293727216295\n",
      "plms: 208.16046082856153 -96.50933650673035 -7.824827678910503 -0.009916186116041312\n",
      "lmds:  [ 0.53416825 -0.06925094 -0.00128778]\n",
      "lmd_max: tensor([0.5342], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5342], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5342], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.2453, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(5.3692, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5342], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.4813, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 3.4633515621925617\n",
      "yk norm: 20.976598300917836\n",
      "D_hat_inv: 261.40812762246577\n",
      "g_norm_D: 57.206674053822624\n",
      "loss:  tensor(0.1046, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 3.4633515621925617\n",
      "D_inv norm: 261.40812762246577\n",
      "B norm: 108.80283975881363\n",
      "a: 57.206674053822624\n",
      "b: 29685.233626465117\n",
      "c: 518.9120695696433\n",
      "plms: 30808052.033534765 -15341605.187787771 -59473.123843369045 -0.209158691111661\n",
      "lmds:  [ 5.01820780e-01 -3.84338010e-03 -3.52005702e-06]\n",
      "lmd_max: tensor([0.5018], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5018], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5018], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.4081, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(108.8028, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5018], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(131.1191, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 5.350978562332535\n",
      "yk norm: 167.09798305110402\n",
      "D_hat_inv: 261.55300547561717\n",
      "g_norm_D: 141.06304038657674\n",
      "loss:  tensor(0.1450, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 5.350978562332535\n",
      "D_inv norm: 261.55300547561717\n",
      "B norm: 183.53561315607342\n",
      "a: 141.06304038657674\n",
      "b: 127549.98303365901\n",
      "c: 904.2055430261123\n",
      "plms: 230662803.34384215 -115058257.10321108 -255342.17953578342 -0.2899448876876693\n",
      "lmds:  [ 5.01025288e-01 -2.20832487e-03 -1.13609666e-06]\n",
      "lmd_max: tensor([0.5010], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5010], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5010], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.5530, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(183.5356, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5010], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(130.9829, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.808896367623654\n",
      "yk norm: 13.285998562488405\n",
      "D_hat_inv: 261.67984953394466\n",
      "g_norm_D: 16.13035015544285\n",
      "loss:  tensor(0.0481, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 1.808896367623654\n",
      "D_inv norm: 261.6798495339447\n",
      "B norm: 66.41152051324983\n",
      "a: 16.13035015544285\n",
      "b: 5280.8476747812165\n",
      "c: 327.38580526097905\n",
      "plms: 3457749.136937635 -1718060.927413241 -10592.416913466272 -0.09618966858461932\n",
      "lmds:  [ 5.02963417e-01 -6.08168720e-03 -9.09440875e-06]\n",
      "lmd_max: tensor([0.5030], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5030], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5030], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.6798, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(66.4115, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5030], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(131.5512, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 14.41699983988158\n",
      "yk norm: 335.02788892029156\n",
      "D_hat_inv: 262.11429330840167\n",
      "g_norm_D: 1051.5188465131448\n",
      "loss:  tensor(0.3912, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 14.41699983988158\n",
      "D_inv norm: 262.11429330840167\n",
      "B norm: 434.1801921123862\n",
      "a: 1051.5188465131448\n",
      "b: 2309693.441906246\n",
      "c: 2196.530713229944\n",
      "plms: 10146625166.585701 -5067848455.432759 -4620720.76223887 -0.7823510271684758\n",
      "lmds:  [ 5.00371597e-01 -9.09944256e-04 -1.69345088e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(262.1143, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(434.1802, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(131.0886, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 45.20216787427632\n",
      "yk norm: 0.03288538163359495\n",
      "D_hat_inv: 262.227821870826\n",
      "g_norm_D: 9891.523073384964\n",
      "loss:  tensor(9.0671, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 45.20216787427632\n",
      "D_inv norm: 262.227821870826\n",
      "B norm: 0.23582888942496147\n",
      "a: 9891.523073384964\n",
      "b: 11292.882640906373\n",
      "c: 1.1416727795229065\n",
      "plms: 25785.55342693912 32255.11754955088 -2844.1255713335013 -18.134108578811624\n",
      "lmds:  [ 0.0883082  -1.33323371 -0.00597327]\n",
      "lmd_max: tensor([0.0883], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0883], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0883], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(262.2278, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.2358, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0883], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(23.1552, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.02996086757096\n",
      "yk norm: 2.4742284178428413e-13\n",
      "g_norm_l2: 43.23297732053803\n",
      "yk norm: 4.322671678575628e-13\n",
      "g_norm_l2: 41.55522096467388\n",
      "yk norm: 2.561708341637621e-14\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 2.0407993072472359e-13\n",
      "g_norm_l2: 2.5671525554198714e-23\n",
      "yk norm: 2.483336938377312e-21\n",
      "g_norm_l2: 3.8398846184281e-81\n",
      "yk norm: 1.440887165248464e-79\n",
      "g_norm_l2: 47.21772424993831\n",
      "yk norm: 1.5184472178694548e-08\n",
      "D_hat_inv: 263.02487196640567\n",
      "g_norm_D: 10860.217757564646\n",
      "loss:  tensor(360.2448, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.21772424993831\n",
      "D_inv norm: 263.02487196640567\n",
      "B norm: 2.521354778519374e-08\n",
      "a: 10860.217757564646\n",
      "b: 0.0013338313565506162\n",
      "c: 1.228181042338254e-07\n",
      "plms: 3.276372771583566e-10 0.005335325251515754 21720.43267048824 -720.4896124198177\n",
      "lmds:  [ 3.31710475e-02 -8.14413953e+06 -8.14010416e+06]\n",
      "lmd_max: tensor([0.0332], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0332], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0332], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(263.0249, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2.5214e-08, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0332], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(8.7248, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 50.3485856109312\n",
      "yk norm: 3.5889802029728214e-14\n",
      "g_norm_l2: 41.50305410508298\n",
      "yk norm: 4.185177583779763e-05\n",
      "D_hat_inv: 263.252561314214\n",
      "g_norm_D: 8686.288319201167\n",
      "loss:  tensor(17.1911, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50305410508298\n",
      "D_inv norm: 263.252561314214\n",
      "B norm: 5.8907463499931805e-05\n",
      "a: 8686.288319201167\n",
      "b: 2.5803504338517422\n",
      "c: 0.00029706018716277706\n",
      "plms: 0.0015330387656511033 10.320632181979427 17367.395510396633 -34.38215365204495\n",
      "lmds:  [ 1.97969311e-03 -3.40709827e+03 -3.32504409e+03]\n",
      "lmd_max: tensor([0.0020], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0020], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0020], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(263.2526, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(5.8907e-05, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0020], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.5212, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.3333142775154369e-41\n",
      "yk norm: 8.585295909369484e-40\n",
      "g_norm_l2: 8.838969815255777e-08\n",
      "yk norm: 2.6421937616009974e-06\n",
      "D_hat_inv: 263.4801081434726\n",
      "g_norm_D: 3.96593291026713e-14\n",
      "g_norm_l2: 7.477420609471424e-120\n",
      "yk norm: 7.884958043769636e-119\n",
      "g_norm_l2: 2.6543223935536875e-54\n",
      "yk norm: 1.1792394315254142e-53\n",
      "g_norm_l2: 1.4959105000291448e-46\n",
      "yk norm: 2.5779730464586714e-45\n",
      "g_norm_l2: 44.71600053315655\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 44.705829373331675\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.9024538984454\n",
      "yk norm: 0.0\n",
      "Loss: 74.74589031782509 | GradNorm^2: 64.42032390834943\n",
      "g_norm_l2: 2.082054197488403e-07\n",
      "yk norm: 2.8508531546412696e-07\n",
      "D_hat_inv: 264.27486915250716\n",
      "g_norm_D: 2.191704115400603e-13\n",
      "g_norm_l2: 41.38612189030718\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.30230153230653\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 40.61579369794132\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 33.030326505804624\n",
      "yk norm: 1.3383311328391822e-13\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.337312999703711e-21\n",
      "yk norm: 5.19955872604677e-20\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 1335.4030411303868\n",
      "D_hat_inv: 265.51303154260785\n",
      "g_norm_D: 15978.479926171778\n",
      "loss:  tensor(407.6113, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 56.36449803070452\n",
      "D_inv norm: 265.51303154260785\n",
      "B norm: 3176.9566382532953\n",
      "a: 15978.479926171778\n",
      "b: 255311820.75107458\n",
      "c: 15978.479926171787\n",
      "plms: 8158989605570.831 -4286609537986.3867 -536643722.4640096 -815.22266329731\n",
      "lmds:  [ 5.25510012e-01 -1.23623254e-04 -1.53800837e-06]\n",
      "lmd_max: tensor([0.5255], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5255], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5255], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(265.5130, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3176.9566, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5255], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.4619, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.43810440926741\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 20.155342310067006\n",
      "yk norm: 458.28619960257237\n",
      "D_hat_inv: 265.70793203596446\n",
      "g_norm_D: 2073.6461054881715\n",
      "loss:  tensor(0.6648, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 20.155342310067006\n",
      "D_inv norm: 265.70793203596446\n",
      "B norm: 430.2704673727376\n",
      "a: 2073.6461054881715\n",
      "b: 4554392.569356869\n",
      "c: 2196.3210392087067\n",
      "plms: 20005816441.788578 -9991104626.177763 -9110478.5004385 -1.3296448541607813\n",
      "lmds:  [ 5.00320192e-01 -9.10054392e-04 -1.45970136e-07]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(265.7079, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(430.2705, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(132.8740, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.002083091089669e-41\n",
      "yk norm: 8.028228656172378e-39\n",
      "g_norm_l2: 45.913584901568214\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.4145109509627696e-27\n",
      "yk norm: 1.8499348449794335e-25\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.398216418774933e-61\n",
      "yk norm: 1.9095327685201153e-59\n",
      "g_norm_l2: 1.9310445835356585e-22\n",
      "yk norm: 3.2585758647573353e-22\n",
      "g_norm_l2: 4.255524967657472e-51\n",
      "yk norm: 2.997170657763909e-50\n",
      "g_norm_l2: 1.2439621478719497e-07\n",
      "yk norm: 2.7569705497718624e-06\n",
      "D_hat_inv: 266.7217965063673\n",
      "g_norm_D: 7.969520227191721e-14\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 3.903327915992235e-13\n",
      "g_norm_l2: 39.15506083797119\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0090593839597916e-119\n",
      "yk norm: 9.69416423428687e-119\n",
      "g_norm_l2: 1.95915488412256e-102\n",
      "yk norm: 3.74861305554862e-101\n",
      "g_norm_l2: 46.77143671421474\n",
      "yk norm: 0.000271973136776355\n",
      "D_hat_inv: 267.2860695691516\n",
      "g_norm_D: 10678.677822661419\n",
      "loss:  tensor(364.7208, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.77143671421474\n",
      "D_inv norm: 267.2860695691516\n",
      "B norm: 0.0002982052907958578\n",
      "a: 10678.677822661419\n",
      "b: -15.544934308975149\n",
      "c: -0.0014556984082792494\n",
      "plms: 0.04525747226076123 -62.203911700906154 21390.569207786142 -729.4415633332416\n",
      "lmds:  [0.03410446 0.         0.        ]\n",
      "lmd_max: tensor([0.0341], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0341], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0341], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(267.2861, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0003, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0341], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(9.1156, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 7.448261563426955e-25\n",
      "yk norm: 6.05778261850735e-23\n",
      "g_norm_l2: 2.008156273007643e-62\n",
      "yk norm: 3.1989899885934835e-61\n",
      "g_norm_l2: 1.7445943807245191e-19\n",
      "yk norm: 1.526919130703561e-17\n",
      "g_norm_l2: 2.712954937722112e-75\n",
      "yk norm: 7.845358905163163e-74\n",
      "g_norm_l2: 62.0094043051659\n",
      "yk norm: 3.79031610149336e-13\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.9024538984454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.16768259674024\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.650222856519164\n",
      "yk norm: 0.015041544728329524\n",
      "D_hat_inv: 268.30153649332016\n",
      "g_norm_D: 8040.157940217017\n",
      "loss:  tensor(12.1769, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 39.650222856519164\n",
      "D_inv norm: 268.30153649332016\n",
      "B norm: 0.008093343692311003\n",
      "a: 8040.157940217017\n",
      "b: 332.7866366136285\n",
      "c: 0.04139055962433569\n",
      "plms: 27.548450249877046 1317.3305988850548 15412.726570463174 -24.353823213582615\n",
      "lmds:  [ 1.57989794e-03 -2.73946317e+01 -2.04256309e+01]\n",
      "lmd_max: tensor([0.0016], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0016], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0016], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(268.3015, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0081, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0016], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.4239, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 4.512032042691518e-36\n",
      "yk norm: 4.770732208445437e-35\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 2.655275482299315e-13\n",
      "g_norm_l2: 5.0417254194008405e-59\n",
      "yk norm: 1.2468534145233463e-57\n",
      "g_norm_l2: 2.1595506647303528e-32\n",
      "yk norm: 7.603234830611023e-31\n",
      "g_norm_l2: 2.40699129046144e-18\n",
      "yk norm: 1.2334867828774894e-17\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.041231034340089e-31\n",
      "yk norm: 1.0505800718505985e-29\n",
      "g_norm_l2: 38.33875456219458\n",
      "yk norm: 6.248201043368059e-14\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 2.6779878550808475e-13\n",
      "g_norm_l2: 46.84977630494817\n",
      "yk norm: 3.623721495598212e-12\n",
      "g_norm_l2: 50.34858561035416\n",
      "yk norm: 3.5765251667610143e-09\n",
      "D_hat_inv: 269.5509108573623\n",
      "g_norm_D: 13015.040072272082\n",
      "loss:  tensor(25.1921, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.34858561035416\n",
      "D_inv norm: 269.55091085736234\n",
      "B norm: 2.9053128806266178e-08\n",
      "a: 13015.040072272082\n",
      "b: 0.0019413747598083261\n",
      "c: 1.4916394794237566e-07\n",
      "plms: 5.791662472173823e-10 0.007765498748529138 26030.076246763645 -50.3841632124405\n",
      "lmds:  [ 1.93561055e-03 -6.70586340e+06 -6.70220170e+06]\n",
      "lmd_max: tensor([0.0019], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0019], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0019], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(269.5509, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2.9053e-08, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0019], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.5217, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.551513072829698e-13\n",
      "yk norm: 6.129198031519133e-11\n",
      "g_norm_l2: 41.201373203309444\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0255941370034202e-15\n",
      "yk norm: 1.2859181460850178e-14\n",
      "g_norm_l2: 43.23297732053803\n",
      "yk norm: 3.0205938578135853e-13\n",
      "g_norm_l2: 2.7314362180083943e-108\n",
      "yk norm: 3.0205665295562444e-106\n",
      "g_norm_l2: 43.33387368350503\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.5067924125254306e-33\n",
      "yk norm: 2.6879133451247805e-33\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 34.23317323032481\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.008396474772904417\n",
      "yk norm: 0.5899835405329431\n",
      "D_hat_inv: 270.8110863558268\n",
      "g_norm_D: 0.0003669218847961985\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.008396474772904417\n",
      "D_inv norm: 270.8110863558268\n",
      "B norm: 0.3981454222411537\n",
      "a: 0.0003669218847961985\n",
      "b: 0.0007603174939216074\n",
      "c: 2.0721508457962776\n",
      "plms: 0.0031509850762067287 -5.472293448209164e-05 -0.002254348828884964 -0.00035411456979865747\n",
      "lmds:  [ 0.92366327 -0.74241135 -0.16388499]\n",
      "lmd_max: tensor([0.9237], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.9237], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.9237], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(270.8111, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.3981, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.9237], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(250.0413, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 5.352238238398094e-24\n",
      "yk norm: 5.134254016175496e-24\n",
      "g_norm_l2: 5.271510805788808e-75\n",
      "yk norm: 2.016578165313497e-73\n",
      "g_norm_l2: 44.71600053315655\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.2101525840028431e-47\n",
      "yk norm: 6.8088715699207495e-46\n",
      "g_norm_l2: 1.7994821898193734e-05\n",
      "yk norm: 0.002008140743770598\n",
      "D_hat_inv: 271.38185422666015\n",
      "g_norm_D: 1.6542527677283543e-09\n",
      "loss:  tensor(3.8959e-07, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 1.7994821898193734e-05\n",
      "D_inv norm: 271.38185422666015\n",
      "B norm: 0.0008311613631190778\n",
      "a: 1.6542527677283543e-09\n",
      "b: 7.024153298802113e-12\n",
      "c: 0.004246118510926109\n",
      "plms: 5.96507746912527e-14 1.4018483947399996e-11 -3.3225525528103183e-09 -7.791833605965705e-07\n",
      "lmds:  [ 235.88435921 -243.11716018 -227.77645113]\n",
      "lmd_max: tensor([235.8844], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([235.8844], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([235.8844], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(271.3819, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0008, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([235.8844], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(63995.0398, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "Loss: 38.58838181566594 | GradNorm^2: 63.192511718501095\n",
      "g_norm_l2: 0.1274264343945565\n",
      "yk norm: 3.5159564386189435\n",
      "D_hat_inv: 271.491123769001\n",
      "g_norm_D: 0.08402066384563145\n",
      "loss:  tensor(0.0033, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.1274264343945565\n",
      "D_inv norm: 271.491123769001\n",
      "B norm: 4.973152294902096\n",
      "a: 0.08402066384563145\n",
      "b: 2.1621454902619632\n",
      "c: 25.73349687208382\n",
      "plms: 111.27912842129271 -51.30822908690179 -4.49178483942339 -0.00651942462889142\n",
      "lmds:  [ 0.53651585 -0.07396262 -0.00147639]\n",
      "lmd_max: tensor([0.5365], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5365], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5365], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(271.4911, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(4.9732, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5365], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(145.5928, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 6.77369993722144e-14\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 40.61579369794132\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 44.71600053315655\n",
      "yk norm: 1.1078118711922304e-13\n",
      "g_norm_l2: 46.16768259674025\n",
      "yk norm: 2.2681526869318953e-14\n",
      "g_norm_l2: 6.074688174388038e-40\n",
      "yk norm: 7.854933208131278e-39\n",
      "g_norm_l2: 1.1322883269727822e-17\n",
      "yk norm: 4.793038431985392e-16\n",
      "g_norm_l2: 35.9024538984454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.7683297128244417e-63\n",
      "yk norm: 3.3451817682161243e-62\n",
      "g_norm_l2: 24.53605316212667\n",
      "yk norm: 458.4473976033016\n",
      "D_hat_inv: 272.6859856257111\n",
      "g_norm_D: 3144.492002927804\n",
      "loss:  tensor(0.6681, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 24.53605316212667\n",
      "D_inv norm: 272.6859856257111\n",
      "B norm: 633.3376684129878\n",
      "a: 3144.492002927804\n",
      "b: 10402240.731764853\n",
      "c: 3308.0830614545794\n",
      "plms: 68822952731.84839 -34384490219.79011 -20807033.138311017 -1.336220799619261\n",
      "lmds:  [ 5.00212288e-01 -6.04333132e-04 -6.42264906e-08]\n",
      "lmd_max: tensor([0.5002], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(272.6860, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(633.3377, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.3376, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 1.6536187272590903e-13\n",
      "g_norm_l2: 1.0797208770701826e-108\n",
      "yk norm: 1.828550975763619e-107\n",
      "g_norm_l2: 1.6803824320191111e-32\n",
      "yk norm: 8.741498882162237e-32\n",
      "g_norm_l2: 38.33875456219458\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.4886231957973703e-78\n",
      "yk norm: 1.5181311759544001e-77\n",
      "g_norm_l2: 1.3976491861944936e-47\n",
      "yk norm: 4.658719589225123e-47\n",
      "g_norm_l2: 8.652820982523097e-16\n",
      "yk norm: 4.3339333314701986e-14\n",
      "g_norm_l2: 41.50663154498864\n",
      "yk norm: 4.3758200743189815e-13\n",
      "g_norm_l2: 3.0979995553294207e-34\n",
      "yk norm: 5.013521840245472e-33\n",
      "g_norm_l2: 7.709223095598108e-24\n",
      "yk norm: 2.4921829302074635e-22\n",
      "g_norm_l2: 42.93269227210107\n",
      "yk norm: 3.3526163917522746e-13\n",
      "g_norm_l2: 5.844173098304608e-115\n",
      "yk norm: 2.391703640346539e-113\n",
      "g_norm_l2: 2.7071319778832763e-05\n",
      "yk norm: 0.00010134918192161777\n",
      "D_hat_inv: 274.14532067400285\n",
      "g_norm_D: 3.802828993339261e-09\n",
      "loss:  tensor(5.8610e-07, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 2.7071319778832763e-05\n",
      "D_inv norm: 274.14532067400285\n",
      "B norm: 0.0012503947388058348\n",
      "a: 3.802828993339261e-09\n",
      "b: 2.467413135815464e-11\n",
      "c: 0.00648836205923851\n",
      "plms: 3.2018939549783544e-13 4.9188182479166236e-11 -7.655001791996879e-09 -1.1721996535551167e-06\n",
      "lmds:  [ 154.49736077 -160.26358854 -147.85591953]\n",
      "lmd_max: tensor([154.4974], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([154.4974], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([154.4974], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.1453, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0013, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([154.4974], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(42341.8394, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 4.588286433413192e-13\n",
      "yk norm: 1.695980980800413e-11\n",
      "g_norm_l2: 3.189119792618169e-22\n",
      "yk norm: 1.0706097254994642e-20\n",
      "g_norm_l2: 1.7675142524941915e-83\n",
      "yk norm: 8.414905860779759e-82\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 43.33387368350503\n",
      "yk norm: 5.762375375794545e-13\n",
      "g_norm_l2: 46.96174265339647\n",
      "yk norm: 1.2842961878150678e-05\n",
      "D_hat_inv: 274.8220058308119\n",
      "g_norm_D: 11239.62686345307\n",
      "loss:  tensor(18.0279, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.96174265339647\n",
      "D_inv norm: 274.8220058308119\n",
      "B norm: 3.266533961828969e-05\n",
      "a: 11239.62686345307\n",
      "b: 1.8711239449265673\n",
      "c: 0.00016647562838680529\n",
      "plms: 0.0006229930690424966 7.484183283918519 22475.499474217286 -36.05572515268491\n",
      "lmds:  [ 1.60422267e-03 -6.06143951e+03 -5.95183103e+03]\n",
      "lmd_max: tensor([0.0016], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0016], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0016], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.8220, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3.2665e-05, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0016], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.4409, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 34.87882810420822\n",
      "yk norm: 4.942475236781109e-14\n",
      "g_norm_l2: 2.6898098084395346e-76\n",
      "yk norm: 7.950513711905562e-75\n",
      "g_norm_l2: 8.872719284317052e-38\n",
      "yk norm: 2.9427258773805164e-36\n",
      "g_norm_l2: 41.55522096467388\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.30230143367027\n",
      "yk norm: 5.807062859805977e-06\n",
      "D_hat_inv: 275.39021781929495\n",
      "g_norm_D: 7042.521934227877\n",
      "loss:  tensor(19.7237, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 36.30230143367027\n",
      "D_inv norm: 275.39021781929495\n",
      "B norm: 3.5807233193606144e-06\n",
      "a: 7042.521934227877\n",
      "b: 0.1347593364860736\n",
      "c: 1.9135096453320204e-05\n",
      "plms: 5.157265803292902e-06 0.5390347528676457 14084.772840122563 -39.44741597521267\n",
      "lmds:  [ 2.80071337e-03 -5.24213906e+04 -5.20980947e+04]\n",
      "lmd_max: tensor([0.0028], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0028], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0028], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.3902, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3.5807e-06, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0028], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.7713, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.2946551949448893e-32\n",
      "yk norm: 6.096731227987692e-32\n",
      "g_norm_l2: 5.126938879573444e-12\n",
      "yk norm: 3.5148826448936064e-10\n",
      "D_hat_inv: 275.6171040348064\n",
      "g_norm_D: 1.3960282702635259e-22\n",
      "g_norm_l2: 4.46781672953178e-33\n",
      "yk norm: 2.5160741287655797e-31\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.3915487024969806e-27\n",
      "yk norm: 1.074003493776101e-25\n",
      "g_norm_l2: 33.03032650580462\n",
      "yk norm: 2.591069144474999e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.696313375453919\n",
      "yk norm: 186.67268317851457\n",
      "D_hat_inv: 276.48334861615\n",
      "g_norm_D: 503.3319129643938\n",
      "loss:  tensor(0.2804, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 9.696313375453919\n",
      "D_inv norm: 276.48334861615007\n",
      "B norm: 290.44447234525165\n",
      "a: 503.3319129643938\n",
      "b: 782634.0945667815\n",
      "c: 1554.906562465762\n",
      "plms: 2433845779.302677 -1215148388.230408 -1566005.7265221258 -0.5608701051867482\n",
      "lmds:  [ 5.00556334e-01 -1.28506940e-03 -3.58252881e-07]\n",
      "lmd_max: tensor([0.5006], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5006], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5006], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.4833, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(290.4445, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5006], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(138.3331, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.00021280166759811908\n",
      "yk norm: 0.015434019542798594\n",
      "D_hat_inv: 276.5957652718772\n",
      "g_norm_D: 2.4272545714432376e-07\n",
      "loss:  tensor(4.4870e-06, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.00021280166759811908\n",
      "D_inv norm: 276.5957652718772\n",
      "B norm: 0.010092405985395033\n",
      "a: 2.4272545714432376e-07\n",
      "b: 1.3130320107800732e-08\n",
      "c: 0.054095356384449955\n",
      "plms: 1.4205786913467795e-09 2.5550409785381348e-08 -5.117093762968309e-07 -8.973964821211235e-06\n",
      "lmds:  [ 18.86334747 -20.56437786 -16.28488616]\n",
      "lmd_max: tensor([18.8633], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([18.8633], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([18.8633], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.5958, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0101, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([18.8633], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(5215.8725, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 45.91358490156823\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.343231387641408e-21\n",
      "yk norm: 1.0513187667331593e-19\n",
      "g_norm_l2: 46.438104409254514\n",
      "yk norm: 6.51447148435985e-10\n",
      "D_hat_inv: 277.0430890669268\n",
      "g_norm_D: 11472.213025854375\n",
      "loss:  tensor(28.9115, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.438104409254514\n",
      "D_inv norm: 277.0430890669268\n",
      "B norm: 5.990130087586864e-10\n",
      "a: 11472.213025854375\n",
      "b: 3.655793802481939e-05\n",
      "c: 3.1866509053162214e-09\n",
      "plms: 2.3299477260657004e-13 0.000146231751982193 22944.42597822435 -57.82305564145646\n",
      "lmds:  [ 2.51999497e-03 -3.13821609e+08 -3.13796557e+08]\n",
      "lmd_max: tensor([0.0025], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0025], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0025], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.0431, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(5.9901e-10, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0025], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.6981, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 43.23297732053804\n",
      "yk norm: 1.838955039757002e-13\n",
      "g_norm_l2: 41.50305552443547\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977629757338\n",
      "yk norm: 2.898008603586816e-07\n",
      "D_hat_inv: 277.3792677086184\n",
      "g_norm_D: 12002.195780546073\n",
      "loss:  tensor(22.5721, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.84977629757338\n",
      "D_inv norm: 277.3792677086184\n",
      "B norm: 3.4552194167516455e-07\n",
      "a: 12002.195780546073\n",
      "b: 0.022676812124973977\n",
      "c: 1.889388620183151e-06\n",
      "plms: 8.569062154191429e-08 0.09070720549342987 24004.346036878007 -45.14420396111297\n",
      "lmds:  [ 1.88066775e-03 -5.29785916e+05 -5.28757061e+05]\n",
      "lmd_max: tensor([0.0019], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0019], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0019], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.3793, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3.4552e-07, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0019], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.5217, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 44.01082187663912\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.9356897266208388e-78\n",
      "yk norm: 2.1295300701111026e-77\n",
      "g_norm_l2: 41.201373203309444\n",
      "yk norm: 8.452651749433451e-14\n",
      "g_norm_l2: 34.23317323032481\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 2.2726897637955292e-13\n",
      "g_norm_l2: 8.065510061775068e-67\n",
      "yk norm: 5.48607131050197e-66\n",
      "g_norm_l2: 36.76645636008093\n",
      "yk norm: 126.02955838173126\n",
      "D_hat_inv: 278.11945080747023\n",
      "g_norm_D: 7198.400726965723\n",
      "loss:  tensor(2.6863, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 36.76645636008093\n",
      "D_inv norm: 278.11945080747023\n",
      "B norm: 98.83438491107785\n",
      "a: 7198.400726965723\n",
      "b: 3788580.8184358687\n",
      "c: 526.3086846837484\n",
      "plms: 3987925974.7381215 -1980296874.1043332 -7568420.109793184 -5.372583181651438\n",
      "lmds:  [ 5.00366024e-01 -3.79218610e-03 -7.10000421e-07]\n",
      "lmd_max: tensor([0.5004], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(278.1195, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(98.8344, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5004], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.0999, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 6.342661394663705e-09\n",
      "yk norm: 2.6288789698909936e-07\n",
      "D_hat_inv: 278.23139146945636\n",
      "g_norm_D: 2.0856397520313585e-16\n",
      "g_norm_l2: 1.745489930882199e-51\n",
      "yk norm: 3.032251677357639e-50\n",
      "Loss: 34.09113734774422 | GradNorm^2: 50.8716446299653\n",
      "g_norm_l2: 33.03032650580462\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.6708104490186625e-85\n",
      "yk norm: 1.5923794914491085e-83\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.709106054833688e-10\n",
      "yk norm: 6.81747213037482e-09\n",
      "D_hat_inv: 278.90552132451484\n",
      "g_norm_D: 5.1100730270927194e-18\n",
      "g_norm_l2: 2.2629961783218083e-18\n",
      "yk norm: 4.402184989174822e-17\n",
      "g_norm_l2: 2.1168119671736416e-49\n",
      "yk norm: 1.4872432453268266e-47\n",
      "g_norm_l2: 3.567178689182075e-33\n",
      "yk norm: 1.2799466483026856e-31\n",
      "g_norm_l2: 6.8188292816365575e-124\n",
      "yk norm: 4.935236056523107e-122\n",
      "g_norm_l2: 1.4283996918131052e-12\n",
      "yk norm: 4.818448239863181e-11\n",
      "g_norm_l2: 34.23317323032481\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0319993975426525e-33\n",
      "yk norm: 6.985908349557564e-33\n",
      "g_norm_l2: 44.01082187663861\n",
      "yk norm: 4.863023106979075e-11\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 3.64358367154394e-14\n",
      "g_norm_l2: 1.3620388164376955\n",
      "yk norm: 38.303370849507445\n",
      "D_hat_inv: 279.9700429218112\n",
      "g_norm_D: 10.136645775608734\n",
      "loss:  tensor(0.0382, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 1.3620388164376955\n",
      "D_inv norm: 279.9700429218112\n",
      "B norm: 47.589994075544155\n",
      "a: 10.136645775608734\n",
      "b: 2635.877495704138\n",
      "c: 260.0344881387399\n",
      "plms: 1370838.1107836978 -680047.1434041543 -5291.257946709073 -0.07648263723924263\n",
      "lmds:  [ 5.03743881e-01 -7.64810593e-03 -1.44814819e-05]\n",
      "lmd_max: tensor([0.5037], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5037], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5037], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(279.9700, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(47.5900, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5037], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.9704, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.55522096467388\n",
      "yk norm: 3.930320186700482e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 43.33387368350502\n",
      "yk norm: 2.285988139375739e-13\n",
      "g_norm_l2: 1.573030094338701e-22\n",
      "yk norm: 4.234241683586506e-21\n",
      "g_norm_l2: 25.451918977991596\n",
      "yk norm: 1046.5865571156012\n",
      "D_hat_inv: 280.55474177984564\n",
      "g_norm_D: 3542.1141831465775\n",
      "loss:  tensor(1.0270, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 25.451918977991596\n",
      "D_inv norm: 280.5547417798456\n",
      "B norm: 361.37927514850475\n",
      "a: 3542.1141831465775\n",
      "b: 6999182.089863725\n",
      "c: 1975.9899675639813\n",
      "plms: 27660627181.448437 -13810336505.37221 -13999397.040151168 -2.053929656337861\n",
      "lmds:  [ 5.00289419e-01 -1.01149355e-03 -1.46736816e-07]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(280.5547, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(361.3793, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.2967, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.9684527368060526\n",
      "yk norm: 4.616574506056889\n",
      "D_hat_inv: 280.79236974565555\n",
      "g_norm_D: 5.0816752652683554\n",
      "loss:  tensor(0.0250, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.9684527368060526\n",
      "D_inv norm: 280.79236974565555\n",
      "B norm: 36.98192512491366\n",
      "a: 5.0816752652683554\n",
      "b: 1018.2313659825384\n",
      "c: 200.37316688491057\n",
      "plms: 408052.48684693925 -201964.38573461896 -2046.3726058721675 -0.050089602189990465\n",
      "lmds:  [ 5.04880550e-01 -9.90893593e-03 -2.45366853e-05]\n",
      "lmd_max: tensor([0.5049], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5049], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5049], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(280.7924, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(36.9819, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5049], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.7040, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.1619203207385348e-27\n",
      "yk norm: 1.9189027266693905e-25\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 1.208075762196138e-13\n",
      "g_norm_l2: 2.5962225998080697e-09\n",
      "yk norm: 7.833536072247755e-08\n",
      "D_hat_inv: 281.13465396680454\n",
      "g_norm_D: 3.550474328551291e-17\n",
      "g_norm_l2: 42.93269227030871\n",
      "yk norm: 1.5449544372227517e-08\n",
      "D_hat_inv: 281.24911304241925\n",
      "g_norm_D: 10293.295165928681\n",
      "loss:  tensor(23.8994, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 42.93269227030871\n",
      "D_inv norm: 281.24911304241925\n",
      "B norm: 7.695115878098583e-08\n",
      "a: 10293.295165928681\n",
      "b: 0.00442331400251288\n",
      "c: 4.29727694699193e-07\n",
      "plms: 3.80164105846104e-09 0.017693254100404194 20586.581444148487 -47.79872173252182\n",
      "lmds:  [ 2.32183700e-03 -2.32813346e+06 -2.32597613e+06]\n",
      "lmd_max: tensor([0.0023], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0023], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0023], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(281.2491, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(7.6951e-08, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0023], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.6530, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 50.31966006805973\n",
      "yk norm: 2.1479891851996307\n",
      "D_hat_inv: 281.36346024217795\n",
      "g_norm_D: 13836.486756501292\n",
      "loss:  tensor(7.4620, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.31966006805973\n",
      "D_inv norm: 281.36346024217795\n",
      "B norm: 1.4555234845764609\n",
      "a: 13836.486756501292\n",
      "b: 110051.37761375403\n",
      "c: 7.953708159482366\n",
      "plms: 1750633.0801775805 -436055.1439609309 -192667.1840200027 -14.924001530921219\n",
      "lmds:  [ 4.78920829e-01 -2.29759096e-01 -7.74735962e-05]\n",
      "lmd_max: tensor([0.4789], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.4789], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.4789], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(281.3635, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1.4555, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.4789], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(134.6961, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 3.7547955671551265e-37\n",
      "yk norm: 2.0142043105580157e-36\n",
      "g_norm_l2: 50.201075393436085\n",
      "yk norm: 43.81578904167281\n",
      "D_hat_inv: 281.61650253445026\n",
      "g_norm_D: 14175.261207701828\n",
      "loss:  tensor(4.5933, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.201075393436085\n",
      "D_inv norm: 281.61650253445026\n",
      "B norm: 25.76425021065283\n",
      "a: 14175.261207701828\n",
      "b: 2054251.4764733426\n",
      "c: 144.91806862488068\n",
      "plms: 595396312.8806525 -289674078.7561492 -4082815.0139281885 -9.186512841952194\n",
      "lmds:  [ 5.00231461e-01 -1.37060784e-02 -2.25040317e-06]\n",
      "lmd_max: tensor([0.5002], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(281.6165, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(25.7643, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.8089, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.0496580704609967e-148\n",
      "yk norm: 1.2165867174605212e-146\n",
      "g_norm_l2: 4.634604420475687e-38\n",
      "yk norm: 5.191856948407049e-37\n",
      "g_norm_l2: 39.44225841247945\n",
      "yk norm: 2.672811764873399e-13\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 3.627398988538234e-13\n",
      "g_norm_l2: 34.61815464985951\n",
      "yk norm: 2.318899709838348\n",
      "D_hat_inv: 282.2094489927251\n",
      "g_norm_D: 6402.404102954517\n",
      "loss:  tensor(3.3306, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 34.61815464985951\n",
      "D_inv norm: 282.2094489927251\n",
      "B norm: 44.460070004244436\n",
      "a: 6402.404102954517\n",
      "b: 1520717.2738966437\n",
      "c: 237.52285070460925\n",
      "plms: 722410204.0233457 -355498037.67678195 -3031794.1068015713 -6.661184818230904\n",
      "lmds:  [ 5.00485416e-01 -8.38325114e-03 -2.19767622e-06]\n",
      "lmd_max: tensor([0.5005], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(282.2094, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(44.4601, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.1813, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.965519917184524e-39\n",
      "yk norm: 7.297098646602373e-38\n",
      "g_norm_l2: 1.4911534003390118e-44\n",
      "yk norm: 7.333971318531234e-43\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 4.303590178250623e-14\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.1076004607617587e-70\n",
      "yk norm: 2.456141461057201e-69\n",
      "g_norm_l2: 2.1191472552536906e-131\n",
      "yk norm: 2.5626276392637484e-130\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 2.4256823907804497e-13\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 1628.3480893959413\n",
      "D_hat_inv: 280.4165151011953\n",
      "g_norm_D: 10763.91388192068\n",
      "loss:  tensor(418.5414, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 280.4165151011953\n",
      "B norm: 2133.4178598687618\n",
      "a: 10763.91388192068\n",
      "b: 115861842.05740474\n",
      "c: 10763.913881920682\n",
      "plms: 2494253780213.2007 -1343649403336.5693 -249722731.6394922 -837.0828469147425\n",
      "lmds:  [ 5.38883743e-01 -1.82376373e-04 -3.41479113e-06]\n",
      "lmd_max: tensor([0.5389], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5389], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5389], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(280.4165, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5389], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(151.0446, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 2405.6566426297686\n",
      "D_hat_inv: 277.2903323269268\n",
      "g_norm_D: 13145.218049325733\n",
      "loss:  tensor(496.8708, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 277.2903323269268\n",
      "B norm: 2584.798857508483\n",
      "a: 13145.218049325733\n",
      "b: 172796757.564319\n",
      "c: 13145.218049325733\n",
      "plms: 4542902112798.898 -2442475183424.207 -371693122.8572827 -993.7415289236466\n",
      "lmds:  [ 5.37798584e-01 -1.49414330e-04 -2.72225099e-06]\n",
      "lmd_max: tensor([0.5378], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5378], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5378], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.2903, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5378], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(149.0599, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.4319525656631653e-71\n",
      "yk norm: 8.800199589335077e-71\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.913584901568214\n",
      "yk norm: 4.769842527381058e-13\n",
      "g_norm_l2: 44.71600053315354\n",
      "yk norm: 4.581734721563506e-11\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.536424588487791e-127\n",
      "yk norm: 1.6644599114547967e-125\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 5897.344458983545\n",
      "D_hat_inv: 277.56882075948545\n",
      "g_norm_D: 11272.644595136531\n",
      "loss:  tensor(390.3785, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.961743348969875\n",
      "D_inv norm: 277.56882075948545\n",
      "B norm: 2205.4053383745163\n",
      "a: 11272.644595136531\n",
      "b: 127072516.16826081\n",
      "c: 11272.644595136531\n",
      "plms: 2864886625149.0903 -1531147770318.409 -271724877.8565549 -780.7569315552591\n",
      "lmds:  [ 5.34630588e-01 -1.74485465e-04 -2.92142910e-06]\n",
      "lmd_max: tensor([0.5346], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5346], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5346], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.5688, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2205.4053, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5346], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.3322, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 3.929954419618759e-26\n",
      "yk norm: 4.383238733102834e-25\n",
      "g_norm_l2: 40.53680293480847\n",
      "yk norm: 1.1016398913765362\n",
      "D_hat_inv: 277.80555173719847\n",
      "g_norm_D: 8910.737446541852\n",
      "loss:  tensor(6.2426, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 40.53680293480847\n",
      "D_inv norm: 277.80555173719847\n",
      "B norm: 3.202032998786713\n",
      "a: 8910.737446541852\n",
      "b: 154722.72682233225\n",
      "c: 17.363627617866605\n",
      "plms: 5373095.625127758 -2071421.1264474916 -292057.55418360274 -12.485162708044882\n",
      "lmds:  [ 4.95274961e-01 -1.09714935e-01 -4.27619513e-05]\n",
      "lmd_max: tensor([0.4953], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.4953], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.4953], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.8056, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3.2020, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.4953], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(137.5290, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 7.05958261410044e-18\n",
      "yk norm: 2.0413142918383274e-16\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 2.994373324882886e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "Loss: 103.1521347039777 | GradNorm^2: 55.73156991869218\n",
      "g_norm_l2: 1.5109603484586978e-150\n",
      "yk norm: 1.2521136304564237e-149\n",
      "g_norm_l2: 54.0229356749543\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.594525391893452e-29\n",
      "yk norm: 7.535545763904035e-27\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 408.1779994597071\n",
      "D_hat_inv: 277.5830688718442\n",
      "g_norm_D: 9115.684020174765\n",
      "loss:  tensor(373.1751, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 277.5830688718442\n",
      "B norm: 1722.8004622114447\n",
      "a: 9115.684020174765\n",
      "b: 83095695.15566947\n",
      "c: 9115.684020174755\n",
      "plms: 1514948200951.698 -819160212285.2472 -179780145.419083 -746.3502708995587\n",
      "lmds:  [ 5.40937679e-01 -2.15148411e-04 -4.23310981e-06]\n",
      "lmd_max: tensor([0.5409], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5409], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5409], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.5831, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5409], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.0867, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.6059235952605963e-79\n",
      "yk norm: 9.607512373605099e-79\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.112706105386839e-32\n",
      "yk norm: 4.325177894194257e-31\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 3.513388399066811e-13\n",
      "g_norm_l2: 3.1675828794578593e-137\n",
      "yk norm: 5.7859584042957856e-136\n",
      "g_norm_l2: 3.5421617222727463e-25\n",
      "yk norm: 1.2256927435362224e-23\n",
      "g_norm_l2: 2.2890801903329235e-17\n",
      "yk norm: 2.107068931874245e-15\n",
      "g_norm_l2: 0.09010108965208355\n",
      "yk norm: 4.362893622980248\n",
      "D_hat_inv: 278.60574013593526\n",
      "g_norm_D: 0.043674908713268255\n",
      "loss:  tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.09010108965208355\n",
      "D_inv norm: 278.60574013593526\n",
      "B norm: 4.190535118147594\n",
      "a: 0.043674908713268255\n",
      "b: 0.9846307846532132\n",
      "c: 22.544541331899485\n",
      "plms: 44.39609884254997 -20.226882814304815 -2.0564423846108353 -0.003870795820627159\n",
      "lmds:  [ 0.54144702 -0.08392793 -0.00191864]\n",
      "lmd_max: tensor([0.5414], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5414], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5414], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(278.6057, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(4.1905, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5414], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.7837, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0191082783533638e-47\n",
      "yk norm: 3.0216107526663955e-46\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 4065.0389616806033\n",
      "D_hat_inv: 279.37087037004875\n",
      "g_norm_D: 10879.783292591686\n",
      "loss:  tensor(443.7395, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 279.37087037004875\n",
      "B norm: 2133.4178598687613\n",
      "a: 10879.783292591686\n",
      "b: 118369684.49375717\n",
      "c: 10879.783292591685\n",
      "plms: 2575673031409.0566 -1392413636618.596 -256028766.05464157 -887.4789191280056\n",
      "lmds:  [ 5.40785675e-01 -1.80278494e-04 -3.53425770e-06]\n",
      "lmd_max: tensor([0.5408], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5408], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5408], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(279.3709, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5408], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(151.0126, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.319629746506536\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.532458031037541e-44\n",
      "yk norm: 5.892904991438833e-44\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.2854904327631345e-70\n",
      "yk norm: 1.063556637841589e-68\n",
      "g_norm_l2: 42.33001765211567\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 8.475879995894137e-14\n",
      "g_norm_l2: 7.29718061853524e-110\n",
      "yk norm: 3.984955041929589e-108\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.20738507735562\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.91358489558876\n",
      "yk norm: 1.5024735353399585e-07\n",
      "D_hat_inv: 280.8684898149628\n",
      "g_norm_D: 11299.721120144692\n",
      "loss:  tensor(22.7617, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 45.91358489558876\n",
      "D_inv norm: 280.8684898149628\n",
      "B norm: 2.745385490180381e-07\n",
      "a: 11299.721120144692\n",
      "b: 0.016628626452405124\n",
      "c: 1.4715961814986983e-06\n",
      "plms: 4.894124638185525e-08 0.06651448124041204 22599.408849052375 -45.52339356286294\n",
      "lmds:  [ 2.01436173e-03 -6.80116890e+05 -6.78951099e+05]\n",
      "lmd_max: tensor([0.0020], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0020], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0020], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(280.8685, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2.7454e-07, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0020], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.5658, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.02996086757096\n",
      "yk norm: 2764.6631878534267\n",
      "D_hat_inv: 277.00923048420634\n",
      "g_norm_D: 10796.850141091094\n",
      "loss:  tensor(407.7958, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757096\n",
      "D_inv norm: 277.0092304842063\n",
      "B norm: 2118.757297470115\n",
      "a: 10796.850141091094\n",
      "b: 116571972.96917886\n",
      "c: 10796.850141091101\n",
      "plms: 2517220245599.0933 -1353218955019.715 -250733992.4608483 -815.5915842411139\n",
      "lmds:  [ 5.37769871e-01 -1.81912365e-04 -3.31201913e-06]\n",
      "lmd_max: tensor([0.5378], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5378], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5378], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.0092, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5378], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.9030, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 2.0853873090450663e-14\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 1445.90676569324\n",
      "D_hat_inv: 277.5797113458878\n",
      "g_norm_D: 10207.942958857093\n",
      "loss:  tensor(439.5332, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 277.5797113458878\n",
      "B norm: 1936.9524422572576\n",
      "a: 10207.942958857093\n",
      "b: 104202099.45128012\n",
      "c: 10207.942958857097\n",
      "plms: 2127378174783.644 -1154872849545.8547 -226330703.5511777 -879.0664586817281\n",
      "lmds:  [ 5.43057947e-01 -1.91945418e-04 -3.96417744e-06]\n",
      "lmd_max: tensor([0.5431], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5431], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5431], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.5797, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5431], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.6748, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 8.685042962148725e-14\n",
      "yk norm: 2.489838412472686e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.043389524252174e-92\n",
      "yk norm: 3.3358311178292696e-90\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.7800620230279674e-83\n",
      "yk norm: 7.736167468176189e-82\n",
      "g_norm_l2: 6.594169932431117e-113\n",
      "yk norm: 2.9641751292087825e-111\n",
      "g_norm_l2: 2.4068444335777373e-18\n",
      "yk norm: 8.972041332769784e-18\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 1853.4978495183723\n",
      "D_hat_inv: 278.4597074845489\n",
      "g_norm_D: 13128.626707278825\n",
      "loss:  tensor(525.5384, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 278.4597074845489\n",
      "B norm: 2584.798857508483\n",
      "a: 13128.626707278825\n",
      "b: 172360839.21907485\n",
      "c: 13128.626707278825\n",
      "plms: 4525722234121.075 -2443336154551.388 -372293811.3114473 -1051.076808795659\n",
      "lmds:  [ 5.40029950e-01 -1.49451324e-04 -2.87759024e-06]\n",
      "lmd_max: tensor([0.5400], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5400], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5400], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(278.4597, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5400], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.3124, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 1289.9891966735838\n",
      "D_hat_inv: 279.0375574706612\n",
      "g_norm_D: 12077.659536573887\n",
      "loss:  tensor(389.3376, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 279.0375574706612\n",
      "B norm: 2249.2786885991136\n",
      "a: 12077.659536573887\n",
      "b: 145869859.8813942\n",
      "c: 12077.659536573894\n",
      "plms: 3523533008590.4375 -1874768255545.6035 -310524710.42865527 -778.6751202905508\n",
      "lmds:  [ 5.32236164e-01 -1.63036131e-04 -2.54676992e-06]\n",
      "lmd_max: tensor([0.5322], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5322], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5322], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(279.0376, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5322], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.4472, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 4.461574022428531e-13\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 2.890322910528069e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.9341301800960745e-62\n",
      "yk norm: 2.5809456736348798e-61\n",
      "g_norm_l2: 3.2769088550839434e-18\n",
      "yk norm: 1.5782562096237243e-16\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 4718.0393435067945\n",
      "D_hat_inv: 277.15207904237565\n",
      "g_norm_D: 19993.591690816003\n",
      "loss:  tensor(606.6966, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 277.15207904237565\n",
      "B norm: 3845.1662222815285\n",
      "a: 19993.591690816003\n",
      "b: 399743708.6990669\n",
      "c: 19993.591690816007\n",
      "plms: 15984624985403.273 -8475759790151.405 -847967604.0569906 -1213.3931359748165\n",
      "lmds:  [ 5.30344547e-01 -9.85755890e-05 -1.45201660e-06]\n",
      "lmd_max: tensor([0.5303], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5303], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5303], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.1521, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5303], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(146.9205, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.4454309162893366e-73\n",
      "yk norm: 3.2204818238866077e-72\n",
      "Loss: 102.218932544962 | GradNorm^2: 55.45922794703986\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.4973286757618538e-138\n",
      "yk norm: 1.880882088021929e-136\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 7.738844227559553e-13\n",
      "g_norm_l2: 9.583040343363282e-28\n",
      "yk norm: 7.376219170827106e-26\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.9534767735388685e-47\n",
      "yk norm: 2.0901688581054434e-46\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.319629746506514\n",
      "yk norm: 5.348223413613231e-13\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 3.51438655709288e-14\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 126.16105809405846\n",
      "D_hat_inv: 279.2886967695663\n",
      "g_norm_D: 10335.859441778428\n",
      "loss:  tensor(437.4731, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 279.2886967695663\n",
      "B norm: 1936.9524422572636\n",
      "a: 10335.859441778428\n",
      "b: 106829990.40020065\n",
      "c: 10335.859441778462\n",
      "plms: 2208359529886.0327 -1197222945244.5818 -231725952.14969844 -874.9462572542767\n",
      "lmds:  [ 5.42325746e-01 -1.89632716e-04 -3.85245975e-06]\n",
      "lmd_max: tensor([0.5423], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5423], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5423], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(279.2887, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5423], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(151.3981, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 884.6147854575577\n",
      "D_hat_inv: 279.0285507626589\n",
      "g_norm_D: 12170.635509210206\n",
      "loss:  tensor(387.8483, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 279.0285507626589\n",
      "B norm: 2249.2786885991127\n",
      "a: 12170.635509210206\n",
      "b: 148124368.69804835\n",
      "c: 12170.635509210206\n",
      "plms: 3605535402911.624 -1917074779424.1995 -315105838.32359433 -775.696642308752\n",
      "lmds:  [ 5.31867537e-01 -1.61818309e-04 -2.49971795e-06]\n",
      "lmd_max: tensor([0.5319], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5319], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5319], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(279.0286, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5319], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.3386, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 62.0094043051659\n",
      "yk norm: 3082.150032690431\n",
      "D_hat_inv: 273.91383077176766\n",
      "g_norm_D: 19224.7072464736\n",
      "loss:  tensor(605.5321, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.0094043051659\n",
      "D_inv norm: 273.91383077176766\n",
      "B norm: 3845.1662222815303\n",
      "a: 19224.7072464736\n",
      "b: 369589368.7126149\n",
      "c: 19224.707246473616\n",
      "plms: 14210494829818.031 -7551365539474.598 -785705000.4198201 -1211.0642781731985\n",
      "lmds:  [ 5.31497595e-01 -1.02463096e-04 -1.56490945e-06]\n",
      "lmd_max: tensor([0.5315], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5315], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5315], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(273.9138, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5315], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(145.5176, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 5.332674506728448\n",
      "D_hat_inv: 274.14532787207526\n",
      "g_norm_D: 8915.052669038523\n",
      "loss:  tensor(371.0243, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 274.14532787207526\n",
      "B norm: 11.072205762614448\n",
      "a: 8915.052669038523\n",
      "b: -510795.4204568081\n",
      "c: -57.29583878183601\n",
      "plms: 58532904.12198683 -33745640.58271669 1124453.5382055894 -742.0485829492154\n",
      "lmds:  [0.5410622  0.00067352 0.03478856]\n",
      "lmd_max: tensor([0.5411], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.0007], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5411], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5411], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.1453, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(11.0722, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5411], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.2617, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.3133294603102122e-06\n",
      "yk norm: 7.029569035612776e-05\n",
      "D_hat_inv: 274.26167755120065\n",
      "g_norm_D: 8.81493505351239e-12\n",
      "loss:  tensor(2.8183e-08, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 1.3133294603102122e-06\n",
      "D_inv norm: 274.26167755120065\n",
      "B norm: 6.120031367638041e-05\n",
      "a: 8.81493505351239e-12\n",
      "b: 2.7570491545490826e-15\n",
      "c: 0.00031277021756961345\n",
      "plms: 1.7246457278368707e-18 5.513236070206905e-15 -1.7635383668373177e-11 -5.6366843286862945e-08\n",
      "lmds:  [ 3197.61032863 -3225.44416069 -3168.90157929]\n",
      "lmd_max: tensor([3197.6103], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([3197.6103], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([3197.6103], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.2617, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(6.1200e-05, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([3197.6103], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(876719.3517, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.2991502514636906e-24\n",
      "yk norm: 1.2270892650395275e-22\n",
      "g_norm_l2: 3.0127113495867883e-96\n",
      "yk norm: 1.547351509259272e-94\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 3.8152681977430145e-13\n",
      "g_norm_l2: 7.164368661245447e-16\n",
      "yk norm: 3.253470581788924e-14\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.978219780385693e-31\n",
      "yk norm: 9.594105745683138e-30\n",
      "g_norm_l2: 4.0467586110321264e-32\n",
      "yk norm: 1.3721037670969559e-30\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.7464835448480736e-11\n",
      "yk norm: 7.977181174251069e-10\n",
      "D_hat_inv: 275.42639048385166\n",
      "g_norm_D: 1.6114492320565269e-21\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 8.870037074941555e-16\n",
      "g_norm_l2: 1.508835748987628e-67\n",
      "yk norm: 1.78294695576057e-65\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.537814217698196e-119\n",
      "yk norm: 8.550993737193431e-118\n",
      "g_norm_l2: 0.2748888219697539\n",
      "yk norm: 13.3636005045975\n",
      "D_hat_inv: 276.0068591379828\n",
      "g_norm_D: 0.4027756207549853\n",
      "loss:  tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.2748888219697539\n",
      "D_inv norm: 276.0068591379829\n",
      "B norm: 12.545567401556449\n",
      "a: 0.4027756207549853\n",
      "b: 26.934101914632148\n",
      "c: 66.87123183907048\n",
      "plms: 3602.2331470210365 -1747.0867899687853 -54.66892250801073 -0.012010171459993339\n",
      "lmds:  [ 5.14510401e-01 -2.92881155e-02 -2.21254342e-04]\n",
      "lmd_max: tensor([0.5145], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5145], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5145], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.0069, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(12.5456, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5145], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.9451, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 1643.7269102819068\n",
      "D_hat_inv: 275.05897852563214\n",
      "g_norm_D: 12935.373113355388\n",
      "loss:  tensor(564.6941, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 275.05897852563214\n",
      "B norm: 2584.7988575084837\n",
      "a: 12935.373113355388\n",
      "b: 167323877.5817175\n",
      "c: 12935.37311335539\n",
      "plms: 4328793574585.8345 -2352701093261.792 -363839998.1620823 -1129.3881316305913\n",
      "lmds:  [ 5.43655017e-01 -1.51435664e-04 -3.16901855e-06]\n",
      "lmd_max: tensor([0.5437], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5437], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5437], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.0590, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5437], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(149.4674, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 6.992161981622501e-63\n",
      "yk norm: 8.891734433734795e-62\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 4.859013614779296e-13\n",
      "g_norm_l2: 9.423895796654223e-07\n",
      "yk norm: 4.490485667404636e-05\n",
      "D_hat_inv: 275.5072146098614\n",
      "g_norm_D: 4.608911090142851e-12\n",
      "loss:  tensor(2.2263e-08, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 9.423895796654223e-07\n",
      "D_inv norm: 275.5072146098614\n",
      "B norm: 3.9891366654309075e-05\n",
      "a: 4.608911090142851e-12\n",
      "b: 9.541455412630688e-16\n",
      "c: 0.00020702190226748232\n",
      "plms: 3.950580499846341e-19 1.9080935817742684e-15 -9.219730198226857e-12 -4.452583008248637e-08\n",
      "lmds:  [ 4830.78171658 -4865.09422912 -4795.59433747]\n",
      "lmd_max: tensor([4830.7817], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([4830.7817], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([4830.7817], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.5072, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3.9891e-05, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([4830.7817], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(1330503.9502, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 4.4729570992850174e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.006607597588374e-82\n",
      "yk norm: 2.385867238775193e-81\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 1161.517010630297\n",
      "D_hat_inv: 276.56136770229307\n",
      "g_norm_D: 10820.980359725518\n",
      "loss:  tensor(415.4112, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 276.56136770229307\n",
      "B norm: 2118.7572974701166\n",
      "a: 10820.980359725518\n",
      "b: 117093615.94556546\n",
      "c: 10820.980359725525\n",
      "plms: 2534135436792.415 -1363883340792.9336 -252146215.27607578 -830.8223815185078\n",
      "lmds:  [ 5.38389408e-01 -1.81455490e-04 -3.35592114e-06]\n",
      "lmd_max: tensor([0.5384], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5384], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5384], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.5614, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5384], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.8306, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 2091.8569235548193\n",
      "D_hat_inv: 273.98827751381793\n",
      "g_norm_D: 10225.821545517158\n",
      "loss:  tensor(460.4527, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 273.98827751381793\n",
      "B norm: 2133.417859868761\n",
      "a: 10225.821545517158\n",
      "b: 104567426.2807629\n",
      "c: 10225.821545517156\n",
      "plms: 2138575681242.2039 -1165166274998.7185 -227948428.80638564 -920.9053670708458\n",
      "lmds:  [ 5.45028413e-01 -1.91440182e-04 -4.12703487e-06]\n",
      "lmd_max: tensor([0.5450], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5450], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5450], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(273.9883, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5450], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(149.2653, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.14033068933095108\n",
      "yk norm: 5.324147101704005\n",
      "D_hat_inv: 274.1022609781965\n",
      "g_norm_D: 0.10743647639809009\n",
      "loss:  tensor(0.0031, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.14033068933095108\n",
      "D_inv norm: 274.1022609781965\n",
      "B norm: 6.255334476572936\n",
      "a: 0.10743647639809009\n",
      "b: 3.6664750343053805\n",
      "c: 34.1269106845965\n",
      "plms: 250.25093204608527 -117.78099752609775 -7.54714798647978 -0.006286400703402437\n",
      "lmds:  [ 0.52787346 -0.05637779 -0.00084409]\n",
      "lmd_max: tensor([0.5279], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5279], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5279], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.1023, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(6.2553, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5279], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(144.6249, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.4367362091720063e-54\n",
      "yk norm: 3.5423181216589927e-53\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 3.5107104759018805e-13\n",
      "g_norm_l2: 6.459360809521711e-93\n",
      "yk norm: 1.7683414869665326e-91\n",
      "g_norm_l2: 1.0421188745187248e-30\n",
      "yk norm: 2.0622964221012445e-29\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.3603882832287766e-67\n",
      "yk norm: 2.348648564516389e-67\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.3644980307045\n",
      "yk norm: 4.733765306796602e-13\n",
      "Loss: 114.04337292414353 | GradNorm^2: 58.95408921664951\n",
      "g_norm_l2: 46.02996086757096\n",
      "yk norm: 5885.266376717116\n",
      "D_hat_inv: 275.25015651649426\n",
      "g_norm_D: 10856.697562518784\n",
      "loss:  tensor(414.0855, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757096\n",
      "D_inv norm: 275.25015651649426\n",
      "B norm: 2118.757297470114\n",
      "a: 10856.697562518784\n",
      "b: 117867881.96400133\n",
      "c: 10856.697562518784\n",
      "plms: 2559311893635.6494 -1376799237282.7568 -253696454.74569994 -828.1710027045443\n",
      "lmds:  [ 5.38141004e-01 -1.80879045e-04 -3.32439385e-06]\n",
      "lmd_max: tensor([0.5381], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5381], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5381], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.2502, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5381], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.0547, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 2.6931069022971758e-14\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 1.6040554263613506e-13\n",
      "g_norm_l2: 6.90467687168893e-16\n",
      "yk norm: 1.6239467314689756e-15\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 1226.5311675575301\n",
      "D_hat_inv: 274.82750534980295\n",
      "g_norm_D: 8912.767210413582\n",
      "loss:  tensor(531.5231, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 274.82750534980295\n",
      "B norm: 1722.800462211447\n",
      "a: 8912.767210413582\n",
      "b: 79437419.34702349\n",
      "c: 8912.767210413582\n",
      "plms: 1416014452872.049 -792135122436.9137 -177806379.54263052 -1063.0461861981614\n",
      "lmds:  [ 5.59636127e-01 -2.18230098e-04 -6.14701190e-06]\n",
      "lmd_max: tensor([0.5596], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5596], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5596], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.8275, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5596], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(153.7343, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 5.057033986180964e-13\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 1.7968082855704548e-13\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 1.9015853889991373e-13\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.3815925226415059e-67\n",
      "yk norm: 1.596307893704236e-66\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 1.1373479404263193e-13\n",
      "g_norm_l2: 2.5304940801003813e-96\n",
      "yk norm: 8.098687138338823e-95\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.1709322666240609e-06\n",
      "yk norm: 7.917038543157648e-06\n",
      "D_hat_inv: 276.01294006234684\n",
      "g_norm_D: 7.1469634197844405e-12\n",
      "loss:  tensor(2.7662e-08, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 1.1709322666240609e-06\n",
      "D_inv norm: 276.0129400623468\n",
      "B norm: 4.956558214454586e-05\n",
      "a: 7.1469634197844405e-12\n",
      "b: 1.846544517639256e-15\n",
      "c: 0.00025836770236259995\n",
      "plms: 9.541749286654199e-19 3.6926119933768535e-15 -1.4297619575907798e-11 -5.532396864047748e-08\n",
      "lmds:  [ 3870.82777582 -3901.49610862 -3839.28452641]\n",
      "lmd_max: tensor([3870.8278], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([3870.8278], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([3870.8278], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.0129, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(4.9566e-05, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([3870.8278], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(1068073.8919, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.96174334896987\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.038167389920243e-31\n",
      "yk norm: 8.232225265478373e-30\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.2358892797282227e-54\n",
      "yk norm: 4.527026233455771e-53\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 2263.45733370992\n",
      "D_hat_inv: 274.20853086267465\n",
      "g_norm_D: 18961.380272440852\n",
      "loss:  tensor(675.1381, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 274.20853086267465\n",
      "B norm: 3845.1662222815294\n",
      "a: 18961.380272440852\n",
      "b: 359533941.8361091\n",
      "c: 18961.380272440856\n",
      "plms: 13634519584008.2 -7301291805600.626 -770236164.5095699 -1350.2762684508111\n",
      "lmds:  [ 5.35605954e-01 -1.03689496e-04 -1.78321055e-06]\n",
      "lmd_max: tensor([0.5356], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5356], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5356], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.2085, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5356], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(146.8020, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.0833749287837689e-30\n",
      "yk norm: 2.4844251229362304e-29\n",
      "g_norm_l2: 6.989036040277872e-32\n",
      "yk norm: 1.6596075118049952e-30\n",
      "g_norm_l2: 0.05469090831925389\n",
      "yk norm: 0.9355962587386862\n",
      "D_hat_inv: 274.55352983440343\n",
      "g_norm_D: 0.01634599590051323\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.05469090831925389\n",
      "D_inv norm: 274.55352983440343\n",
      "B norm: 2.4425675901097854\n",
      "a: 0.01634599590051323\n",
      "b: 0.21819213354954908\n",
      "c: 13.348353619903838\n",
      "plms: 5.825011511401329 -2.4758545149493254 -0.46903625791425874 -0.00244764202675722\n",
      "lmds:  [ 0.5680825  -0.13767119 -0.00537275]\n",
      "lmd_max: tensor([0.5681], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5681], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5681], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.5535, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2.4426, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5681], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(155.9003, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 9.86018582310785e-14\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 4219.029366592196\n",
      "D_hat_inv: 273.95169521435173\n",
      "g_norm_D: 12487.784415800332\n",
      "loss:  tensor(561.8203, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 273.95169521435173\n",
      "B norm: 2584.7988575084833\n",
      "a: 12487.784415800332\n",
      "b: 155944759.6155056\n",
      "c: 12487.784415800332\n",
      "plms: 3894809077704.4805 -2122006629462.1206 -339928107.8323996 -1123.640640957582\n",
      "lmds:  [ 5.44989581e-01 -1.56769018e-04 -3.37670275e-06]\n",
      "lmd_max: tensor([0.5450], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5450], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5450], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(273.9517, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5450], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(149.2335, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.3592290079461976e-07\n",
      "yk norm: 1.4581612088854751e-05\n",
      "D_hat_inv: 274.06436390646877\n",
      "g_norm_D: 2.867652960102183e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.391693923844282e-54\n",
      "yk norm: 2.678837954618094e-54\n",
      "g_norm_l2: 9.936171352439239e-127\n",
      "yk norm: 1.2438129237669633e-125\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 406.64655085347994\n",
      "D_hat_inv: 273.3652052502078\n",
      "g_norm_D: 9772.151442862702\n",
      "loss:  tensor(484.2550, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 273.3652052502078\n",
      "B norm: 1936.9524422572595\n",
      "a: 9772.151442862702\n",
      "b: 95494943.82224368\n",
      "c: 9772.151442862712\n",
      "plms: 1866382106117.2646 -1025296877945.1554 -209899195.43780252 -968.5099646110149\n",
      "lmds:  [ 5.49554575e-01 -1.99922755e-04 -4.72313628e-06]\n",
      "lmd_max: tensor([0.5496], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5496], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5496], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(273.3652, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5496], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.1601, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 6.835651685309084e-119\n",
      "yk norm: 5.074842857289695e-118\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 4.536252515812147e-13\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 1302.5461296729209\n",
      "D_hat_inv: 271.3646241663389\n",
      "g_norm_D: 11626.569319620015\n",
      "loss:  tensor(420.8334, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 271.3646241663389\n",
      "B norm: 2249.2786885991127\n",
      "a: 11626.569319620015\n",
      "b: 135177114.14392942\n",
      "c: 11626.569319620015\n",
      "plms: 3143292176041.1655 -1684879475839.3674 -289902371.17287123 -841.666853119973\n",
      "lmds:  [ 5.36195826e-01 -1.69052936e-04 -2.95399204e-06]\n",
      "lmd_max: tensor([0.5362], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5362], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5362], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(271.3646, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5362], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(145.4374, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 2631.2458445172465\n",
      "D_hat_inv: 271.7781284055308\n",
      "g_norm_D: 10564.726927294776\n",
      "loss:  tensor(458.4044, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 271.7781284055308\n",
      "B norm: 2133.4178598687613\n",
      "a: 10564.726927294776\n",
      "b: 111613455.0483073\n",
      "c: 10564.726927294774\n",
      "plms: 2358331347994.514 -1281047416107.7144 -242577449.52447578 -916.8087833708033\n",
      "lmds:  [ 5.43390069e-01 -1.85435980e-04 -3.85805346e-06]\n",
      "lmd_max: tensor([0.5434], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5434], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5434], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(271.7781, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5434], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(147.6133, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.175624057460036e-68\n",
      "yk norm: 4.330287028935423e-67\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 6.917920369762061e-15\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.55522096467388\n",
      "yk norm: 9.192650064710493e-14\n",
      "g_norm_l2: 1.1225546028575667e-24\n",
      "yk norm: 5.97895477234842e-23\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.042111653930999e-63\n",
      "yk norm: 3.598943754826684e-61\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.002277777402777e-82\n",
      "yk norm: 8.425858613525646e-81\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.916442913894755e-93\n",
      "yk norm: 3.0604465977770964e-92\n",
      "g_norm_l2: 7.735855198938884e-30\n",
      "yk norm: 1.3047497995599165e-28\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.2164109732884183e-11\n",
      "yk norm: 3.1985676670889164e-10\n",
      "D_hat_inv: 273.8602897767703\n",
      "g_norm_D: 7.809108059201005e-22\n",
      "g_norm_l2: 0.12645355717994544\n",
      "yk norm: 0.21155804399572783\n",
      "D_hat_inv: 273.97697110211\n",
      "g_norm_D: 0.0828131635108117\n",
      "loss:  tensor(0.0028, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.12645355717994544\n",
      "D_inv norm: 273.97697110211\n",
      "B norm: 5.789945631563262\n",
      "a: 0.0828131635108117\n",
      "b: 2.483196770618032\n",
      "c: 29.985532074183325\n",
      "plms: 148.91995282375092 -69.48673745134455 -5.131563286778466 -0.005515928010642684\n",
      "lmds:  [ 0.53156089 -0.06386521 -0.00109106]\n",
      "lmd_max: tensor([0.5316], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5316], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5316], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(273.9770, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(5.7899, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5316], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(145.5707, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 1.293137568140813e-13\n",
      "Loss: 113.45931978169043 | GradNorm^2: 58.95476905037079\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 1.0643311339956485e-13\n",
      "g_norm_l2: 1.054669494322907e-24\n",
      "yk norm: 1.9183057823898735e-24\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 4165.833256318795\n",
      "D_hat_inv: 274.4212546620934\n",
      "g_norm_D: 9058.873923728901\n",
      "loss:  tensor(529.7036, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 274.4212546620934\n",
      "B norm: 1722.8004622114472\n",
      "a: 9058.873923728901\n",
      "b: 82063196.76601546\n",
      "c: 9058.873923728901\n",
      "plms: 1486800306562.9827 -830010238683.621 -183302347.56863928 -1059.4071595465462\n",
      "lmds:  [ 5.58473427e-01 -2.14819173e-04 -5.93929243e-06]\n",
      "lmd_max: tensor([0.5585], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5585], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5585], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.4213, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5585], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(153.1877, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 3036.1223113373053\n",
      "D_hat_inv: 274.1659119528419\n",
      "g_norm_D: 10689.533708664892\n",
      "loss:  tensor(411.1441, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 274.1659119528419\n",
      "B norm: 2118.757297470115\n",
      "a: 10689.533708664892\n",
      "b: 114266130.90868306\n",
      "c: 10689.533708664896\n",
      "plms: 2442903316214.1665 -1314954276944.0508 -246090636.16509333 -822.2881322173328\n",
      "lmds:  [ 5.38462286e-01 -1.83680520e-04 -3.40329307e-06]\n",
      "lmd_max: tensor([0.5385], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5385], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5385], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.1659, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5385], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(147.5609, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 7.614856669376157e-119\n",
      "yk norm: 3.72385766114372e-117\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 1955.4795515222893\n",
      "D_hat_inv: 273.44744603699183\n",
      "g_norm_D: 11691.365054574446\n",
      "loss:  tensor(419.0171, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 273.44744603699183\n",
      "B norm: 2249.278688599113\n",
      "a: 11691.365054574446\n",
      "b: 136688016.83932456\n",
      "c: 11691.36505457445\n",
      "plms: 3196139006908.7266 -1712071982800.0237 -292948178.22500604 -838.0341895491053\n",
      "lmds:  [ 5.35839865e-01 -1.68143500e-04 -2.91018752e-06]\n",
      "lmd_max: tensor([0.5358], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5358], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5358], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(273.4474, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5358], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(146.4578, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 6.290795252964121e-14\n",
      "g_norm_l2: 46.18893655269366\n",
      "yk norm: 2363.043329501433\n",
      "D_hat_inv: 274.32302951875306\n",
      "g_norm_D: 10742.62869686792\n",
      "loss:  tensor(456.7183, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269366\n",
      "D_inv norm: 274.323029518753\n",
      "B norm: 2133.4178598687613\n",
      "a: 10742.62869686792\n",
      "b: 115404071.31877019\n",
      "c: 10742.628696867923\n",
      "plms: 2479486176568.8257 -1344695778619.3315 -250412078.6052007 -913.4366354287195\n",
      "lmds:  [ 5.42514563e-01 -1.82437325e-04 -3.72213087e-06]\n",
      "lmd_max: tensor([0.5425], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5425], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5425], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.3230, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5425], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.7556, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 3.5722305628069854e-13\n",
      "g_norm_l2: 1.1375686391503103e-15\n",
      "yk norm: 3.236937430767786e-14\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 4.2464034332599253e-13\n",
      "g_norm_l2: 37.44860154946611\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.692264810770876e-96\n",
      "yk norm: 1.7014321941886706e-94\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 2.077255681682381e-14\n",
      "g_norm_l2: 1.2705628712424482e-31\n",
      "yk norm: 7.363743394489001e-30\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.8133909679624471e-82\n",
      "yk norm: 2.3332521371850835e-80\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 3275.651213481832\n",
      "D_hat_inv: 275.3260224583803\n",
      "g_norm_D: 9888.72103298632\n",
      "loss:  tensor(481.0221, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 275.3260224583803\n",
      "B norm: 1936.952442257257\n",
      "a: 9888.72103298632\n",
      "b: 97786803.668226\n",
      "c: 9888.72103298632\n",
      "plms: 1933972844364.9807 -1060670494808.956 -214580601.81510806 -962.0441236664192\n",
      "lmds:  [ 5.48643489e-01 -1.97646252e-04 -4.58739157e-06]\n",
      "lmd_max: tensor([0.5486], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5486], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5486], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.3260, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5486], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.9883, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 7.377214090125604e-13\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.080808554511385e-06\n",
      "yk norm: 8.652405051371489e-05\n",
      "D_hat_inv: 275.79778398073705\n",
      "g_norm_D: 5.125228049415632e-11\n",
      "loss:  tensor(7.2781e-08, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 3.080808554511385e-06\n",
      "D_inv norm: 275.79778398073705\n",
      "B norm: 0.00013041067100387453\n",
      "a: 5.125228049415632e-11\n",
      "b: 3.60919290564913e-14\n",
      "c: 0.0007042014269122412\n",
      "plms: 5.083197588319312e-17 7.215844467689167e-14 -1.0257673759892353e-10 -1.4556141672989805e-07\n",
      "lmds:  [ 1420.42322721 -1438.82638454 -1401.14513729]\n",
      "lmd_max: tensor([1420.4232], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1420.4232], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1420.4232], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.7978, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0001, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1420.4232], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(391625.5741, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.4047433275919594e-67\n",
      "yk norm: 8.747206929429807e-66\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.062434709973545215\n",
      "yk norm: 1.2798557851296728\n",
      "D_hat_inv: 276.1560826383936\n",
      "g_norm_D: 0.021609990586990417\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.062434709973545215\n",
      "D_inv norm: 276.1560826383936\n",
      "B norm: 2.7879324314550415\n",
      "a: 0.021609990586990417\n",
      "b: 0.3339944130223996\n",
      "c: 15.455555692072808\n",
      "plms: 10.324138502617727 -4.493613868414117 -0.711148433220039 -0.002794451072164453\n",
      "lmds:  [ 0.5592805  -0.11999411 -0.00403323]\n",
      "lmd_max: tensor([0.5593], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5593], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5593], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.1561, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2.7879, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5593], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(154.3793, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 1145.9613916685128\n",
      "D_hat_inv: 275.7254879221521\n",
      "g_norm_D: 12630.872991132306\n",
      "loss:  tensor(556.5409, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 275.7254879221521\n",
      "B norm: 2584.798857508485\n",
      "a: 12630.872991132306\n",
      "b: 159538952.51811567\n",
      "c: 12630.872991132317\n",
      "plms: 4030232492789.218 -2192057988054.042 -347171031.8757694 -1113.0817563149135\n",
      "lmds:  [ 5.44061938e-01 -1.55057776e-04 -3.27382203e-06]\n",
      "lmd_max: tensor([0.5441], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5441], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5441], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.7255, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5441], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(149.9455, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.1395729276719348e-29\n",
      "yk norm: 5.641292339815923e-28\n",
      "g_norm_l2: 1.8531566578063845e-31\n",
      "yk norm: 9.245691987129322e-30\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 1.3457116361687146e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.4850619020422206e-54\n",
      "yk norm: 1.1716780992887507e-52\n",
      "g_norm_l2: 6.982594564153235e-68\n",
      "yk norm: 8.571465863569878e-66\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 3175.5746925346266\n",
      "D_hat_inv: 277.3010678526834\n",
      "g_norm_D: 19505.59034385786\n",
      "loss:  tensor(673.4618, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 277.30106785268333\n",
      "B norm: 3845.1662222815303\n",
      "a: 19505.59034385786\n",
      "b: 380468054.66240126\n",
      "c: 19505.590343857875\n",
      "plms: 14842508026338.648 -7932193508673.995 -813442174.5749534 -1346.9235102485532\n",
      "lmds:  [ 5.34526597e-01 -1.00846641e-04 -1.68346809e-06]\n",
      "lmd_max: tensor([0.5345], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5345], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5345], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.3011, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5345], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.1594, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.968547124959597e-93\n",
      "yk norm: 1.3428324477452128e-91\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.05827353727140642\n",
      "yk norm: 0.6892804442659626\n",
      "D_hat_inv: 278.0173506727751\n",
      "g_norm_D: 0.0179358168503245\n",
      "loss:  tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.05827353727140642\n",
      "D_inv norm: 278.0173506727751\n",
      "B norm: 2.6721511958792985\n",
      "a: 0.0179358168503245\n",
      "b: 0.2531398897917869\n",
      "c: 14.113652693058532\n",
      "plms: 7.145456974560788 -3.0661272864528644 -0.5421058657210306 -0.0025400129008902343\n",
      "lmds:  [ 0.56459206 -0.13067219 -0.00481824]\n",
      "lmd_max: tensor([0.5646], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5646], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5646], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(278.0174, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2.6722, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5646], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(156.9002, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.445817634671916e-08\n",
      "yk norm: 6.865900051643844e-07\n",
      "D_hat_inv: 278.1368984572946\n",
      "g_norm_D: 3.2212215158791764e-15\n",
      "g_norm_l2: 3.4932292717027693e-31\n",
      "yk norm: 6.098266991211668e-30\n",
      "g_norm_l2: 1.5686149484961498e-126\n",
      "yk norm: 1.093895558647475e-124\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.7561503870175593e-63\n",
      "yk norm: 2.087459899676702e-61\n",
      "g_norm_l2: 6.371430182084759e-55\n",
      "yk norm: 6.603992499751724e-54\n",
      "g_norm_l2: 7.824094494167942e-12\n",
      "yk norm: 1.651585023165484e-10\n",
      "D_hat_inv: 278.85684299474036\n",
      "g_norm_D: 3.3175792146656996e-22\n",
      "Loss: 112.88189240927562 | GradNorm^2: 58.95516525304163\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 1536.1128596252047\n",
      "D_hat_inv: 280.49807455118827\n",
      "g_norm_D: 12873.494233696121\n",
      "loss:  tensor(555.5488, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 280.49807455118827\n",
      "B norm: 2584.798857508484\n",
      "a: 12873.494233696121\n",
      "b: 165726853.7850073\n",
      "c: 12873.494233696125\n",
      "plms: 4266967393139.7856 -2316959507313.8184 -360035379.0207595 -1111.0976522727187\n",
      "lmds:  [ 5.43154460e-01 -1.52197820e-04 -3.14993158e-06]\n",
      "lmd_max: tensor([0.5432], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5432], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5432], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(280.4981, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5432], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(152.2888, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 2.211695810447394e-13\n",
      "g_norm_l2: 1.4203876712926284e-29\n",
      "yk norm: 3.712045773977644e-28\n",
      "g_norm_l2: 1.301900861131443e-54\n",
      "yk norm: 4.368730155441456e-53\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.4959936217992875e-68\n",
      "yk norm: 3.6849602802881523e-66\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.029253874689825245\n",
      "yk norm: 2.459906922936305\n",
      "D_hat_inv: 282.0982048550014\n",
      "g_norm_D: 0.004892309525555661\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.029253874689825245\n",
      "D_inv norm: 282.0982048550014\n",
      "B norm: 1.3072604870427527\n",
      "a: 0.004892309525555661\n",
      "b: 0.03656143164490465\n",
      "c: 7.473245806284519\n",
      "plms: 0.5464651314240835 -0.20008577817040823 -0.08290107970077085 -0.0013088580229504685\n",
      "lmds:  [ 0.61792446 -0.23530634 -0.01647256]\n",
      "lmd_max: tensor([0.6179], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.6179], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.6179], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(282.0982, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1.3073, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.6179], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(174.2424, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.599805068696664e-119\n",
      "yk norm: 1.7368287877359906e-117\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.4832248650505175e-06\n",
      "yk norm: 3.556925826041961e-05\n",
      "D_hat_inv: 282.4691242552683\n",
      "g_norm_D: 1.1255992805255723e-10\n",
      "loss:  tensor(1.0591e-07, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 4.4832248650505175e-06\n",
      "D_inv norm: 282.4691242552683\n",
      "B norm: 0.00018977496757668764\n",
      "a: 1.1255992805255723e-10\n",
      "b: 1.1962597622630507e-13\n",
      "c: 0.001062775876779599\n",
      "plms: 2.542712035390537e-16 2.391248297533886e-13 -2.253590837767226e-10 -2.1182250075796377e-07\n",
      "lmds:  [ 941.3071578  -956.20559175 -925.53377555]\n",
      "lmd_max: tensor([941.3072], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([941.3072], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([941.3072], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(282.4691, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0002, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([941.3072], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(265807.0911, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.885464132550001e-126\n",
      "yk norm: 5.406212966082569e-125\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 333.02177554487764\n",
      "D_hat_inv: 279.90323245073057\n",
      "g_norm_D: 10744.744968347162\n",
      "loss:  tensor(407.7853, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 279.90323245073057\n",
      "B norm: 2118.7572974701075\n",
      "a: 10744.744968347162\n",
      "b: 115449544.43482126\n",
      "c: 10744.744968347124\n",
      "plms: 2480951823328.027 -1334171374660.2156 -248403796.87463358 -815.5706601951962\n",
      "lmds:  [ 5.37952057e-01 -1.82779263e-04 -3.34328015e-06]\n",
      "lmd_max: tensor([0.5380], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5380], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5380], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(279.9032, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5380], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.5089, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 5.296423660299027e-25\n",
      "yk norm: 5.1668161900446855e-24\n",
      "g_norm_l2: 2.256137236903247e-31\n",
      "yk norm: 4.532937789697563e-30\n",
      "g_norm_l2: 8.873226254631537e-12\n",
      "yk norm: 2.8921424381191016e-10\n",
      "D_hat_inv: 280.2641465148363\n",
      "g_norm_D: 4.302344059725235e-22\n",
      "g_norm_l2: 1.0581022548086781e-15\n",
      "yk norm: 1.6805605116428835e-14\n",
      "g_norm_l2: 9.453576771201271e-68\n",
      "yk norm: 2.3152490652322632e-66\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.109015835981103e-93\n",
      "yk norm: 7.61155556788889e-92\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 7.731701170340478e-32\n",
      "yk norm: 2.9550921863530622e-30\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 3.1919235906700353e-13\n",
      "g_norm_l2: 4.614485754945795e-63\n",
      "yk norm: 1.0243237732256274e-61\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 41.59687957565648\n",
      "D_hat_inv: 281.38880631202494\n",
      "g_norm_D: 12024.840024987167\n",
      "loss:  tensor(416.0542, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 281.38880631202494\n",
      "B norm: 2249.2786885991236\n",
      "a: 12024.840024987167\n",
      "b: 144596777.62653407\n",
      "c: 12024.840024987227\n",
      "plms: 3477506238175.4487 -1858494922007.5269 -309181445.82008797 -832.1083775536974\n",
      "lmds:  [ 5.34599549e-01 -1.63573949e-04 -2.73633493e-06]\n",
      "lmd_max: tensor([0.5346], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5346], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5346], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(281.3888, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5346], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.3644, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 1069.2489733370576\n",
      "D_hat_inv: 281.26158674004984\n",
      "g_norm_D: 11099.818281973758\n",
      "loss:  tensor(454.4011, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 281.26158674004984\n",
      "B norm: 2133.417859868762\n",
      "a: 11099.818281973758\n",
      "b: 123205965.8928389\n",
      "c: 11099.818281973761\n",
      "plms: 2735127665331.1377 -1479040849464.008 -266564808.50038183 -908.8021010232469\n",
      "lmds:  [ 5.40937688e-01 -1.76692901e-04 -3.47636505e-06]\n",
      "lmd_max: tensor([0.5409], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5409], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5409], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(281.2616, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5409], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(152.0773, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 685.1809635925123\n",
      "D_hat_inv: 280.9285991649139\n",
      "g_norm_D: 9169.564003158206\n",
      "loss:  tensor(527.4425, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 280.9285991649139\n",
      "B norm: 1722.800462211447\n",
      "a: 9169.564003158206\n",
      "b: 84080904.00801474\n",
      "c: 9169.564003158204\n",
      "plms: 1541970461489.7844 -859344588263.006 -187489139.21729878 -1054.884960866871\n",
      "lmds:  [ 5.57520980e-01 -2.12314276e-04 -5.77947825e-06]\n",
      "lmd_max: tensor([0.5575], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5575], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5575], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(280.9286, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5575], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(156.5554, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 1119.8194924217514\n",
      "D_hat_inv: 281.00054150556934\n",
      "g_norm_D: 20074.616123635264\n",
      "loss:  tensor(672.1136, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 281.00054150556934\n",
      "B norm: 3845.1662222815357\n",
      "a: 20074.616123635264\n",
      "b: 402990212.51131755\n",
      "c: 20074.6161236353\n",
      "plms: 16179747635493.826 -8629972229219.588 -859909962.5815517 -1344.2271189340797\n",
      "lmds:  [ 5.33480763e-01 -9.80354036e-05 -1.58854384e-06]\n",
      "lmd_max: tensor([0.5335], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5335], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5335], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(281.0005, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5335], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(149.8422, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 1.3496499417935221e-12\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 5.48629413815993e-14\n",
      "g_norm_l2: 3.071179179057337e-82\n",
      "yk norm: 8.677618510946019e-81\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.026765586491475174\n",
      "yk norm: 1.2798540078767242\n",
      "D_hat_inv: 281.91504161494737\n",
      "g_norm_D: 0.003925086852730882\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.026765586491475174\n",
      "D_inv norm: 281.91504161494737\n",
      "B norm: 1.2281876311963797\n",
      "a: 0.003925086852730882\n",
      "b: 0.026412513573627464\n",
      "c: 6.729153918021188\n",
      "plms: 0.35546773839752616 -0.12489344173305122 -0.060670623659612025 -0.0011662513897760902\n",
      "lmds:  [ 0.63036661 -0.25891492 -0.02010211]\n",
      "lmd_max: tensor([0.6304], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.6304], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.6304], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(281.9150, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1.2282, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.6304], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(177.6371, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.412079297649161e-31\n",
      "yk norm: 2.6847666336002626e-30\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 1621.2231704524158\n",
      "D_hat_inv: 280.34015822213337\n",
      "g_norm_D: 9858.483740583866\n",
      "loss:  tensor(477.7099, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 280.34015822213337\n",
      "B norm: 1936.9524422572574\n",
      "a: 9858.483740583866\n",
      "b: 97189701.66335651\n",
      "c: 9858.48374058387\n",
      "plms: 1916286187200.7942 -1050611306510.1168 -213197668.78326607 -955.4198657591202\n",
      "lmds:  [ 5.48456718e-01 -1.98268882e-04 -4.58497504e-06]\n",
      "lmd_max: tensor([0.5485], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5485], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5485], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(280.3402, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5485], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(153.6868, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 2.3519067147947354e-13\n",
      "g_norm_l2: 4.19112961881674e-55\n",
      "yk norm: 1.8147879483315442e-53\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.7168680977806699e-96\n",
      "yk norm: 1.304709885281387e-94\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.259454621046063e-09\n",
      "yk norm: 9.285064457018779e-08\n",
      "D_hat_inv: 281.13626434643044\n",
      "g_norm_D: 2.1075262751898398e-16\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "Loss: 112.29981446581193 | GradNorm^2: 58.955358556491014\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.865485567660768e-32\n",
      "yk norm: 2.2236832278316505e-30\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 4.092089063311087e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.2511537890478884e-93\n",
      "yk norm: 8.755511233482162e-92\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 2.1818201961470938e-13\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.319629746506536\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 4841.067552086163\n",
      "D_hat_inv: 282.69432123209305\n",
      "g_norm_D: 9306.91035130553\n",
      "loss:  tensor(525.9721, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 282.69432123209305\n",
      "B norm: 1722.800462211447\n",
      "a: 9306.91035130553\n",
      "b: 86618580.28723803\n",
      "c: 9306.91035130553\n",
      "plms: 1612302722981.3696 -896922793960.5353 -192799246.1162032 -1051.944126639355\n",
      "lmds:  [ 5.56514124e-01 -2.09273288e-04 -5.60216759e-06]\n",
      "lmd_max: tensor([0.5565], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5565], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5565], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(282.6943, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5565], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(157.2544, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.3854142382670688e-82\n",
      "yk norm: 3.12914902564455e-81\n",
      "g_norm_l2: 3.130607306736213e-63\n",
      "yk norm: 6.250222182924624e-62\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 1150.2586008831815\n",
      "D_hat_inv: 283.80949026279944\n",
      "g_norm_D: 10025.007336424947\n",
      "loss:  tensor(476.4154, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 283.80949026279944\n",
      "B norm: 1936.9524422572563\n",
      "a: 10025.007336424947\n",
      "b: 100500772.09537397\n",
      "c: 10025.007336424944\n",
      "plms: 2015041955144.9907 -1102879197089.6704 -220085764.00690517 -952.8307157151132\n",
      "lmds:  [ 5.47522678e-01 -1.95056913e-04 -4.42759812e-06]\n",
      "lmd_max: tensor([0.5475], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5475], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5475], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(283.8095, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5475], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(155.3244, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.2412320934372138e-67\n",
      "yk norm: 2.7335500820699064e-66\n",
      "g_norm_l2: 0.02035208822917762\n",
      "yk norm: 0.662134706402143\n",
      "D_hat_inv: 284.1428317418955\n",
      "g_norm_D: 0.0023894101541323976\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.02035208822917762\n",
      "D_inv norm: 284.1428317418955\n",
      "B norm: 0.9096497806114676\n",
      "a: 0.0023894101541323976\n",
      "b: 0.012538271671246121\n",
      "c: 5.247433827784501\n",
      "plms: 0.13158750181929804 -0.04071150001881829 -0.02985318828332001 -0.0009104893518139833\n",
      "lmds:  [ 0.66576368 -0.32433215 -0.03204425]\n",
      "lmd_max: tensor([0.6658], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.6658], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.6658], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(284.1428, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.9096, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.6658], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(189.0943, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 3.056083821186779e-13\n",
      "g_norm_l2: 1.8250278413073689e-31\n",
      "yk norm: 1.2431649255381707e-29\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 1.0112037132538409e-13\n",
      "g_norm_l2: 1.4385179335670935e-15\n",
      "yk norm: 1.3978533786086997e-13\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 1160.5620471038012\n",
      "D_hat_inv: 285.13119079593855\n",
      "g_norm_D: 11433.922214290991\n",
      "loss:  tensor(452.7619, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 285.13119079593855\n",
      "B norm: 2133.417859868761\n",
      "a: 11433.922214290991\n",
      "b: 130734577.202457\n",
      "c: 11433.92221429099\n",
      "plms: 2989617972902.2266 -1612669315625.5632 -282153663.3056753 -905.5237720310998\n",
      "lmds:  [ 5.39598112e-01 -1.71634511e-04 -3.27046212e-06]\n",
      "lmd_max: tensor([0.5396], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5396], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5396], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(285.1312, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5396], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(153.7882, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.3842796714223163e-55\n",
      "yk norm: 8.929517134907105e-54\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 1.5524435481949361e-13\n",
      "g_norm_l2: 3.4899057259315936e-31\n",
      "yk norm: 4.01961561373757e-31\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.240103621706741e-118\n",
      "yk norm: 1.8421984601416674e-117\n",
      "g_norm_l2: 46.02996086757096\n",
      "yk norm: 450.2293679703764\n",
      "D_hat_inv: 286.30688277746316\n",
      "g_norm_D: 11070.771484082963\n",
      "loss:  tensor(404.5901, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757096\n",
      "D_inv norm: 286.30688277746316\n",
      "B norm: 2118.7572974701175\n",
      "a: 11070.771484082963\n",
      "b: 122561981.25278473\n",
      "c: 11070.771484082983\n",
      "plms: 2713711374172.0845 -1455540173550.28 -263018320.1933618 -809.1802480305897\n",
      "lmds:  [ 5.36545779e-01 -1.77510958e-04 -3.13075922e-06]\n",
      "lmd_max: tensor([0.5365], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5365], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5365], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(286.3069, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5365], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(153.5515, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.2050548463828251e-96\n",
      "yk norm: 1.0644884313761088e-95\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 3610.9827364105918\n",
      "D_hat_inv: 286.2809745718089\n",
      "g_norm_D: 12493.080588827417\n",
      "loss:  tensor(412.7776, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 286.2809745718089\n",
      "B norm: 2249.2786885991127\n",
      "a: 12493.080588827417\n",
      "b: 156077062.5989364\n",
      "c: 12493.080588827417\n",
      "plms: 3899766642231.948 -2078109234759.354 -332756592.92649186 -825.5551440308424\n",
      "lmds:  [ 5.33040484e-01 -1.57556709e-04 -2.52063734e-06]\n",
      "lmd_max: tensor([0.5330], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5330], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5330], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(286.2810, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5330], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(152.5326, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.2218411766255314e-25\n",
      "yk norm: 8.368317610984046e-25\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 119.56617903539002\n",
      "D_hat_inv: 286.5723411570579\n",
      "g_norm_D: 13111.384552242187\n",
      "loss:  tensor(549.3003, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 286.5723411570579\n",
      "B norm: 2584.7988575084773\n",
      "a: 13111.384552242187\n",
      "b: 171908404.87677467\n",
      "c: 13111.384552242158\n",
      "plms: 4507914408203.867 -2442128237872.351 -372598935.42963296 -1098.6005455946151\n",
      "lmds:  [ 5.41894900e-01 -1.49521514e-04 -3.00777538e-06]\n",
      "lmd_max: tensor([0.5419], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5419], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5419], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(286.5723, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5419], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(155.2241, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.5309618706759243e-68\n",
      "yk norm: 1.0688780912139798e-66\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.015980672526291324\n",
      "yk norm: 0.9547912570899936\n",
      "D_hat_inv: 287.03212675244447\n",
      "g_norm_D: 0.001447733786796428\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.015980672526291324\n",
      "D_inv norm: 287.03212675244447\n",
      "B norm: 0.7334745829256432\n",
      "a: 0.001447733786796428\n",
      "b: 0.006019665852996337\n",
      "c: 4.1579922413199775\n",
      "plms: 0.05005944782419516 -0.012988296759368155 -0.014933791366816516 -0.0006962407453385066\n",
      "lmds:  [ 0.70833553 -0.39976082 -0.04911726]\n",
      "lmd_max: tensor([0.7083], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.7083], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.7083], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(287.0321, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.7335, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.7083], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(203.2339, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.8809457162142515e-12\n",
      "yk norm: 2.123936114551928e-10\n",
      "D_hat_inv: 287.14624770720184\n",
      "g_norm_D: 4.7221023169657194e-23\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 3.359650070654493e-13\n",
      "g_norm_l2: 39.44225841247945\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.169344343007741e-29\n",
      "yk norm: 1.3431032863699592e-27\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 6.876904319508622e-14\n",
      "g_norm_l2: 2.9921598632269944e-126\n",
      "yk norm: 1.9524611656262785e-124\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.0514886354531228e-05\n",
      "yk norm: 1.241302985080344e-05\n",
      "D_hat_inv: 288.1700387633787\n",
      "g_norm_D: 2.3690205516694258e-09\n",
      "loss:  tensor(4.8464e-07, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 2.0514886354531228e-05\n",
      "D_inv norm: 288.1700387633787\n",
      "B norm: 0.0008683950806578993\n",
      "a: 2.3690205516694258e-09\n",
      "b: 1.158021920322098e-11\n",
      "c: 0.004888188578634538\n",
      "plms: 1.1321259049453827e-13 2.3103837722468822e-11 -4.761199245895188e-09 -9.692833816033584e-07\n",
      "lmds:  [ 204.94993828 -211.66085064 -197.36389611]\n",
      "lmd_max: tensor([204.9499], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([204.9499], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([204.9499], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(288.1700, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0009, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([204.9499], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(59042.2764, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.404419893599068e-55\n",
      "yk norm: 1.4522948950415383e-54\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.3100263283068164e-09\n",
      "yk norm: 7.110355202504826e-09\n",
      "D_hat_inv: 288.851607279293\n",
      "g_norm_D: 9.30523098289921e-18\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 4176.375398679602\n",
      "D_hat_inv: 282.94968050141625\n",
      "g_norm_D: 19229.19271479148\n",
      "loss:  tensor(670.3446, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 282.94968050141625\n",
      "B norm: 3845.166222281529\n",
      "a: 19229.19271479148\n",
      "b: 369761852.46258974\n",
      "c: 19229.192714791476\n",
      "plms: 14220443839162.857 -7604478579393.7 -791045986.9800692 -1340.6891595781258\n",
      "lmds:  [ 5.34860771e-01 -1.02280418e-04 -1.72338261e-06]\n",
      "lmd_max: tensor([0.5349], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5349], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5349], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(282.9497, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5349], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(151.2728, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "Loss: 111.71812467051843 | GradNorm^2: 58.9554639503313\n",
      "g_norm_l2: 2.8611419488779963e-55\n",
      "yk norm: 8.663843083737894e-54\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 1.0682933745721454e-13\n",
      "g_norm_l2: 1.6383333067705326e-118\n",
      "yk norm: 1.758311319217908e-118\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.8243589924609936e-25\n",
      "yk norm: 9.035675449993652e-24\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.4382880658734275e-82\n",
      "yk norm: 5.530410292579611e-81\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.0119550691918407e-29\n",
      "yk norm: 5.5147274010748615e-28\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 995.5961497339835\n",
      "D_hat_inv: 281.40305211375244\n",
      "g_norm_D: 10783.178867982897\n",
      "loss:  tensor(402.6455, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 281.40305211375244\n",
      "B norm: 2118.7572974701143\n",
      "a: 10783.178867982897\n",
      "b: 116276946.49891283\n",
      "c: 10783.178867982891\n",
      "plms: 2507670224641.3086 -1347006772766.121 -249899518.51881966 -805.2909114906805\n",
      "lmds:  [ 5.37340129e-01 -1.82178710e-04 -3.28046552e-06]\n",
      "lmd_max: tensor([0.5373], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5373], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5373], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(281.4031, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5373], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(151.1415, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 1468.748808614667\n",
      "D_hat_inv: 275.96943557969814\n",
      "g_norm_D: 10193.127954942496\n",
      "loss:  tensor(450.4558, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 275.9694355796981\n",
      "B norm: 2133.4178598687618\n",
      "a: 10193.127954942496\n",
      "b: 103899857.50583023\n",
      "c: 10193.127954942498\n",
      "plms: 2118129084114.4402 -1152253527529.9224 -226145542.80044684 -900.9115811104264\n",
      "lmds:  [ 5.44192090e-01 -1.92126289e-04 -4.06809163e-06]\n",
      "lmd_max: tensor([0.5442], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5442], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5442], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.9694, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5442], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.1160, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.9025906854404036e-15\n",
      "yk norm: 7.141763194924524e-14\n",
      "g_norm_l2: 3.1657471579150034e-55\n",
      "yk norm: 2.429262663789201e-54\n",
      "g_norm_l2: 3.273402049184235e-12\n",
      "yk norm: 1.721201312178424e-10\n",
      "D_hat_inv: 276.5088384597097\n",
      "g_norm_D: 5.713060691139344e-23\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 1052.1263773481778\n",
      "D_hat_inv: 276.7985901537299\n",
      "g_norm_D: 11543.611063010583\n",
      "loss:  tensor(410.6273, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 276.7985901537299\n",
      "B norm: 2249.278688599113\n",
      "a: 11543.611063010583\n",
      "b: 133254956.37406036\n",
      "c: 11543.611063010589\n",
      "plms: 3076486777201.194 -1647146618184.8354 -285447313.50716096 -821.2546263760452\n",
      "lmds:  [ 5.35571812e-01 -1.70316434e-04 -2.92649988e-06]\n",
      "lmd_max: tensor([0.5356], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5356], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5356], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.7986, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5356], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.1779, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.300882006936642e-68\n",
      "yk norm: 4.3430103979272135e-67\n",
      "g_norm_l2: 5.936665107878763e-10\n",
      "yk norm: 2.7158878555667476e-08\n",
      "D_hat_inv: 277.23108809021306\n",
      "g_norm_D: 1.8285167857056918e-18\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.7607710058808077e-32\n",
      "yk norm: 9.407224497311336e-31\n",
      "g_norm_l2: 1.5586756254966438e-96\n",
      "yk norm: 2.581325578540893e-95\n",
      "g_norm_l2: 1.0896160764552318e-67\n",
      "yk norm: 1.922487723170316e-66\n",
      "g_norm_l2: 4.788899849384098e-126\n",
      "yk norm: 1.1703278798667987e-124\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 1.7980157277584992e-13\n",
      "g_norm_l2: 0.007873028427661036\n",
      "yk norm: 0.5692485744123719\n",
      "D_hat_inv: 278.09976153465254\n",
      "g_norm_D: 0.00033312044592192147\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.007873028427661036\n",
      "D_inv norm: 278.09976153465254\n",
      "B norm: 0.36141697456925215\n",
      "a: 0.00033312044592192147\n",
      "b: 0.0006470345705500214\n",
      "c: 1.9423442135451414\n",
      "plms: 0.0025135277081429993 3.7416243573706095e-05 -0.0019601957828080047 -0.00034297925266294193\n",
      "lmds:  [ 0.9533119  -0.78611825 -0.1820796 ]\n",
      "lmd_max: tensor([0.9533], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.9533], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.9533], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(278.0998, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.3614, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.9533], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(265.0152, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 2062.1857058773826\n",
      "D_hat_inv: 278.2095517063499\n",
      "g_norm_D: 9525.62763837926\n",
      "loss:  tensor(523.8033, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 278.2095517063499\n",
      "B norm: 1722.8004622114465\n",
      "a: 9525.62763837926\n",
      "b: 90737581.9050548\n",
      "c: 9525.627638379257\n",
      "plms: 1728664836068.9834 -959026762398.123 -201414334.3749386 -1047.6066553185976\n",
      "lmds:  [ 5.54988834e-01 -2.04605165e-04 -5.33686984e-06]\n",
      "lmd_max: tensor([0.5550], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5550], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5550], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(278.2096, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5550], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(154.3309, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.6956071942628644e-63\n",
      "yk norm: 1.568042974396733e-61\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 4028.314742510673\n",
      "D_hat_inv: 278.39507289352173\n",
      "g_norm_D: 9729.626088376448\n",
      "loss:  tensor(472.2803, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 278.39507289352173\n",
      "B norm: 1936.9524422572574\n",
      "a: 9729.626088376448\n",
      "b: 94665623.81961559\n",
      "c: 9729.62608837645\n",
      "plms: 1842122246375.5261 -1010099884958.6335 -207692232.49743438 -944.560661603341\n",
      "lmds:  [ 5.48540422e-01 -2.00887007e-04 -4.65319149e-06]\n",
      "lmd_max: tensor([0.5485], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5485], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5485], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(278.3951, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5485], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(152.6435, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 3.3023906068974744e-05\n",
      "yk norm: 0.0011815090886351026\n",
      "D_hat_inv: 278.5062246993835\n",
      "g_norm_D: 5.822613717650153e-09\n",
      "loss:  tensor(7.8015e-07, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 3.3023906068974744e-05\n",
      "D_inv norm: 278.50622469938355\n",
      "B norm: 0.0013979014362631382\n",
      "a: 5.822613717650153e-09\n",
      "b: 4.345658842205619e-11\n",
      "c: 0.007463416006857155\n",
      "plms: 6.486691952651551e-13 8.658887614868885e-11 -1.1732131527240397e-08 -1.560307355525811e-06\n",
      "lmds:  [ 134.36220059 -139.70850103 -128.14065529]\n",
      "lmd_max: tensor([134.3622], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([134.3622], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([134.3622], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(278.5062, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0014, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([134.3622], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(37409.0900, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 62.0094043051659\n",
      "yk norm: 6474.623872469125\n",
      "D_hat_inv: 276.4104856504775\n",
      "g_norm_D: 18612.110229875205\n",
      "loss:  tensor(668.8742, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.0094043051659\n",
      "D_inv norm: 276.41048565047754\n",
      "B norm: 3845.166222281528\n",
      "a: 18612.110229875205\n",
      "b: 346410647.2090252\n",
      "c: 18612.110229875205\n",
      "plms: 12894866301313.58 -6909457807901.479 -742580712.7179734 -1337.7484311384435\n",
      "lmds:  [ 5.35937576e-01 -1.05619154e-04 -1.83273930e-06]\n",
      "lmd_max: tensor([0.5359], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5359], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5359], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.4105, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5359], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.0733, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 8.350380495391217e-32\n",
      "yk norm: 1.2029497335894785e-30\n",
      "g_norm_l2: 8.48014984434217e-31\n",
      "yk norm: 2.622733236231102e-29\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.028399548928360253\n",
      "yk norm: 1.0697707988741143\n",
      "D_hat_inv: 276.96752793851635\n",
      "g_norm_D: 0.004367136968036872\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.028399548928360253\n",
      "D_inv norm: 276.96752793851635\n",
      "B norm: 1.269107710642628\n",
      "a: 0.004367136968036872\n",
      "b: 0.030010223132268265\n",
      "c: 6.871830068970461\n",
      "plms: 0.4124503073936679 -0.14618564362343622 -0.06874917180704704 -0.0012706221853067852\n",
      "lmds:  [ 0.62776862 -0.25401763 -0.01931885]\n",
      "lmd_max: tensor([0.6278], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.6278], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.6278], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.9675, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1.2691, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.6278], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(173.7967, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 3.8866648251873157e-13\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 3219.680390398713\n",
      "D_hat_inv: 275.537724450394\n",
      "g_norm_D: 11930.768145529411\n",
      "loss:  tensor(545.8248, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 275.53772445039397\n",
      "B norm: 2584.7988575084837\n",
      "a: 11930.768145529411\n",
      "b: 142343228.5423793\n",
      "c: 11930.768145529411\n",
      "plms: 3396528113650.4644 -1853083624622.5625 -310711034.14288044 -1091.6496857821169\n",
      "lmds:  [ 5.45749334e-01 -1.64031741e-04 -3.59026885e-06]\n",
      "lmd_max: tensor([0.5457], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5457], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5457], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.5377, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5457], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.3076, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.8675149875658015e-93\n",
      "yk norm: 1.014877510053129e-91\n",
      "Loss: 111.13439674817923 | GradNorm^2: 58.9555692286414\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.55522096467388\n",
      "yk norm: 3.7240038260181444e-13\n",
      "g_norm_l2: 2.3190398765113242e-32\n",
      "yk norm: 5.531172999152337e-31\n",
      "g_norm_l2: 4.0012284608512065e-82\n",
      "yk norm: 7.13064868461647e-81\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.004303392010000076\n",
      "yk norm: 0.2613056597054297\n",
      "D_hat_inv: 276.52154987864776\n",
      "g_norm_D: 9.550817323256038e-05\n",
      "loss:  tensor(9.3732e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.004303392010000076\n",
      "D_inv norm: 276.52154987864776\n",
      "B norm: 0.19756563523307702\n",
      "a: 9.550817323256038e-05\n",
      "b: 9.731295572957615e-05\n",
      "c: 1.0188966288007744\n",
      "plms: 0.00019830368506300826 9.548319016889915e-05 -0.0003856243537699297 -0.00018746493902208885\n",
      "lmds:  [ 1.39621416 -1.39093747 -0.48677652]\n",
      "lmd_max: tensor([1.3962], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1.3962], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1.3962], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.5215, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.1976, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1.3962], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(385.9492, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.684824619725608e-55\n",
      "yk norm: 6.340203928597481e-54\n",
      "g_norm_l2: 1.8293852258223993e-55\n",
      "yk norm: 1.5617886633048674e-53\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.007471206893754e-96\n",
      "yk norm: 5.1604731090606136e-95\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.013313140536853584\n",
      "yk norm: 0.7272872540419408\n",
      "D_hat_inv: 277.17994534799664\n",
      "g_norm_D: 0.0009584664557786809\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.013313140536853584\n",
      "D_inv norm: 277.17994534799664\n",
      "B norm: 0.5951331596329789\n",
      "a: 0.0009584664557786809\n",
      "b: 0.0030846575160257943\n",
      "c: 3.21832600132025\n",
      "plms: 0.0198548669779875 -0.003757199981347448 -0.008085677165139438 -0.0005955417572788902\n",
      "lmds:  [ 0.76928809 -0.50245543 -0.07759946]\n",
      "lmd_max: tensor([0.7693], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.7693], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.7693], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(277.1799, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.5951, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.7693], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(213.1455, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 7.201934333859017e-32\n",
      "yk norm: 3.9308083319454906e-31\n",
      "g_norm_l2: 8.49812422484794e-68\n",
      "yk norm: 6.148323498996283e-67\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 1761.8881547917408\n",
      "D_hat_inv: 276.9312785941941\n",
      "g_norm_D: 9336.032036302886\n",
      "loss:  tensor(470.9104, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 276.9312785941941\n",
      "B norm: 1936.952442257257\n",
      "a: 9336.032036302886\n",
      "b: 87161494.18287382\n",
      "c: 9336.032036302886\n",
      "plms: 1627485004046.675 -895484355719.4519 -191890052.80164406 -941.8207023919479\n",
      "lmds:  [ 5.50440077e-01 -2.09178835e-04 -5.02601115e-06]\n",
      "lmd_max: tensor([0.5504], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5504], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5504], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.9313, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5504], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(152.3670, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 9.98564647422941e-14\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 1452.0020536314057\n",
      "D_hat_inv: 276.17720991793243\n",
      "g_norm_D: 10335.259814022516\n",
      "loss:  tensor(448.3826, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 276.17720991793243\n",
      "B norm: 2133.4178598687627\n",
      "a: 10335.259814022516\n",
      "b: 106817595.42334875\n",
      "c: 10335.25981402252\n",
      "plms: 2207975202818.905 -1199350631675.2173 -232151122.6711138 -896.7651843108242\n",
      "lmds:  [ 5.43383760e-01 -1.89553283e-04 -3.94317979e-06]\n",
      "lmd_max: tensor([0.5434], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5434], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5434], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.1772, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5434], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.0023, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 213.08742746543496\n",
      "D_hat_inv: 275.24650898028165\n",
      "g_norm_D: 12126.197627783371\n",
      "loss:  tensor(543.8191, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 275.24650898028165\n",
      "B norm: 2584.7988575084746\n",
      "a: 12126.197627783371\n",
      "b: 147044668.90805858\n",
      "c: 12126.197627783331\n",
      "plms: 3566185430582.17 -1942435939274.565 -320442917.54404587 -1087.6382248112075\n",
      "lmds:  [ 5.44846620e-01 -1.61453676e-04 -3.46703597e-06]\n",
      "lmd_max: tensor([0.5448], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5448], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5448], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(275.2465, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5448], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(149.8983, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.8920766491415953e-63\n",
      "yk norm: 1.056899478876627e-62\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 1.3672547021761026e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 54.0229356749543\n",
      "yk norm: 3.83058814943664e-13\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.086650418162455e-05\n",
      "yk norm: 0.000573525059236747\n",
      "D_hat_inv: 276.65136138300375\n",
      "g_norm_D: 1.3683588207026095e-08\n",
      "loss:  tensor(1.2017e-06, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 5.086650418162455e-05\n",
      "D_inv norm: 276.65136138300375\n",
      "B norm: 0.002153177432508334\n",
      "a: 1.3683588207026095e-08\n",
      "b: 1.5581742687266349e-10\n",
      "c: 0.011387175974256236\n",
      "plms: 3.548640919309644e-12 3.098607205200409e-10 -2.7678778382669704e-08 -2.4033316103447496e-06\n",
      "lmds:  [ 88.19356607 -92.43683096 -83.07487397]\n",
      "lmd_max: tensor([88.1936], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([88.1936], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([88.1936], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(276.6514, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0022, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([88.1936], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(24391.1926, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.6911458079786717e-10\n",
      "yk norm: 1.3742314070497203e-09\n",
      "D_hat_inv: 276.76839567407825\n",
      "g_norm_D: 1.4890368583581502e-19\n",
      "g_norm_l2: 1.3411112691823544e-93\n",
      "yk norm: 1.2413128883354292e-91\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 12308.566945129625\n",
      "D_hat_inv: 274.28786216473713\n",
      "g_norm_D: 17810.11530555464\n",
      "loss:  tensor(667.9033, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 274.28786216473713\n",
      "B norm: 3845.1662222815285\n",
      "a: 17810.11530555464\n",
      "b: 317200207.19715154\n",
      "c: 17810.11530555464\n",
      "plms: 11298744530254.184 -6071821620204.692 -681946536.1835474 -1335.8066807410164\n",
      "lmds:  [ 5.37501343e-01 -1.10296057e-04 -1.99422371e-06]\n",
      "lmd_max: tensor([0.5375], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5375], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5375], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(274.2879, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5375], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(147.3647, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 749.0241178232674\n",
      "D_hat_inv: 268.5587897149005\n",
      "g_norm_D: 8534.972825019493\n",
      "loss:  tensor(521.5229, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 268.5587897149005\n",
      "B norm: 1722.8004622114456\n",
      "a: 8534.972825019493\n",
      "b: 72845761.12382117\n",
      "c: 8534.972825019486\n",
      "plms: 1243473183219.3489 -697426679765.1328 -163479188.82727352 -1043.0458825298347\n",
      "lmds:  [ 5.61104208e-01 -2.27744069e-04 -6.56411814e-06]\n",
      "lmd_max: tensor([0.5611], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5611], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5611], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(268.5588, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5611], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(150.6188, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.5875371664109213e-12\n",
      "yk norm: 1.53043022796432e-10\n",
      "D_hat_inv: 268.77233371440394\n",
      "g_norm_D: 1.2630713798262849e-23\n",
      "g_norm_l2: 2.6238554702081323e-15\n",
      "yk norm: 6.149512326547814e-14\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 973.7735404163934\n",
      "D_hat_inv: 259.13234892722545\n",
      "g_norm_D: 9751.34378529401\n",
      "loss:  tensor(407.2137, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 259.13234892722545\n",
      "B norm: 2249.2786885991122\n",
      "a: 9751.34378529401\n",
      "b: 95088705.61899212\n",
      "c: 9751.34378529401\n",
      "plms: 1854485317178.8206 -1004305157291.2076 -206041432.96087793 -814.4274655980332\n",
      "lmds:  [ 5.41759738e-01 -2.01050051e-04 -4.03197747e-06]\n",
      "lmd_max: tensor([0.5418], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5418], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5418], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.1323, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5418], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.3203, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.7002422303691344e-118\n",
      "yk norm: 2.0767940118288585e-117\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.3644980307045\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.020235426930675e-29\n",
      "yk norm: 2.0336453167241302e-27\n",
      "g_norm_l2: 1.471031666926231e-25\n",
      "yk norm: 1.996787100871969e-24\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 3848.1758179698268\n",
      "D_hat_inv: 258.3781411973656\n",
      "g_norm_D: 9469.388978478495\n",
      "loss:  tensor(397.9524, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 258.37814119736555\n",
      "B norm: 2118.757297470115\n",
      "a: 9469.388978478495\n",
      "b: 89669327.62573001\n",
      "c: 9469.388978478497\n",
      "plms: 1698227485453.3306 -920123312201.9044 -194393180.44207463 -795.904783446413\n",
      "lmds:  [ 5.42025120e-01 -2.07011013e-04 -4.17688368e-06]\n",
      "lmd_max: tensor([0.5420], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5420], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5420], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.3781, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5420], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.9788, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.6853104872116762e-30\n",
      "yk norm: 3.6025395286523385e-29\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.2553645235414518e-68\n",
      "yk norm: 5.923298748023151e-67\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 7.235946169102261e-126\n",
      "yk norm: 3.3201748539621884e-124\n",
      "g_norm_l2: 42.93269227210107\n",
      "yk norm: 2.2584588330544102e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "Loss: 110.54847709231825 | GradNorm^2: 58.95562855752301\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.021295184914502e-15\n",
      "yk norm: 6.635291846193786e-14\n",
      "g_norm_l2: 1.4796485517796482e-32\n",
      "yk norm: 1.155976762694873e-30\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 7.811485138145013e-97\n",
      "yk norm: 2.7992929954227234e-95\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.3591190587586432e-93\n",
      "yk norm: 1.4631345554683249e-92\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.7501325794656655e-82\n",
      "yk norm: 4.1497556353155454e-81\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 7.369356092798395e-29\n",
      "yk norm: 4.080368137157045e-27\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0038523338875227e-10\n",
      "yk norm: 1.5718984825339993e-09\n",
      "D_hat_inv: 261.9291450230944\n",
      "g_norm_D: 4.914697306782864e-20\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.705221081739043e-68\n",
      "yk norm: 7.701914022862113e-68\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.3389076007525461e-55\n",
      "yk norm: 6.689366696772733e-54\n",
      "g_norm_l2: 7.274335471255168e-05\n",
      "yk norm: 0.0009390466797942699\n",
      "D_hat_inv: 262.7093561687083\n",
      "g_norm_D: 2.6499610203625682e-08\n",
      "loss:  tensor(1.7185e-06, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 7.274335471255168e-05\n",
      "D_inv norm: 262.7093561687084\n",
      "B norm: 0.0030792221974607708\n",
      "a: 2.6499610203625682e-08\n",
      "b: 4.0863291819493654e-10\n",
      "c: 0.015420336942881797\n",
      "plms: 1.2602514569037949e-11 8.109652813490858e-10 -5.3816395163435345e-08 -3.436966070421272e-06\n",
      "lmds:  [ 65.22509129 -68.80840518 -60.76616786]\n",
      "lmd_max: tensor([65.2251], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([65.2251], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([65.2251], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(262.7094, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0031, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([65.2251], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(17129.4183, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 2.5650056051744754e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.766799193238299e-32\n",
      "yk norm: 2.3183314959612497e-30\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 3987.7538772549783\n",
      "D_hat_inv: 260.9862888169228\n",
      "g_norm_D: 10945.64257107378\n",
      "loss:  tensor(541.3307, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 260.9862888169228\n",
      "B norm: 2584.7988575084833\n",
      "a: 10945.64257107378\n",
      "b: 119807091.29370263\n",
      "c: 10945.64257107378\n",
      "plms: 2622731197561.749 -1440596874387.24 -263293139.03765842 -1082.6613230560768\n",
      "lmds:  [ 5.49456257e-01 -1.78498367e-04 -4.20892776e-06]\n",
      "lmd_max: tensor([0.5495], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5495], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5495], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.9863, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5495], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.3311, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 764.5543475499786\n",
      "D_hat_inv: 261.1975266402622\n",
      "g_norm_D: 10088.690228050848\n",
      "loss:  tensor(405.3415, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 261.1975266402622\n",
      "B norm: 2249.2786885991154\n",
      "a: 10088.690228050848\n",
      "b: 101781670.51756878\n",
      "c: 10088.690228050862\n",
      "plms: 2053687489490.5781 -1108949297140.317 -219900624.77439708 -810.6830891801447\n",
      "lmds:  [ 5.40177800e-01 -1.94467159e-04 -3.75780081e-06]\n",
      "lmd_max: tensor([0.5402], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5402], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5402], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.1975, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5402], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.0237, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 5.993488996888432\n",
      "D_hat_inv: 261.3792478800623\n",
      "g_norm_D: 8919.148995298678\n",
      "loss:  tensor(467.0061, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 261.3792478800623\n",
      "B norm: 1936.9524422571374\n",
      "a: 8919.148995298678\n",
      "b: 79551218.80033249\n",
      "c: 8919.148995298126\n",
      "plms: 1419058346475.454 -783512775347.6199 -175745786.82723835 -934.0121761250532\n",
      "lmds:  [ 5.52359917e-01 -2.18769216e-04 -5.44683123e-06]\n",
      "lmd_max: tensor([0.5524], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5524], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5524], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.3792, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5524], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(144.3034, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.6199678345302834e-30\n",
      "yk norm: 7.241937004823062e-29\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 1.436250365010276e-13\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 4.534518555736096e-13\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 1305.9329839483153\n",
      "D_hat_inv: 263.4436105353911\n",
      "g_norm_D: 9864.22017844351\n",
      "loss:  tensor(445.1043, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 263.44361053539114\n",
      "B norm: 2133.4178598687636\n",
      "a: 9864.22017844351\n",
      "b: 97302839.7288122\n",
      "c: 9864.22017844352\n",
      "plms: 1919633270145.61 -1046047249250.1874 -212148378.45082977 -890.2086082760898\n",
      "lmds:  [ 5.45123094e-01 -1.98448920e-04 -4.28677018e-06]\n",
      "lmd_max: tensor([0.5451], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5451], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5451], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(263.4436, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5451], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.5408, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.003558548152736817\n",
      "yk norm: 0.1010226370578376\n",
      "D_hat_inv: 263.55580286544347\n",
      "g_norm_D: 6.095267386227473e-05\n",
      "loss:  tensor(7.7508e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.003558548152736817\n",
      "D_inv norm: 263.55580286544347\n",
      "B norm: 0.16337303947204526\n",
      "a: 6.095267386227473e-05\n",
      "b: 4.793141156777411e-05\n",
      "c: 0.7863709420865975\n",
      "plms: 7.538373854018192e-05 5.817466890186198e-05 -0.00021775872230037633 -0.00015501669367541906\n",
      "lmds:  [ 1.67872809 -1.75077821 -0.69966364]\n",
      "lmd_max: tensor([1.6787], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1.6787], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1.6787], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(263.5558, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.1634, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1.6787], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(442.2806, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 62.0094043051659\n",
      "yk norm: 2931.0005551555487\n",
      "D_hat_inv: 263.04559948676086\n",
      "g_norm_D: 17329.653867395948\n",
      "loss:  tensor(666.4585, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.0094043051659\n",
      "D_inv norm: 263.0455994867609\n",
      "B norm: 3845.1662222815303\n",
      "a: 17329.653867395948\n",
      "b: 300316903.1637516\n",
      "c: 17329.65386739596\n",
      "plms: 10408775964712.168 -5603484249100.711 -646797130.8249037 -1332.9170957087697\n",
      "lmds:  [ 5.38457690e-01 -1.13304409e-04 -2.09896441e-06]\n",
      "lmd_max: tensor([0.5385], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5385], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5385], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(263.0456, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5385], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.5721, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.924385268458076e-63\n",
      "yk norm: 6.908888774309755e-62\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.089881718145801e-125\n",
      "yk norm: 9.909878285899029e-124\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 7.548429938961736e-13\n",
      "g_norm_l2: 8.651135476114871e-26\n",
      "yk norm: 3.1002159054217984e-24\n",
      "g_norm_l2: 1.1685945270226963e-55\n",
      "yk norm: 9.635510702975523e-54\n",
      "g_norm_l2: 3.1100134204857773e-118\n",
      "yk norm: 1.3782016236109082e-116\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 2.1122199355191447e-13\n",
      "g_norm_l2: 0.023181489140697238\n",
      "yk norm: 0.49562655097164715\n",
      "D_hat_inv: 264.1645683551876\n",
      "g_norm_D: 0.002696868964323723\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.023181489140697238\n",
      "D_inv norm: 264.16456835518767\n",
      "B norm: 1.0360460993360008\n",
      "a: 0.002696868964323723\n",
      "b: 0.014022198445493097\n",
      "c: 5.199436320781478\n",
      "plms: 0.14581505578940476 -0.04485586041549158 -0.0334353381363872 -0.001037100803691304\n",
      "lmds:  [ 0.66724704 -0.32703104 -0.0325944 ]\n",
      "lmd_max: tensor([0.6672], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.6672], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.6672], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(264.1646, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1.0360, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.6672], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(176.1836, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 1327.921183903485\n",
      "D_hat_inv: 261.4106049505759\n",
      "g_norm_D: 9358.83750402191\n",
      "loss:  tensor(395.1733, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 261.4106049505759\n",
      "B norm: 2118.7572974701147\n",
      "a: 9358.83750402191\n",
      "b: 87587839.42668709\n",
      "c: 9358.83750402191\n",
      "plms: 1639440713045.4558 -888594751137.3823 -189950410.88675398 -790.3465415459141\n",
      "lmds:  [ 5.42224591e-01 -2.09437239e-04 -4.24510783e-06]\n",
      "lmd_max: tensor([0.5422], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5422], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5422], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.4106, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5422], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.6762, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.709399045837562e-13\n",
      "yk norm: 1.7656808588318112e-11\n",
      "g_norm_l2: 8.678047690233398e-69\n",
      "yk norm: 1.772370848551913e-67\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 3915.905616581886\n",
      "D_hat_inv: 260.15174810738733\n",
      "g_norm_D: 8390.232017269564\n",
      "loss:  tensor(519.3931, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 260.15174810738733\n",
      "B norm: 1722.8004622114474\n",
      "a: 8390.232017269564\n",
      "b: 70395993.30361529\n",
      "c: 8390.232017269565\n",
      "plms: 1181277433806.974 -663483525037.7471 -158206521.97736105 -1038.7862813737588\n",
      "lmds:  [ 5.61904480e-01 -2.31592423e-04 -6.75752181e-06]\n",
      "lmd_max: tensor([0.5619], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5619], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5619], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.1517, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5619], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(146.1074, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "Loss: 109.9659028568456 | GradNorm^2: 58.9556724671858\n",
      "g_norm_l2: 8.161772356720916e-26\n",
      "yk norm: 7.196397272668924e-25\n",
      "g_norm_l2: 2.5425291577566392e-11\n",
      "yk norm: 1.0496606014782916e-10\n",
      "D_hat_inv: 260.37345513206753\n",
      "g_norm_D: 3.1381665037517456e-21\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 387.63420572210487\n",
      "D_hat_inv: 260.3402130247224\n",
      "g_norm_D: 8871.004370298648\n",
      "loss:  tensor(464.9112, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 260.3402130247224\n",
      "B norm: 1936.9524422572597\n",
      "a: 8871.004370298648\n",
      "b: 78694718.53785783\n",
      "c: 8871.00437029866\n",
      "plms: 1396202384137.5195 -770958524831.742 -173868612.12004828 -929.8223946494251\n",
      "lmds:  [ 5.52407934e-01 -2.19951745e-04 -5.48105683e-06]\n",
      "lmd_max: tensor([0.5524], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5524], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5524], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.3402, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5524], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.7426, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 9.571173021820417e-14\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 2169.891720536739\n",
      "D_hat_inv: 260.1300230933693\n",
      "g_norm_D: 9995.687853128751\n",
      "loss:  tensor(402.7504, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 260.1300230933693\n",
      "B norm: 2249.278688599113\n",
      "a: 9995.687853128751\n",
      "b: 99913775.6571857\n",
      "c: 9995.687853128755\n",
      "plms: 1997413827393.5251 -1078787882754.657 -215910628.6505061 -805.500779358597\n",
      "lmds:  [ 5.40292397e-01 -1.96266167e-04 -3.80297623e-06]\n",
      "lmd_max: tensor([0.5403], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5403], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5403], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.1300, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5403], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.4784, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 7.699189026880917e-94\n",
      "yk norm: 3.5563573459466683e-92\n",
      "g_norm_l2: 5.659135499704453e-15\n",
      "yk norm: 8.139306308842374e-14\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 8.12596003301184e-14\n",
      "g_norm_l2: 2.882724029968699e-118\n",
      "yk norm: 1.044255876789962e-116\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 6101.094192362442\n",
      "D_hat_inv: 247.10155052913308\n",
      "g_norm_D: 13932.66846863984\n",
      "loss:  tensor(664.9254, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 247.10155052913308\n",
      "B norm: 3845.16622228153\n",
      "a: 13932.66846863984\n",
      "b: 194119250.65703088\n",
      "c: 13932.668468639848\n",
      "plms: 5409198325570.42 -2961972329135.309 -425267376.96450686 -1329.8508132448221\n",
      "lmds:  [ 5.47724188e-01 -1.40340595e-04 -3.19834114e-06]\n",
      "lmd_max: tensor([0.5477], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5477], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5477], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(247.1016, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5477], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(135.2756, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 3576.642758683857\n",
      "D_hat_inv: 246.77880570196632\n",
      "g_norm_D: 7383.702045455058\n",
      "loss:  tensor(517.7528, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 246.77880570196632\n",
      "B norm: 1722.8004622114468\n",
      "a: 7383.702045455058\n",
      "b: 54519055.89605721\n",
      "c: 7383.702045455057\n",
      "plms: 805104929071.9923 -458789180149.63275 -124315075.14575927 -1035.505676122751\n",
      "lmds:  [ 5.70121008e-01 -2.62235810e-04 -8.60282239e-06]\n",
      "lmd_max: tensor([0.5701], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5701], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5701], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(246.7788, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5701], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.6195, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.01001626038586501\n",
      "yk norm: 0.6383483080087095\n",
      "D_hat_inv: 246.87928143507796\n",
      "g_norm_D: 0.0004657844139472905\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.01001626038586501\n",
      "D_inv norm: 246.87928143507798\n",
      "B norm: 0.44778677928245714\n",
      "a: 0.0004657844139472905\n",
      "b: 0.0009683446537245924\n",
      "c: 2.0789546080306858\n",
      "plms: 0.004026289160045239 -7.623834985289986e-05 -0.0028680494509216066 -0.0004480446480579209\n",
      "lmds:  [ 0.92220389 -0.7402628  -0.16300595]\n",
      "lmd_max: tensor([0.9222], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.9222], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.9222], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(246.8793, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.4478, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.9222], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(227.5689, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.876727943093604e-33\n",
      "yk norm: 4.644387692956343e-31\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.666584464134405e-13\n",
      "yk norm: 1.3174695969520523e-11\n",
      "g_norm_l2: 4.06964805684629e-97\n",
      "yk norm: 4.486430593190022e-96\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 3195.5687656123227\n",
      "D_hat_inv: 247.5342004815881\n",
      "g_norm_D: 10376.957946007871\n",
      "loss:  tensor(536.0912, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 247.5342004815881\n",
      "B norm: 2584.7988575084833\n",
      "a: 10376.957946007871\n",
      "b: 107681256.21321589\n",
      "c: 10376.957946007871\n",
      "plms: 2234807734595.6807 -1232427099052.2656 -237593743.60674897 -1072.182484114711\n",
      "lmds:  [ 5.51661680e-01 -1.88095901e-04 -4.62355888e-06]\n",
      "lmd_max: tensor([0.5517], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5517], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5517], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(247.5342, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5517], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.4837, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 4.5499333185614224e-82\n",
      "yk norm: 1.4064423295638539e-80\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 1.6148153715835498e-13\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 3964.6657074249274\n",
      "D_hat_inv: 247.8720986684342\n",
      "g_norm_D: 8985.864686134513\n",
      "loss:  tensor(392.5833, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 247.87209866843418\n",
      "B norm: 2118.7572974701143\n",
      "a: 8985.864686134513\n",
      "b: 80745764.15751928\n",
      "c: 8985.864686134511\n",
      "plms: 1451141021395.9968 -788646411275.8191 -175584359.68562338 -785.1666808276401\n",
      "lmds:  [ 5.43688968e-01 -2.17985501e-04 -4.56535037e-06]\n",
      "lmd_max: tensor([0.5437], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5437], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5437], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(247.8721, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5437], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(134.6947, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 2.919520159858482e-13\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 3.4799165818698786e-13\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0005667764814638286\n",
      "yk norm: 0.016825962428395472\n",
      "D_hat_inv: 248.2774476745465\n",
      "g_norm_D: 1.5536037311251283e-06\n",
      "loss:  tensor(1.3390e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0005667764814638286\n",
      "D_inv norm: 248.2774476745465\n",
      "B norm: 0.023991337229587937\n",
      "a: 1.5536037311251283e-06\n",
      "b: 1.8026496347749434e-07\n",
      "c: 0.11603020761732173\n",
      "plms: 4.183236227684517e-08 3.3961615947786085e-07 -3.467695785189456e-06 -2.6779118335202405e-05\n",
      "lmds:  [  8.99872583 -10.01177721  -7.10545164]\n",
      "lmd_max: tensor([8.9987], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([8.9987], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([8.9987], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(248.2774, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0240, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([8.9987], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(2233.2912, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 1.4660379480323817e-14\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0020994176480105117\n",
      "yk norm: 0.1549988615353206\n",
      "D_hat_inv: 248.88374742867964\n",
      "g_norm_D: 2.032997848002554e-05\n",
      "loss:  tensor(4.5726e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0020994176480105117\n",
      "D_inv norm: 248.8837474286796\n",
      "B norm: 0.09638738287132051\n",
      "a: 2.032997848002554e-05\n",
      "b: 9.038499513462334e-06\n",
      "c: 0.44458972361150184\n",
      "plms: 8.036848001105827e-06 1.4058988321811028e-05 -5.873509676523795e-05 -9.145291757735605e-05\n",
      "lmds:  [ 2.64354764 -2.91739915 -1.47546468]\n",
      "lmd_max: tensor([2.6435], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([2.6435], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([2.6435], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(248.8837, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0964, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([2.6435], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(657.6770, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 4.78281738335888e-56\n",
      "yk norm: 1.7837866186429304e-55\n",
      "g_norm_l2: 5.3465603456984e-30\n",
      "yk norm: 1.9011300324010996e-28\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.4823900563253303e-32\n",
      "yk norm: 7.804216613605674e-31\n",
      "g_norm_l2: 5.25783143121383e-56\n",
      "yk norm: 2.773565189394808e-54\n",
      "g_norm_l2: 5.648476119804198e-69\n",
      "yk norm: 2.074371035662916e-67\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 367.3660075171185\n",
      "D_hat_inv: 251.24137761631553\n",
      "g_norm_D: 9714.029090757034\n",
      "loss:  tensor(442.5786, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 251.24137761631553\n",
      "B norm: 2133.417859868763\n",
      "a: 9714.029090757034\n",
      "b: 94362361.17607403\n",
      "c: 9714.029090757043\n",
      "plms: 1833277443073.8123 -999786794222.5009 -205902179.61311266 -885.1571865019968\n",
      "lmds:  [ 5.45560747e-01 -2.01477385e-04 -4.39261143e-06]\n",
      "lmd_max: tensor([0.5456], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5456], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5456], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(251.2414, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5456], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.9935, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 3.029128092619702e-13\n",
      "g_norm_l2: 1.0647176674449226e-63\n",
      "yk norm: 4.554984227607428e-62\n",
      "g_norm_l2: 1.4780626234963077e-28\n",
      "yk norm: 3.439422613831777e-27\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.120805053451335e-68\n",
      "yk norm: 3.3872558915230155e-66\n",
      "g_norm_l2: 1.6626564066222953e-125\n",
      "yk norm: 2.1218321670590212e-123\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "Loss: 109.38103748304005 | GradNorm^2: 58.95567481043184\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 7.513542712337427e-14\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.3241988334828124e-32\n",
      "yk norm: 5.995171120944453e-31\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 3671.282441813148\n",
      "D_hat_inv: 252.4232126539674\n",
      "g_norm_D: 10802.43776706886\n",
      "loss:  tensor(534.1027, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 252.42321265396743\n",
      "B norm: 2584.798857508484\n",
      "a: 10802.43776706886\n",
      "b: 116692661.7113957\n",
      "c: 10802.437767068863\n",
      "plms: 2521130432021.9424 -1384750184182.5383 -256442164.63623402 -1068.205463739453\n",
      "lmds:  [ 5.49442782e-01 -1.80865560e-04 -4.26364586e-06]\n",
      "lmd_max: tensor([0.5494], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5494], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5494], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.4232, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5494], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(138.6217, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 2.670633427629324e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.9050218347699917e-125\n",
      "yk norm: 7.756792322290177e-124\n",
      "g_norm_l2: 2.8574273715458434e-56\n",
      "yk norm: 8.070098460818357e-55\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 1010.6405211014518\n",
      "D_hat_inv: 253.29366692669834\n",
      "g_norm_D: 8617.11815193439\n",
      "loss:  tensor(461.4580, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 253.29366692669834\n",
      "B norm: 1936.9524422572595\n",
      "a: 8617.11815193439\n",
      "b: 74254725.24439725\n",
      "c: 8617.118151934403\n",
      "plms: 1279723481540.7947 -708095590427.4103 -164397967.42119348 -922.9159266623415\n",
      "lmds:  [ 5.53551288e-01 -2.26317539e-04 -5.75665133e-06]\n",
      "lmd_max: tensor([0.5536], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5536], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5536], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(253.2937, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5536], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.1383, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 2421.8355450605295\n",
      "D_hat_inv: 253.31235917420682\n",
      "g_norm_D: 14477.144531581922\n",
      "loss:  tensor(663.3001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 253.31235917420682\n",
      "B norm: 3845.1662222815285\n",
      "a: 14477.144531581922\n",
      "b: 209587713.7883123\n",
      "c: 14477.14453158192\n",
      "plms: 6068463249114.444 -3311432387680.413 -457557240.46223485 -1326.6002522417405\n",
      "lmds:  [ 5.45817047e-01 -1.35177943e-04 -2.96284152e-06]\n",
      "lmd_max: tensor([0.5458], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5458], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5458], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(253.3124, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5458], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(138.1961, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.203258687954897e-13\n",
      "yk norm: 1.153986677782593e-11\n",
      "g_norm_l2: 8.16999247613394e-82\n",
      "yk norm: 7.822837372916481e-80\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.486805509032666e-118\n",
      "yk norm: 7.32750509125298e-117\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 3713.86358946429\n",
      "D_hat_inv: 252.035070489724\n",
      "g_norm_D: 9238.732204210553\n",
      "loss:  tensor(390.1229, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 252.03507048972398\n",
      "B norm: 2118.7572974701143\n",
      "a: 9238.732204210553\n",
      "b: 85354172.7411172\n",
      "c: 9238.732204210552\n",
      "plms: 1577128688934.2192 -854820170870.9891 -185106833.8141702 -780.2458972549125\n",
      "lmds:  [ 5.42226872e-01 -2.12159484e-04 -4.30051905e-06]\n",
      "lmd_max: tensor([0.5422], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5422], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5422], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.0351, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5422], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.5900, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 4.785423449078437e-56\n",
      "yk norm: 6.1394336704708245e-55\n",
      "g_norm_l2: 5.6108833623809525e-33\n",
      "yk norm: 7.356628542459521e-32\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 1.8753024468330417e-160\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.1078868513244544e-28\n",
      "yk norm: 1.6222232313448563e-26\n",
      "g_norm_l2: 41.50305552443547\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.00993313159032829\n",
      "yk norm: 0.08177809388574034\n",
      "D_hat_inv: 252.75724344580374\n",
      "g_norm_D: 0.0004784250689139149\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.00993313159032829\n",
      "D_inv norm: 252.75724344580374\n",
      "B norm: 0.4440712503858432\n",
      "a: 0.0004784250689139149\n",
      "b: 0.0010301681910961917\n",
      "c: 2.1532487698330756\n",
      "plms: 0.004436416780398079 -0.00015764315135796724 -0.003016973951317614 -0.0004443257401933633\n",
      "lmds:  [ 0.90702699 -0.71762374 -0.15386935]\n",
      "lmd_max: tensor([0.9070], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.9070], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.9070], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.7572, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.4441, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.9070], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(229.1566, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 1262.3369853803176\n",
      "D_hat_inv: 253.34870466024475\n",
      "g_norm_D: 9935.507318747033\n",
      "loss:  tensor(440.7001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 253.34870466024475\n",
      "B norm: 2133.417859868761\n",
      "a: 9935.507318747033\n",
      "b: 98714305.68087581\n",
      "c: 9935.50731874703\n",
      "plms: 1961553413114.7466 -1067388650569.4263 -214923055.10598025 -881.4001236665015\n",
      "lmds:  [ 5.44356053e-01 -1.97093024e-04 -4.18811558e-06]\n",
      "lmd_max: tensor([0.5444], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5444], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5444], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(253.3487, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5444], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(137.8401, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.987089859967086e-30\n",
      "yk norm: 1.1112216285117511e-29\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.532640360579686e-26\n",
      "yk norm: 1.267250211344603e-24\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 1.4635435400755133e-12\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.0849808549056515e-12\n",
      "yk norm: 1.6169784329940262e-10\n",
      "D_hat_inv: 254.41981511279073\n",
      "g_norm_D: 2.0004241217831176e-23\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 207.88951724188942\n",
      "D_hat_inv: 252.77502821323776\n",
      "g_norm_D: 7681.4917348497565\n",
      "loss:  tensor(515.6281, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 252.7750282132378\n",
      "B norm: 1722.8004622114447\n",
      "a: 7681.4917348497565\n",
      "b: 59005315.27256504\n",
      "c: 7681.491734849746\n",
      "plms: 906497683156.8236 -513862417547.9147 -133838439.52122334 -1031.2562003865041\n",
      "lmds:  [ 5.67126011e-01 -2.52392000e-04 -7.94775960e-06]\n",
      "lmd_max: tensor([0.5671], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5671], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5671], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.7750, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5671], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.2815, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0009869432922675909\n",
      "yk norm: 0.036400724307559036\n",
      "D_hat_inv: 252.87997710914468\n",
      "g_norm_D: 4.804524278254301e-06\n",
      "loss:  tensor(2.3316e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0009869432922675909\n",
      "D_inv norm: 252.8799771091447\n",
      "B norm: 0.041776352926262104\n",
      "a: 4.804524278254301e-06\n",
      "b: 9.900267030839867e-07\n",
      "c: 0.20606133838576582\n",
      "plms: 4.08012454950267e-07 1.7760702617917615e-06 -1.1588877921630328e-05 -4.6631438052666936e-05\n",
      "lmds:  [ 5.23720731 -5.87692999 -3.71325783]\n",
      "lmd_max: tensor([5.2372], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([5.2372], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([5.2372], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.8800, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0418, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([5.2372], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(1323.8721, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 693.1975420125801\n",
      "D_hat_inv: 253.3449366294461\n",
      "g_norm_D: 10018.39891740481\n",
      "loss:  tensor(398.7702, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 253.34493662944607\n",
      "B norm: 2249.278688599115\n",
      "a: 10018.39891740481\n",
      "b: 100368316.868258\n",
      "c: 10018.398917404822\n",
      "plms: 2011059674109.3997 -1085176156616.0806 -216696753.74593064 -797.540452271637\n",
      "lmds:  [ 5.39803771e-01 -1.95864706e-04 -3.75090156e-06]\n",
      "lmd_max: tensor([0.5398], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5398], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5398], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(253.3449, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5398], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.6851, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 3.6205204551342537e-69\n",
      "yk norm: 1.842975982974312e-67\n",
      "g_norm_l2: 8.52815520685114e-64\n",
      "yk norm: 2.42604831014132e-62\n",
      "g_norm_l2: 6.296491914374188e-15\n",
      "yk norm: 6.580146673710221e-14\n",
      "g_norm_l2: 3.9385148519359333e-97\n",
      "yk norm: 1.7650774858137465e-95\n",
      "g_norm_l2: 0.0015443531190430654\n",
      "yk norm: 0.002884350132889319\n",
      "D_hat_inv: 253.85540804537519\n",
      "g_norm_D: 1.127575025273275e-05\n",
      "loss:  tensor(3.3637e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0015443531190430654\n",
      "D_inv norm: 253.85540804537519\n",
      "B norm: 0.07090440302262853\n",
      "a: 1.127575025273275e-05\n",
      "b: 3.7798179397280767e-06\n",
      "c: 0.3352165359295727\n",
      "plms: 2.5341149524002e-06 6.292705542940483e-06 -3.0110377832339652e-05 -6.727329595074742e-05\n",
      "lmds:  [ 3.37295825 -3.76657669 -2.08957813]\n",
      "lmd_max: tensor([3.3730], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([3.3730], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([3.3730], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(253.8554, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0709, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([3.3730], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(855.9258, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 8.042209349540689e-14\n",
      "g_norm_l2: 8.993624425962265e-68\n",
      "yk norm: 6.252063799219436e-66\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.107970599773511e-94\n",
      "yk norm: 8.21105270960158e-93\n",
      "Loss: 108.79526075055057 | GradNorm^2: 58.95565988333781\n",
      "g_norm_l2: 1.4933170950609048e-12\n",
      "yk norm: 3.1758262429217085e-12\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.6223723749522736e-125\n",
      "yk norm: 1.1247797561877999e-123\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946611\n",
      "yk norm: 2.0494585098200074e-13\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 1.7155551412947514e-13\n",
      "g_norm_l2: 2.1163949678205517e-28\n",
      "yk norm: 3.45027574490016e-27\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.319629746506536\n",
      "yk norm: 2.4509490500123695e-13\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 4.0211046747703445e-14\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 7.69120589807006e-33\n",
      "yk norm: 3.8562902466940896e-31\n",
      "g_norm_l2: 3.483748957792553e-56\n",
      "yk norm: 3.7967065168255086e-55\n",
      "g_norm_l2: 8.646931453758583e-64\n",
      "yk norm: 2.3933155762834463e-62\n",
      "g_norm_l2: 8.993624425962265e-68\n",
      "yk norm: 5.010446466948134e-66\n",
      "g_norm_l2: 9.133305064114336e-82\n",
      "yk norm: 9.47164129636157e-80\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 1044.3435640388484\n",
      "D_hat_inv: 254.21779061620228\n",
      "g_norm_D: 10848.333801519797\n",
      "loss:  tensor(530.5382, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 254.21779061620228\n",
      "B norm: 2584.798857508482\n",
      "a: 10848.333801519797\n",
      "b: 117686346.26919693\n",
      "c: 10848.333801519791\n",
      "plms: 2553401536418.983 -1401104221810.287 -258372816.78275025 -1061.076352053907\n",
      "lmds:  [ 5.48905024e-01 -1.80143473e-04 -4.20253928e-06]\n",
      "lmd_max: tensor([0.5489], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5489], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5489], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(254.2178, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5489], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.4734, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 2.8923254849143023e-14\n",
      "g_norm_l2: 3.188749944998339e-26\n",
      "yk norm: 1.6754248480119025e-24\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 4.462450699772943e-13\n",
      "g_norm_l2: 46.96174334896987\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 4.841223438321003e-14\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 5.389362582025683e-14\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 3655.5576954921708\n",
      "D_hat_inv: 256.21937021768827\n",
      "g_norm_D: 10011.964724383519\n",
      "loss:  tensor(438.8324, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 256.21937021768827\n",
      "B norm: 2133.4178598687618\n",
      "a: 10011.964724383519\n",
      "b: 100239437.64229998\n",
      "c: 10011.964724383522\n",
      "plms: 2007187427333.4985 -1091169374186.9839 -218033147.8479349 -877.6647229880168\n",
      "lmds:  [ 5.43830777e-01 -1.95634224e-04 -4.10990800e-06]\n",
      "lmd_max: tensor([0.5438], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5438], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5438], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(256.2194, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5438], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.2676, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.421911609012799e-94\n",
      "yk norm: 1.0543248325921508e-92\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 307.586465538298\n",
      "D_hat_inv: 256.24947968581915\n",
      "g_norm_D: 9451.717551398744\n",
      "loss:  tensor(387.6332, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 256.2494796858191\n",
      "B norm: 2118.7572974701125\n",
      "a: 9451.717551398744\n",
      "b: 89334964.67141896\n",
      "c: 9451.717551398733\n",
      "plms: 1688737707076.8728 -913269906410.3723 -193306223.19944265 -775.2663583106519\n",
      "lmds:  [ 5.41011911e-01 -2.07493062e-04 -4.08957644e-06]\n",
      "lmd_max: tensor([0.5410], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5410], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5410], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(256.2495, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5410], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(138.5632, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0009420525861764652\n",
      "yk norm: 0.06287220303464645\n",
      "D_hat_inv: 256.35093205636656\n",
      "g_norm_D: 4.28114368636182e-06\n",
      "loss:  tensor(2.0518e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0009420525861764652\n",
      "D_inv norm: 256.35093205636656\n",
      "B norm: 0.043252123934079914\n",
      "a: 4.28114368636182e-06\n",
      "b: 8.932576714788401e-07\n",
      "c: 0.208649308904169\n",
      "plms: 3.7275519165481447e-07 1.6001560750678494e-06 -1.0348627033934064e-05 -4.103631867662961e-05\n",
      "lmds:  [ 5.1771351  -5.80981697 -3.66009825]\n",
      "lmd_max: tensor([5.1771], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([5.1771], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([5.1771], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(256.3509, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0433, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([5.1771], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(1326.6742, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.197119970248217e-97\n",
      "yk norm: 1.651458578259604e-95\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 1509.9275883575826\n",
      "D_hat_inv: 254.04028681633034\n",
      "g_norm_D: 7725.353154711673\n",
      "loss:  tensor(514.3573, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 254.04028681633034\n",
      "B norm: 1722.8004622114477\n",
      "a: 7725.353154711673\n",
      "b: 59681081.36501361\n",
      "c: 7725.3531547116745\n",
      "plms: 922114860399.624 -522213508283.315 -135241079.87446606 -1028.7146446537752\n",
      "lmds:  [ 5.66580402e-01 -2.51017637e-04 -7.84411797e-06]\n",
      "lmd_max: tensor([0.5666], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5666], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5666], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(254.0403, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5666], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.8632, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 3440.0675588399713\n",
      "D_hat_inv: 254.42908684662314\n",
      "g_norm_D: 8848.9301142471\n",
      "loss:  tensor(457.4011, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 254.42908684662314\n",
      "B norm: 1936.952442257257\n",
      "a: 8848.9301142471\n",
      "b: 78303564.1668292\n",
      "c: 8848.930114247101\n",
      "plms: 1385805534017.4702 -764221819424.3877 -172779470.56810513 -914.8021221576088\n",
      "lmds:  [ 5.51689964e-01 -2.20570264e-04 -5.42478868e-06]\n",
      "lmd_max: tensor([0.5517], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5517], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5517], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(254.4291, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5517], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.2920, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.8924904766721826e-69\n",
      "yk norm: 8.788670842925831e-68\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.806894471132518e-33\n",
      "yk norm: 1.1066268063399215e-31\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.9590582662972515e-118\n",
      "yk norm: 3.528803886206723e-116\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 992.9876962408229\n",
      "D_hat_inv: 251.1943003321299\n",
      "g_norm_D: 14648.702285487605\n",
      "loss:  tensor(661.4000, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 251.1943003321299\n",
      "B norm: 3845.166222281526\n",
      "a: 14648.702285487605\n",
      "b: 214584478.64884964\n",
      "c: 14648.702285487594\n",
      "plms: 6286768285627.135 -3426378159169.67 -467894267.4670578 -1322.8000275602406\n",
      "lmds:  [ 5.45150750e-01 -1.33634805e-04 -2.88822176e-06]\n",
      "lmd_max: tensor([0.5452], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5452], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5452], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(251.1943, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5452], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.8720, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0587591833052213e-56\n",
      "yk norm: 1.5857957762236768e-55\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.009758693173778732\n",
      "yk norm: 0.7936786394946326\n",
      "D_hat_inv: 251.6443080101062\n",
      "g_norm_D: 0.00045744438367639046\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.009758693173778732\n",
      "D_inv norm: 251.64430801010622\n",
      "B norm: 0.43627449706914107\n",
      "a: 0.00045744438367639046\n",
      "b: 0.0009586345988883406\n",
      "c: 2.095630929347045\n",
      "plms: 0.0040178886307452085 -9.14658926780916e-05 -0.0028319582878724584 -0.0004365219638218015\n",
      "lmds:  [ 0.91870037 -0.73505001 -0.16088569]\n",
      "lmd_max: tensor([0.9187], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.9187], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.9187], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(251.6443, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.4363, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.9187], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(231.0830, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.578089914712296e-15\n",
      "yk norm: 2.1244456881288063e-13\n",
      "g_norm_l2: 0.0019605263347519547\n",
      "yk norm: 0.016282662658708407\n",
      "D_hat_inv: 251.98400250034422\n",
      "g_norm_D: 1.838011795004072e-05\n",
      "loss:  tensor(4.6316e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0019605263347519547\n",
      "D_inv norm: 251.98400250034422\n",
      "B norm: 0.08298527069397861\n",
      "a: 1.838011795004072e-05\n",
      "b: 7.293772991787919e-06\n",
      "c: 0.39682949867967304\n",
      "plms: 5.788768559629077e-06 1.1693499522045648e-05 -5.134607929710322e-05 -9.263269169532469e-05\n",
      "lmds:  [ 2.91231972 -3.23258753 -1.69976449]\n",
      "lmd_max: tensor([2.9123], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([2.9123], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([2.9123], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(251.9840, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0830, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([2.9123], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(733.5802, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 2560.248343315363\n",
      "D_hat_inv: 252.7486389976893\n",
      "g_norm_D: 10291.698074887156\n",
      "loss:  tensor(396.1040, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 252.7486389976893\n",
      "B norm: 2249.2786885991127\n",
      "a: 10291.698074887156\n",
      "b: 105919049.26463601\n",
      "c: 10291.698074887157\n",
      "plms: 2180173750821.4648 -1173573121696.382 -228123847.06632528 -792.2080406241323\n",
      "lmds:  [ 5.38487706e-01 -1.90778045e-04 -3.53707246e-06]\n",
      "lmd_max: tensor([0.5385], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5385], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5385], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.7486, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5385], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.0295, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.0210831098223961e-13\n",
      "yk norm: 2.7809471832499116e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.3089075987017103e-29\n",
      "yk norm: 2.9208594363289973e-28\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 3.904533728081158e-160\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 3.075491000177981e-13\n",
      "Loss: 108.21078677005517 | GradNorm^2: 58.95560777175445\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.3644980307045\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.576233449570031e-57\n",
      "yk norm: 5.153951023770935e-56\n",
      "g_norm_l2: 2.8669726068663918e-28\n",
      "yk norm: 2.3066627056403283e-26\n",
      "g_norm_l2: 2.415126414226974e-26\n",
      "yk norm: 2.500789742942297e-25\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.20738507735562\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 2.168177481273452e-13\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 3556.1734942504204\n",
      "D_hat_inv: 252.99849529243969\n",
      "g_norm_D: 8529.875635414108\n",
      "loss:  tensor(456.0041, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 252.99849529243969\n",
      "B norm: 1936.952442257256\n",
      "a: 8529.875635414108\n",
      "b: 72758778.35563119\n",
      "c: 8529.875635414104\n",
      "plms: 1241246661516.3875 -686688898788.0323 -161059130.1639186 -912.008209084032\n",
      "lmds:  [ 5.53459620e-01 -2.28641274e-04 -5.80630817e-06]\n",
      "lmd_max: tensor([0.5535], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5535], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5535], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.9985, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5535], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.9547, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.4974919671715366e-69\n",
      "yk norm: 1.360150115141822e-68\n",
      "g_norm_l2: 0.007578458767595345\n",
      "yk norm: 0.23982702013459622\n",
      "D_hat_inv: 253.21914009894593\n",
      "g_norm_D: 0.0002777467118602443\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.007578458767595345\n",
      "D_inv norm: 253.21914009894593\n",
      "B norm: 0.33882093325500645\n",
      "a: 0.0002777467118602443\n",
      "b: 0.00045509944155760915\n",
      "c: 1.638541239640686\n",
      "plms: 0.0014913984062591777 0.00016457681450561187 -0.0014655981566024183 -0.0003389883239836231\n",
      "lmds:  [ 1.04203546 -0.91364214 -0.23874399]\n",
      "lmd_max: tensor([1.0420], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1.0420], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1.0420], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(253.2191, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.3388, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1.0420], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(263.7496, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0017172844384122684\n",
      "yk norm: 0.006549973648534418\n",
      "D_hat_inv: 253.32951337666353\n",
      "g_norm_D: 1.4195295946350788e-05\n",
      "loss:  tensor(4.0570e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0017172844384122684\n",
      "D_inv norm: 253.32951337666353\n",
      "B norm: 0.07268973152585262\n",
      "a: 1.4195295946350788e-05\n",
      "b: 4.966809444886819e-06\n",
      "c: 0.34989122196946143\n",
      "plms: 3.4756860519218233e-06 8.195977364809218e-06 -3.8323058990239e-05 -8.11395491341059e-05\n",
      "lmds:  [ 3.24844582 -3.62291685 -1.98361807]\n",
      "lmd_max: tensor([3.2484], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([3.2484], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([3.2484], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(253.3295, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0727, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([3.2484], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(822.6175, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 2.1740477538411666e-13\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 1527.8985915881196\n",
      "D_hat_inv: 254.26691103521247\n",
      "g_norm_D: 11240.03485348123\n",
      "loss:  tensor(526.4716, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 254.26691103521247\n",
      "B norm: 2584.798857508483\n",
      "a: 11240.03485348123\n",
      "b: 126338383.50747278\n",
      "c: 11240.034853481227\n",
      "plms: 2840095667912.944 -1552569615690.6084 -276324522.3141202 -1052.943148194532\n",
      "lmds:  [ 5.46838950e-01 -1.74026353e-04 -3.89580749e-06]\n",
      "lmd_max: tensor([0.5468], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5468], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5468], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(254.2669, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5468], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(138.9712, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 246.92818625120182\n",
      "D_hat_inv: 251.16142351497354\n",
      "g_norm_D: 9343.86859704391\n",
      "loss:  tensor(436.3142, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 251.16142351497354\n",
      "B norm: 2133.417859868757\n",
      "a: 9343.86859704391\n",
      "b: 87307880.35882312\n",
      "c: 9343.86859704389\n",
      "plms: 1631586723118.5447 -891631467488.4003 -190904523.51002544 -872.6284172453179\n",
      "lmds:  [ 5.46695223e-01 -2.09351940e-04 -4.67301224e-06]\n",
      "lmd_max: tensor([0.5467], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5467], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5467], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(251.1614, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5467], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(137.2378, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 5.716251005104367e-160\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.55517726988619e-33\n",
      "yk norm: 6.170906305116957e-32\n",
      "g_norm_l2: 7.717605572995047e-68\n",
      "yk norm: 1.1144067330511231e-66\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.541539854506796e-94\n",
      "yk norm: 6.123876908894658e-93\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 3.763165033593524e-13\n",
      "g_norm_l2: 1.1114710856721389e-14\n",
      "yk norm: 2.449424954621612e-13\n",
      "g_norm_l2: 6.032268524163842e-125\n",
      "yk norm: 2.196084267960029e-123\n",
      "g_norm_l2: 3.320796771809602e-29\n",
      "yk norm: 2.078040274512257e-27\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.7489463154754727e-13\n",
      "yk norm: 5.068174321625834e-12\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.8941343541906563e-97\n",
      "yk norm: 8.437024455275659e-96\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.0781011118690625e-118\n",
      "yk norm: 3.9962133803894487e-116\n",
      "g_norm_l2: 1.4942321279794693e-81\n",
      "yk norm: 4.5674357763981364e-80\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 1.422059294796186e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 7.769816818675987e-64\n",
      "yk norm: 3.5589344046696137e-62\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.1633577642567123e-56\n",
      "yk norm: 1.2141217949739558e-54\n",
      "g_norm_l2: 3.044408243205599e-33\n",
      "yk norm: 3.5371983485114136e-32\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 740.1564384560651\n",
      "D_hat_inv: 254.60374041025847\n",
      "g_norm_D: 10299.357052218862\n",
      "loss:  tensor(393.7677, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 254.60374041025847\n",
      "B norm: 2249.278688599115\n",
      "a: 10299.357052218862\n",
      "b: 106076755.68909052\n",
      "c: 10299.357052218875\n",
      "plms: 2185044763565.8665 -1175637269993.288 -228355128.24696362 -787.5353529661421\n",
      "lmds:  [ 5.38232242e-01 -1.90658374e-04 -3.51223951e-06]\n",
      "lmd_max: tensor([0.5382], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5382], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5382], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(254.6037, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5382], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.9644, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 223.9334519063856\n",
      "D_hat_inv: 252.89212959488128\n",
      "g_norm_D: 7857.877497698336\n",
      "loss:  tensor(512.2728, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 252.89212959488128\n",
      "B norm: 1722.8004622114418\n",
      "a: 7857.877497698336\n",
      "b: 61746238.76883365\n",
      "c: 7857.87749769831\n",
      "plms: 970388760378.2501 -548209235850.8162 -139578270.27152196 -1024.545654571888\n",
      "lmds:  [ 5.65192239e-01 -2.46931242e-04 -7.56507655e-06]\n",
      "lmd_max: tensor([0.5652], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5652], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5652], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.8921, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5652], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(142.8572, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.02996086757096\n",
      "yk norm: 2217.081593560264\n",
      "D_hat_inv: 252.13645963958754\n",
      "g_norm_D: 9180.605664127565\n",
      "loss:  tensor(383.8460, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757096\n",
      "D_inv norm: 252.13645963958754\n",
      "B norm: 2118.757297470114\n",
      "a: 9180.605664127565\n",
      "b: 84283520.3602111\n",
      "c: 9180.605664127565\n",
      "plms: 1547547528823.1301 -838140407180.5486 -182644432.9305156 -767.6919114661247\n",
      "lmds:  [ 5.41810506e-01 -2.13542786e-04 -4.28756424e-06]\n",
      "lmd_max: tensor([0.5418], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5418], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5418], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.1365, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5418], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.5397, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0007198780765051189\n",
      "yk norm: 0.009292724313277273\n",
      "D_hat_inv: 252.4439960659037\n",
      "g_norm_D: 2.4820962396343713e-06\n",
      "loss:  tensor(1.5679e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0007198780765051189\n",
      "D_inv norm: 252.44399606590366\n",
      "B norm: 0.03305166495995036\n",
      "a: 2.4820962396343713e-06\n",
      "b: 3.929277305224099e-07\n",
      "c: 0.1583047926378111\n",
      "plms: 1.2440468580399163e-07 7.236592788750205e-07 -5.7499701065083585e-06 -3.135820135100857e-05\n",
      "lmds:  [ 6.69911148 -7.49753202 -5.01855713]\n",
      "lmd_max: tensor([6.6991], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([6.6991], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([6.6991], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.4440, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0331, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([6.6991], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(1690.5150, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 7.762362107513724e-13\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 6311.11611075319\n",
      "D_hat_inv: 251.06337831861998\n",
      "g_norm_D: 15059.083167164172\n",
      "loss:  tensor(660.2010, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 251.06337831861998\n",
      "B norm: 3845.1662222815294\n",
      "a: 15059.083167164172\n",
      "b: 226775985.83556733\n",
      "c: 15059.083167164175\n",
      "plms: 6830076862026.908 -3713566802784.5776 -493289941.9588671 -1320.4020461477928\n",
      "lmds:  [ 5.43840711e-01 -1.30069803e-04 -2.73295454e-06]\n",
      "lmd_max: tensor([0.5438], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5438], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5438], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(251.0634, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5438], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(136.4702, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.031276465451965e-14\n",
      "yk norm: 1.6441861821037293e-12\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 34.87882810420822\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "Loss: 107.62032959895524 | GradNorm^2: 58.95549753040389\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 1413.422787372086\n",
      "D_hat_inv: 251.8265711664665\n",
      "g_norm_D: 7853.126557052459\n",
      "loss:  tensor(510.9872, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 251.82657116646647\n",
      "B norm: 1722.8004622114481\n",
      "a: 7853.126557052459\n",
      "b: 61671596.72108266\n",
      "c: 7853.126557052465\n",
      "plms: 968629708052.3278 -547094956740.56537 -139378874.78439942 -1021.9743358734831\n",
      "lmds:  [ 5.65067966e-01 -2.47093773e-04 -7.55648315e-06]\n",
      "lmd_max: tensor([0.5651], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5651], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5651], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(251.8266, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5651], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(142.2254, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 1.8883832811284877e-13\n",
      "g_norm_l2: 0.004032026598679576\n",
      "yk norm: 0.04506552021490846\n",
      "D_hat_inv: 252.04376673872923\n",
      "g_norm_D: 7.7895762805099e-05\n",
      "loss:  tensor(9.5257e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.004032026598679576\n",
      "D_inv norm: 252.04376673872923\n",
      "B norm: 0.17065949985741374\n",
      "a: 7.7895762805099e-05\n",
      "b: 6.369588275141304e-05\n",
      "c: 0.8177066435665427\n",
      "plms: 0.000104169092987332 7.53132863737063e-05 -0.00028316845115888167 -0.00019051344006898671\n",
      "lmds:  [ 1.63106918 -1.69095481 -0.66310508]\n",
      "lmd_max: tensor([1.6311], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1.6311], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1.6311], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.0438, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.1707, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1.6311], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(410.9325, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 62.0094043051659\n",
      "yk norm: 306.8628868436131\n",
      "D_hat_inv: 252.30953046899438\n",
      "g_norm_D: 15201.921448542014\n",
      "loss:  tensor(658.9519, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.0094043051659\n",
      "D_inv norm: 252.30953046899435\n",
      "B norm: 3845.166222281512\n",
      "a: 15201.921448542014\n",
      "b: 231098415.72764075\n",
      "c: 15201.921448541952\n",
      "plms: 7026279925548.175 -3816781050875.3823 -502235767.8987621 -1317.903806502725\n",
      "lmds:  [ 5.43346612e-01 -1.28876389e-04 -2.67860041e-06]\n",
      "lmd_max: tensor([0.5433], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5433], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5433], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(252.3095, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5433], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(137.0233, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.319629746506536\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 7.651634934436461e-14\n",
      "g_norm_l2: 1.7442630113266127e-69\n",
      "yk norm: 7.83140895610388e-68\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 1464.9245063607752\n",
      "D_hat_inv: 253.81353478611535\n",
      "g_norm_D: 8530.146103107361\n",
      "loss:  tensor(452.6419, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 253.81353478611535\n",
      "B norm: 1936.9524422572565\n",
      "a: 8530.146103107361\n",
      "b: 72763392.54035768\n",
      "c: 8530.146103107358\n",
      "plms: 1241364738654.0059 -686262831833.9614 -160954129.90910238 -905.2837392179694\n",
      "lmds:  [ 5.53063766e-01 -2.28673866e-04 -5.76625144e-06]\n",
      "lmd_max: tensor([0.5531], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5531], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5531], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(253.8135, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5531], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.3052, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.3644980307045\n",
      "yk norm: 1.931621365460176e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.040524980339036e-97\n",
      "yk norm: 9.562036332605994e-97\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 7.716764521849043e-118\n",
      "yk norm: 2.2210230966609723e-116\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 3.4808974842073716e-13\n",
      "g_norm_l2: 1.1139375527956578e-14\n",
      "yk norm: 1.2162959819387517e-12\n",
      "g_norm_l2: 1.4736845873678178e-81\n",
      "yk norm: 8.447991039408318e-80\n",
      "g_norm_l2: 4.916954652174585e-57\n",
      "yk norm: 5.512662704661834e-55\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 4089.469238432972\n",
      "D_hat_inv: 256.742991247598\n",
      "g_norm_D: 9376.853700073956\n",
      "loss:  tensor(382.1507, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 256.742991247598\n",
      "B norm: 2118.7572974701147\n",
      "a: 9376.853700073956\n",
      "b: 87925385.31259063\n",
      "c: 9376.853700073956\n",
      "plms: 1648926949197.5876 -891313272459.5913 -190165502.65863636 -764.301449042668\n",
      "lmds:  [ 5.40754666e-01 -2.09173875e-04 -4.09784523e-06]\n",
      "lmd_max: tensor([0.5408], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5408], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5408], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(256.7430, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5408], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(138.7648, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.44713715554026e-26\n",
      "yk norm: 2.1512714367667494e-25\n",
      "g_norm_l2: 7.658041013298112e-161\n",
      "yk norm: 2.592245636995501e-159\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.72755888056949e-125\n",
      "yk norm: 9.508616360908357e-124\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 1383.066029143705\n",
      "D_hat_inv: 257.56825228269145\n",
      "g_norm_D: 9785.662733744972\n",
      "loss:  tensor(433.7818, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 257.56825228269145\n",
      "B norm: 2133.4178598687618\n",
      "a: 9785.662733744972\n",
      "b: 95759195.13860515\n",
      "c: 9785.662733744975\n",
      "plms: 1874134374562.523 -1019761338847.6786 -208478187.77067572 -867.5635611465079\n",
      "lmds:  [ 5.44328281e-01 -2.00113269e-04 -4.24975404e-06]\n",
      "lmd_max: tensor([0.5443], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5443], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5443], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(257.5683, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5443], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.1306, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 6.276032086357793e-29\n",
      "yk norm: 8.839193817357262e-28\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 1.11091327387983e-12\n",
      "g_norm_l2: 0.0003948830809617744\n",
      "yk norm: 0.028255737895665833\n",
      "D_hat_inv: 257.87515573068805\n",
      "g_norm_D: 7.748401167040299e-07\n",
      "loss:  tensor(8.6006e-06, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0003948830809617744\n",
      "D_inv norm: 257.87515573068805\n",
      "B norm: 0.01813034193128364\n",
      "a: 7.748401167040299e-07\n",
      "b: 6.980606182353887e-08\n",
      "c: 0.09009092368690962\n",
      "plms: 1.2577785177256275e-08 1.3332383143225429e-07 -1.6892790288799989e-06 -1.7201217457887614e-05\n",
      "lmds:  [ 11.47901198 -12.6923642   -9.38659281]\n",
      "lmd_max: tensor([11.4790], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([11.4790], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([11.4790], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(257.8752, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0181, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([11.4790], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(2959.0806, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 2.1966669146953302e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 49.13188207922238\n",
      "yk norm: 7.456663413786034e-13\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.260931880922308e-28\n",
      "yk norm: 2.339718484845096e-26\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 2665.874328318285\n",
      "D_hat_inv: 258.397567853741\n",
      "g_norm_D: 10385.447913125354\n",
      "loss:  tensor(391.1972, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 258.397567853741\n",
      "B norm: 2249.278688599112\n",
      "a: 10385.447913125354\n",
      "b: 107857528.35623975\n",
      "c: 10385.447913125354\n",
      "plms: 2240297485564.338 -1204104440785.4648 -231945318.7663387 -782.3944179214004\n",
      "lmds:  [ 5.37667807e-01 -1.89126706e-04 -3.43441806e-06]\n",
      "lmd_max: tensor([0.5377], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5377], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5377], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.3976, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5377], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(138.8629, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.089121887535236e-57\n",
      "yk norm: 1.0849972489460197e-56\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 2.881606455333718e-13\n",
      "g_norm_l2: 6.115713218685201e-64\n",
      "yk norm: 1.8768429229695275e-62\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0077608701448766e-67\n",
      "yk norm: 9.314021645489459e-67\n",
      "g_norm_l2: 1.045094883843196e-13\n",
      "yk norm: 5.126824208052813e-12\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 2.9872554088367356e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.0703768464426233e-94\n",
      "yk norm: 4.50544171187535e-93\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 7105.492324013595\n",
      "D_hat_inv: 259.2675176289704\n",
      "g_norm_D: 11595.933522305888\n",
      "loss:  tensor(520.6308, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 259.2675176289704\n",
      "B norm: 2584.798857508484\n",
      "a: 11595.933522305888\n",
      "b: 134465674.25373754\n",
      "c: 11595.933522305893\n",
      "plms: 3118510039356.7583 -1698731100626.4355 -293056957.3171057 -1041.2616039158338\n",
      "lmds:  [ 5.44897692e-01 -1.68832274e-04 -3.62946215e-06]\n",
      "lmd_max: tensor([0.5449], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5449], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5449], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.2675, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5449], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.2035, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.010196586953459798\n",
      "yk norm: 0.06682068648720917\n",
      "D_hat_inv: 259.3754352694599\n",
      "g_norm_D: 0.0005061217240104632\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.010196586953459798\n",
      "D_inv norm: 259.37543526945996\n",
      "B norm: 0.45584661726178616\n",
      "a: 0.0005061217240104632\n",
      "b: 0.0011231015833844946\n",
      "c: 2.2190345328098906\n",
      "plms: 0.004984402394767321 -0.0002457419103590909 -0.003258215775430011 -0.00045611188711847106\n",
      "lmds:  [ 0.89447488 -0.6987671  -0.1464056 ]\n",
      "lmd_max: tensor([0.8945], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.8945], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.8945], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.3754, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.4558, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.8945], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(231.9050, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.3659462664074056e-14\n",
      "yk norm: 1.6422624553168234e-13\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 4.5428028971234107e-13\n",
      "g_norm_l2: 1.3566607098390228e-33\n",
      "yk norm: 1.1285817077713212e-31\n",
      "g_norm_l2: 1.5864256655175957e-33\n",
      "yk norm: 2.8144930597325825e-32\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "Loss: 107.03613393370021 | GradNorm^2: 58.95529093739282\n",
      "g_norm_l2: 6.7227549816862085e-118\n",
      "yk norm: 1.3418379856604648e-116\n",
      "g_norm_l2: 8.531150290356289e-57\n",
      "yk norm: 3.713474346940101e-55\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 1057.5850734881444\n",
      "D_hat_inv: 260.06814951734134\n",
      "g_norm_D: 7947.404348607629\n",
      "loss:  tensor(509.1511, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 260.06814951734134\n",
      "B norm: 1722.8004622114481\n",
      "a: 7947.404348607629\n",
      "b: 63161235.880267486\n",
      "c: 7947.404348607633\n",
      "plms: 1003935761396.5406 -566032464081.8976 -142492296.34043702 -1018.3022455271811\n",
      "lmds:  [ 5.64065059e-01 -2.44267974e-04 -7.36164799e-06]\n",
      "lmd_max: tensor([0.5641], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5641], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5641], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.0681, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5641], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(146.6208, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 3.240539753974096e-13\n",
      "g_norm_l2: 7.92092079277607e-14\n",
      "yk norm: 2.681934927407642e-12\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 3324.946458264317\n",
      "D_hat_inv: 259.8308038314518\n",
      "g_norm_D: 15353.27115214044\n",
      "loss:  tensor(657.3140, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 259.8308038314519\n",
      "B norm: 3845.1662222815285\n",
      "a: 15353.27115214044\n",
      "b: 235722935.0711479\n",
      "c: 15353.271152140442\n",
      "plms: 7238236277851.458 -3928063237480.354 -511782846.4506532 -1314.6280831832341\n",
      "lmds:  [ 5.42812631e-01 -1.27636735e-04 -2.62146773e-06]\n",
      "lmd_max: tensor([0.5428], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5428], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5428], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.8308, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5428], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.9723, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 1447.2110403329793\n",
      "D_hat_inv: 260.2523945456848\n",
      "g_norm_D: 9809.706851426394\n",
      "loss:  tensor(432.1009, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 260.2523945456848\n",
      "B norm: 2133.4178598687613\n",
      "a: 9809.706851426394\n",
      "b: 96230348.51092193\n",
      "c: 9809.706851426394\n",
      "plms: 1887983018205.481 -1026769032268.2595 -209396211.09359688 -864.2018432482762\n",
      "lmds:  [ 5.44048284e-01 -1.99647946e-04 -4.21419677e-06]\n",
      "lmd_max: tensor([0.5440], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5440], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5440], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.2524, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5440], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.5196, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.379133561794613e-64\n",
      "yk norm: 5.142240766497578e-63\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 3.7765006849721307e-13\n",
      "g_norm_l2: 0.00027452339652944154\n",
      "yk norm: 0.00399379485488249\n",
      "D_hat_inv: 260.88312464748725\n",
      "g_norm_D: 3.8651738880307924e-07\n",
      "loss:  tensor(5.9792e-06, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.00027452339652944154\n",
      "D_inv norm: 260.88312464748725\n",
      "B norm: 0.01260427791092614\n",
      "a: 3.8651738880307924e-07\n",
      "b: 2.498603345163075e-08\n",
      "c: 0.06464400871848097\n",
      "plms: 3.230394728574951e-09 4.8357018934724845e-08 -8.23002222402785e-07 -1.1958300264442604e-05\n",
      "lmds:  [ 15.84729042 -17.36393978 -13.45273456]\n",
      "lmd_max: tensor([15.8473], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([15.8473], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([15.8473], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.8831, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0126, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([15.8473], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(4132.7608, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 5.673647688315146e-28\n",
      "yk norm: 2.0537726306850866e-26\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 8.995229466257059e-70\n",
      "yk norm: 1.9481431498114355e-68\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 839.5501988027802\n",
      "D_hat_inv: 261.487815800461\n",
      "g_norm_D: 9766.50451621667\n",
      "loss:  tensor(379.4423, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 261.487815800461\n",
      "B norm: 2118.757297470112\n",
      "a: 9766.50451621667\n",
      "b: 95384610.46528049\n",
      "c: 9766.504516216657\n",
      "plms: 1863148457773.4568 -1003578596884.799 -205572986.53767917 -758.8845421377463\n",
      "lmds:  [ 5.38851371e-01 -2.01002913e-04 -3.76059792e-06]\n",
      "lmd_max: tensor([0.5389], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5389], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5389], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.4878, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5389], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.8322, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.048821189906099e-68\n",
      "yk norm: 1.4908919074531702e-66\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.637054250144644e-97\n",
      "yk norm: 9.819745794360074e-96\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 2432.945347498227\n",
      "D_hat_inv: 260.02629764888866\n",
      "g_norm_D: 8795.058957456276\n",
      "loss:  tensor(448.7359, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 260.02629764888866\n",
      "B norm: 1936.952442257257\n",
      "a: 8795.058957456276\n",
      "b: 77353062.06513189\n",
      "c: 8795.058957456276\n",
      "plms: 1360649482805.219 -749437521950.9 -170475169.01556194 -897.4718122741799\n",
      "lmds:  [ 5.51021343e-01 -2.21986766e-04 -5.39236212e-06]\n",
      "lmd_max: tensor([0.5510], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5510], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5510], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.0263, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5510], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.2091, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.1828219287007756e-33\n",
      "yk norm: 6.389946187948889e-32\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.006304956216397845\n",
      "yk norm: 0.1892733976856301\n",
      "D_hat_inv: 260.55087161986967\n",
      "g_norm_D: 0.00019882056005004708\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.006304956216397845\n",
      "D_inv norm: 260.5508716198696\n",
      "B norm: 0.2818926730610841\n",
      "a: 0.00019882056005004708\n",
      "b: 0.000280312344237403\n",
      "c: 1.4098760418280825\n",
      "plms: 0.0007904113167379612 0.000165458556005139 -0.0009582097385401722 -0.0002820198891862681\n",
      "lmds:  [ 1.13530399 -1.0434425  -0.30119371]\n",
      "lmd_max: tensor([1.1353], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1.1353], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1.1353], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.5509, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.2819, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1.1353], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(295.6804, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 3.0635740617757993e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.012010345389400602\n",
      "yk norm: 0.015257521805347117\n",
      "D_hat_inv: 260.970575221279\n",
      "g_norm_D: 0.0007009016925172579\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.012010345389400602\n",
      "D_inv norm: 260.970575221279\n",
      "B norm: 0.5082538839449571\n",
      "a: 0.0007009016925172579\n",
      "b: 0.0017309476351962554\n",
      "c: 2.4696011632952866\n",
      "plms: 0.008549500586967795 -0.000812363852840471 -0.004863300882492501 -0.0005675428564736488\n",
      "lmds:  [ 0.85306204 -0.63561437 -0.1224288 ]\n",
      "lmd_max: tensor([0.8531], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.8531], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.8531], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.9706, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.5083, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.8531], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(222.5286, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.28069340309695e-34\n",
      "yk norm: 2.877434979518376e-33\n",
      "g_norm_l2: 2.5638679957468268e-81\n",
      "yk norm: 1.9783538854719082e-79\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 2.085641173369495e-13\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 1.4551194922301709e-13\n",
      "g_norm_l2: 54.0229356749543\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.418820063919366e-14\n",
      "yk norm: 4.1951866685444353e-13\n",
      "g_norm_l2: 2.220646124699179e-160\n",
      "yk norm: 1.2007639224901438e-158\n",
      "g_norm_l2: 1.0807527558613037e-124\n",
      "yk norm: 1.367127216469834e-122\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.0761992335889915e-94\n",
      "yk norm: 4.42173686361991e-93\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 3629.5559770093046\n",
      "D_hat_inv: 262.32005909163075\n",
      "g_norm_D: 11800.399725967134\n",
      "loss:  tensor(517.7815, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 262.32005909163075\n",
      "B norm: 2584.798857508484\n",
      "a: 11800.399725967134\n",
      "b: 139249433.69260526\n",
      "c: 11800.399725967138\n",
      "plms: 3286397958374.596 -1786843550820.2866 -302915382.6354614 -1035.5630579158085\n",
      "lmds:  [ 5.43878292e-01 -1.65983124e-04 -3.49052486e-06]\n",
      "lmd_max: tensor([0.5439], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5439], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5439], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(262.3201, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5439], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(142.5997, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.6055370091792456e-57\n",
      "yk norm: 2.52653638544706e-56\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 55.92405513454919\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 1.696308276413056e-13\n",
      "g_norm_l2: 1.3960938161461705e-14\n",
      "yk norm: 5.876332143686761e-13\n",
      "g_norm_l2: 8.041425948657065e-27\n",
      "yk norm: 5.075405695469098e-25\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 1931.065085364935\n",
      "D_hat_inv: 256.3175611296148\n",
      "g_norm_D: 9734.232809402261\n",
      "loss:  tensor(387.8854, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 256.3175611296148\n",
      "B norm: 2249.278688599112\n",
      "a: 9734.232809402261\n",
      "b: 94755288.3876434\n",
      "c: 9734.232809402258\n",
      "plms: 1844740074174.7424 -995499396199.54 -204594174.30470318 -775.7707407843781\n",
      "lmds:  [ 5.39847536e-01 -2.01577948e-04 -3.86441774e-06]\n",
      "lmd_max: tensor([0.5398], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5398], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5398], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(256.3176, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5398], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(138.3022, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.3518893717293891e-28\n",
      "yk norm: 4.799954903689413e-27\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "Loss: 106.44836514392244 | GradNorm^2: 58.95497374890996\n",
      "g_norm_l2: 2.0890384988591596e-160\n",
      "yk norm: 1.3417153082382726e-158\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0048744031400668325\n",
      "yk norm: 0.013966159315819137\n",
      "D_hat_inv: 257.0473606478431\n",
      "g_norm_D: 0.00011575588166307444\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.0048744031400668325\n",
      "D_inv norm: 257.0473606478431\n",
      "B norm: 0.21794005360407664\n",
      "a: 0.00011575588166307444\n",
      "b: 0.0001229080413662372\n",
      "c: 1.06178657706552\n",
      "plms: 0.00026100421707216863 0.00011532737264666415 -0.0004773026085004106 -0.00021802794417202106\n",
      "lmds:  [ 1.35789837 -1.34102504 -0.45873353]\n",
      "lmd_max: tensor([1.3579], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1.3579], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1.3579], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(257.0474, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.2179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1.3579], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(348.9037, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 1.9046833064351742e-13\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.762013296648666e-70\n",
      "yk norm: 1.9932763916651194e-68\n",
      "g_norm_l2: 0.009696844874255636\n",
      "yk norm: 0.0941237212433615\n",
      "D_hat_inv: 257.57204948233584\n",
      "g_norm_D: 0.000457557916818183\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.009696844874255636\n",
      "D_inv norm: 257.57204948233584\n",
      "B norm: 0.4103735858965534\n",
      "a: 0.000457557916818183\n",
      "b: 0.0009137147827134107\n",
      "c: 1.9969379812446517\n",
      "plms: 0.0036492635072502277 3.0071390748574994e-06 -0.0027423357508166058 -0.00045820702400720874\n",
      "lmds:  [ 0.9403351  -0.767087   -0.17407213]\n",
      "lmd_max: tensor([0.9403], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.9403], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.9403], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(257.5720, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.4104, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.9403], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(242.0979, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 7.283909996682133e-34\n",
      "yk norm: 5.876583183301333e-33\n",
      "g_norm_l2: 1.1484121012569794e-33\n",
      "yk norm: 7.695315791080703e-32\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 9.581641356641456e-14\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 663.9191834084226\n",
      "D_hat_inv: 257.1152754150042\n",
      "g_norm_D: 9968.325025066732\n",
      "loss:  tensor(429.9267, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 257.11527541500413\n",
      "B norm: 2133.417859868761\n",
      "a: 9968.325025066732\n",
      "b: 99367503.80537163\n",
      "c: 9968.325025066728\n",
      "plms: 1981055149722.9985 -1075571583977.7786 -215857665.91353554 -859.8533309124147\n",
      "lmds:  [ 5.43129261e-01 -1.96552664e-04 -4.06579690e-06]\n",
      "lmd_max: tensor([0.5431], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5431], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5431], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(257.1153, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5431], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.5743, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 1734.2866867442244\n",
      "D_hat_inv: 257.26597982919054\n",
      "g_norm_D: 7817.490766576297\n",
      "loss:  tensor(507.3958, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 257.26597982919054\n",
      "B norm: 1722.800462211447\n",
      "a: 7817.490766576297\n",
      "b: 61113161.88550567\n",
      "c: 7817.490766576298\n",
      "plms: 955503157512.446 -539524246228.3336 -138076935.8939345 -1014.7915474548745\n",
      "lmds:  [ 5.64905171e-01 -2.48237346e-04 -7.57359443e-06]\n",
      "lmd_max: tensor([0.5649], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5649], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5649], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(257.2660, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5649], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(145.2570, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 4.4912358476616584e-57\n",
      "yk norm: 2.2195329661388635e-55\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.02996086757096\n",
      "yk norm: 4945.492279127324\n",
      "D_hat_inv: 257.7205084633102\n",
      "g_norm_D: 9347.11118895567\n",
      "loss:  tensor(376.6960, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757096\n",
      "D_inv norm: 257.7205084633102\n",
      "B norm: 2118.7572974701143\n",
      "a: 9347.11118895567\n",
      "b: 87368487.5787003\n",
      "c: 9347.11118895567\n",
      "plms: 1633285935618.008 -882116214254.754 -188802358.6924028 -753.3920091814862\n",
      "lmds:  [ 5.40300775e-01 -2.09882576e-04 -4.06768027e-06]\n",
      "lmd_max: tensor([0.5403], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5403], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5403], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(257.7205, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5403], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.1783, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 2720.532727505862\n",
      "D_hat_inv: 258.1719186798361\n",
      "g_norm_D: 11476.98773799133\n",
      "loss:  tensor(514.8231, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 258.1719186798361\n",
      "B norm: 2584.7988575084823\n",
      "a: 11476.98773799133\n",
      "b: 131721247.53800328\n",
      "c: 11476.987737991327\n",
      "plms: 3023526285653.169 -1646862544413.4417 -287054015.5241735 -1029.646234848176\n",
      "lmds:  [ 5.44856977e-01 -1.70585009e-04 -3.66396157e-06]\n",
      "lmd_max: tensor([0.5449], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5449], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5449], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.1719, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5449], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.5965, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 39.10618899129445\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.7734276227698076e-27\n",
      "yk norm: 7.724787973836848e-26\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 1.457603476823171e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.2439727138629775e-94\n",
      "yk norm: 4.023198415724208e-93\n",
      "g_norm_l2: 1.7893127020214691e-124\n",
      "yk norm: 7.055619619156439e-123\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 3088.252523631563\n",
      "D_hat_inv: 259.20764976509025\n",
      "g_norm_D: 15697.527584998606\n",
      "loss:  tensor(656.0483, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 259.20764976509025\n",
      "B norm: 3845.1662222815294\n",
      "a: 15697.527584998606\n",
      "b: 246412372.28179222\n",
      "c: 15697.52758499861\n",
      "plms: 7736130022356.761 -4190396200108.3076 -533986694.97869515 -1312.096610349239\n",
      "lmds:  [ 5.41793091e-01 -1.24895217e-04 -2.50647160e-06]\n",
      "lmd_max: tensor([0.5418], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5418], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5418], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(259.2076, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5418], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.3694, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 1.4851663461465408e-13\n",
      "g_norm_l2: 1.5539619855282667e-14\n",
      "yk norm: 2.44956876886026e-13\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0788381028706664e-27\n",
      "yk norm: 6.002553912060585e-26\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.991684840391617e-28\n",
      "yk norm: 1.5080851310455902e-27\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 1.5412197427242945e-13\n",
      "g_norm_l2: 39.44225841247945\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 8.714376760573767e-58\n",
      "yk norm: 5.25434204809466e-57\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 886.5706039730552\n",
      "D_hat_inv: 260.5966032899128\n",
      "g_norm_D: 9996.05515421989\n",
      "loss:  tensor(385.5982, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 260.5966032899128\n",
      "B norm: 2249.278688599117\n",
      "a: 9996.05515421989\n",
      "b: 99921118.64620623\n",
      "c: 9996.05515421991\n",
      "plms: 1997634026117.6577 -1075476144792.8699 -215240090.52604347 -771.1964923198078\n",
      "lmds:  [ 5.38575025e-01 -1.96412174e-04 -3.64950957e-06]\n",
      "lmd_max: tensor([0.5386], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5386], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5386], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.5966, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5386], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.2830, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.702435139859082e-97\n",
      "yk norm: 2.581395587994437e-96\n",
      "g_norm_l2: 2.8453274366917467e-81\n",
      "yk norm: 1.176053258424905e-79\n",
      "g_norm_l2: 46.96174334896987\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.230130151055376e-64\n",
      "yk norm: 1.9711838977834784e-62\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 8.417992323350626e-118\n",
      "yk norm: 3.5202256642649295e-116\n",
      "g_norm_l2: 0.00020449495261835646\n",
      "yk norm: 0.004150602352733625\n",
      "D_hat_inv: 261.458146287634\n",
      "g_norm_D: 2.1064237282365964e-07\n",
      "loss:  tensor(4.4539e-06, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.00020449495261835646\n",
      "D_inv norm: 261.45814628763395\n",
      "B norm: 0.009389054550799424\n",
      "a: 2.1064237282365964e-07\n",
      "b: 9.962037052543406e-09\n",
      "c: 0.047293604411127566\n",
      "plms: 9.422812789839663e-10 1.945297783530176e-08 -4.412069434011537e-07 -8.907838865683295e-06\n",
      "lmds:  [ 21.52166112 -23.37290498 -18.7933113 ]\n",
      "lmd_max: tensor([21.5217], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([21.5217], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([21.5217], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.4581, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0094, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([21.5217], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(5625.0421, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.9302168832332476e-15\n",
      "yk norm: 4.4120967444014856e-14\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 1443.897372697911\n",
      "D_hat_inv: 263.4304540293574\n",
      "g_norm_D: 9208.84650189883\n",
      "loss:  tensor(444.8534, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 263.4304540293574\n",
      "B norm: 1936.952442257256\n",
      "a: 9208.84650189883\n",
      "b: 84802853.8955343\n",
      "c: 9208.846501898826\n",
      "plms: 1561872928893.8562 -856046936869.9517 -185973638.55615845 -889.7068951423418\n",
      "lmds:  [ 5.48307165e-01 -2.12268551e-04 -4.89431237e-06]\n",
      "lmd_max: tensor([0.5483], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5483], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5483], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(263.4305, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5483], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(144.3669, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 2.742827770869827e-14\n",
      "g_norm_l2: 3.9550551614980205e-14\n",
      "yk norm: 7.136123263266116e-13\n",
      "g_norm_l2: 8.56521369700295e-68\n",
      "yk norm: 5.340785287165479e-67\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "Loss: 105.8549535144268 | GradNorm^2: 58.95437623785166\n",
      "g_norm_l2: 1.0151077776579938e-27\n",
      "yk norm: 4.8571796551624887e-26\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.00012875820131750114\n",
      "yk norm: 0.004519108368657169\n",
      "D_hat_inv: 264.16556026709384\n",
      "g_norm_D: 8.421032290716732e-08\n",
      "loss:  tensor(2.8044e-06, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.00012875820131750114\n",
      "D_inv norm: 264.16556026709384\n",
      "B norm: 0.005911734029289898\n",
      "a: 8.421032290716732e-08\n",
      "b: 2.5286909237278663e-09\n",
      "c: 0.03002827725189312\n",
      "plms: 1.518644642840922e-10 4.981456706757347e-09 -1.7347755534407467e-07 -5.608727008968148e-06\n",
      "lmds:  [ 33.67829783 -36.1180818  -30.36220647]\n",
      "lmd_max: tensor([33.6783], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([33.6783], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([33.6783], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(264.1656, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0059, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([33.6783], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(8893.6307, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.966562488677661e-64\n",
      "yk norm: 2.478928292442523e-62\n",
      "g_norm_l2: 47.426561003293415\n",
      "yk norm: 1380.4200875363704\n",
      "D_hat_inv: 261.7801251171369\n",
      "g_norm_D: 10041.337712178514\n",
      "loss:  tensor(384.2031, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.426561003293415\n",
      "D_inv norm: 261.7801251171369\n",
      "B norm: 2249.278688599112\n",
      "a: 10041.337712178514\n",
      "b: 100828463.05001846\n",
      "c: 10041.337712178516\n",
      "plms: 2024905296970.2966 -1089526553267.0278 -217068496.22922087 -768.4062246951529\n",
      "lmds:  [ 5.38262127e-01 -1.95554378e-04 -3.60516206e-06]\n",
      "lmd_max: tensor([0.5383], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5383], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5383], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.7801, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5383], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.8390, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 367.6916143144701\n",
      "D_hat_inv: 260.99271612931614\n",
      "g_norm_D: 9916.983889670804\n",
      "loss:  tensor(427.0109, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 260.99271612931614\n",
      "B norm: 2133.41785986876\n",
      "a: 9916.983889670804\n",
      "b: 98346569.46799022\n",
      "c: 9916.983889670797\n",
      "plms: 1950602690036.8975 -1058898067966.4822 -213611944.81279874 -854.0217486004173\n",
      "lmds:  [ 5.43058525e-01 -1.97576442e-04 -4.08054636e-06]\n",
      "lmd_max: tensor([0.5431], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5431], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5431], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.9927, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5431], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.6641, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 601.3017581375902\n",
      "D_hat_inv: 258.80431521274636\n",
      "g_norm_D: 15919.778381420618\n",
      "loss:  tensor(654.9474, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 258.80431521274636\n",
      "B norm: 3845.166222281528\n",
      "a: 15919.778381420618\n",
      "b: 253439343.71354723\n",
      "c: 15919.778381420616\n",
      "plms: 8069396370104.716 -4365663327822.3945 -548553320.434338 -1309.8948856185234\n",
      "lmds:  [ 5.41140481e-01 -1.23188054e-04 -2.43509986e-06]\n",
      "lmd_max: tensor([0.5411], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5411], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5411], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(258.8043, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5411], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(139.9812, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.31962974650654\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.604920193316107e-14\n",
      "yk norm: 1.253806045024557e-12\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.247508204433416e-27\n",
      "yk norm: 7.871688727763512e-27\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.50663154498864\n",
      "yk norm: 1488.4472581684633\n",
      "D_hat_inv: 260.1686796173298\n",
      "g_norm_D: 7959.768570141121\n",
      "loss:  tensor(505.1196, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498864\n",
      "D_inv norm: 260.1686796173298\n",
      "B norm: 1722.8004622114463\n",
      "a: 7959.768570141121\n",
      "b: 63357915.69020643\n",
      "c: 7959.76857014112\n",
      "plms: 1008628691961.1119 -568067564836.8312 -142782452.42344454 -1010.2392072365752\n",
      "lmds:  [ 5.63459057e-01 -2.43952124e-04 -7.28661686e-06]\n",
      "lmd_max: tensor([0.5635], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5635], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5635], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.1687, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5635], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(146.5213, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.839923169625903e-81\n",
      "yk norm: 1.2483251965198491e-79\n",
      "g_norm_l2: 8.263731572511976e-160\n",
      "yk norm: 5.239317861953026e-158\n",
      "g_norm_l2: 1.30963529825347e-117\n",
      "yk norm: 4.576958909071724e-116\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.32795654829821e-95\n",
      "yk norm: 3.4761867808950062e-93\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 56.3644980307045\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.20669016745165e-28\n",
      "yk norm: 3.047148215473848e-27\n",
      "g_norm_l2: 4.627136129634657e-34\n",
      "yk norm: 2.3638009905093251e-32\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.031093106602748815\n",
      "yk norm: 0.19783248010460858\n",
      "D_hat_inv: 261.3433600655332\n",
      "g_norm_D: 0.004832432641076871\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.031093106602748815\n",
      "D_inv norm: 261.3433600655332\n",
      "B norm: 1.3152049700752642\n",
      "a: 0.004832432641076871\n",
      "b: 0.031768508673744034\n",
      "c: 6.574019967439145\n",
      "plms: 0.4176936207139138 -0.14528645204186952 -0.07319478165711207 -0.0014696205432507012\n",
      "lmds:  [ 0.63330349 -0.26446624 -0.02100706]\n",
      "lmd_max: tensor([0.6333], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.6333], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.6333], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.3434, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1.3152, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.6333], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(165.4316, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.0000679626282932e-124\n",
      "yk norm: 8.452271435370666e-123\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 7.05253973668347e-13\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 9.175796795612638e-16\n",
      "yk norm: 9.628905412542242e-16\n",
      "g_norm_l2: 3.958584337007352e-58\n",
      "yk norm: 2.0390563949063635e-57\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 2010.5310970770045\n",
      "D_hat_inv: 260.5902424930499\n",
      "g_norm_D: 9789.33090602342\n",
      "loss:  tensor(373.4203, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 260.5902424930499\n",
      "B norm: 2118.7572974701156\n",
      "a: 9789.33090602342\n",
      "b: 95830999.58762538\n",
      "c: 9789.330906023426\n",
      "plms: 1876242732036.5186 -1009308525818.2723 -206264560.57294488 -746.840626794477\n",
      "lmds:  [ 5.38145624e-01 -2.00598725e-04 -3.68732090e-06]\n",
      "lmd_max: tensor([0.5381], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5381], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5381], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.5902, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2118.7573, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5381], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.1661, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 2936.905213632364\n",
      "D_hat_inv: 260.90903641789475\n",
      "g_norm_D: 11788.296850149862\n",
      "loss:  tensor(510.3666, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 260.9090364178947\n",
      "B norm: 2584.798857508483\n",
      "a: 11788.296850149862\n",
      "b: 138963942.62725312\n",
      "c: 11788.296850149862\n",
      "plms: 3276296414314.509 -1779437450684.659 -301969718.8046149 -1020.7331241197513\n",
      "lmds:  [ 5.43294330e-01 -1.66197201e-04 -3.45040554e-06]\n",
      "lmd_max: tensor([0.5433], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5433], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5433], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.9090, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5433], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(141.6813, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 4.26070666835407e-70\n",
      "yk norm: 6.856459301081154e-69\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 1.5997646697686798e-13\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.007417134410562475\n",
      "yk norm: 0.19237215917993553\n",
      "D_hat_inv: 261.3537706257912\n",
      "g_norm_D: 0.0002773091690675403\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.007417134410562475\n",
      "D_inv norm: 261.3537706257912\n",
      "B norm: 0.331609572374341\n",
      "a: 0.0002773091690675403\n",
      "b: 0.0004635357336002363\n",
      "c: 1.6715485288816372\n",
      "plms: 0.0015496449471670906 0.00015232588548846036 -0.0014815978045707476 -0.0003317716046950302\n",
      "lmds:  [ 1.03076325 -0.8976802  -0.23138033]\n",
      "lmd_max: tensor([1.0308], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1.0308], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1.0308], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.3538, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.3316, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1.0308], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(269.2812, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.4868696735111656e-14\n",
      "yk norm: 6.373135469372518e-13\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 2680.054666173918\n",
      "D_hat_inv: 261.63485900937775\n",
      "g_norm_D: 8924.16419107121\n",
      "loss:  tensor(441.8405, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663913\n",
      "D_inv norm: 261.63485900937775\n",
      "B norm: 1936.952442257257\n",
      "a: 8924.16419107121\n",
      "b: 79640706.50919765\n",
      "c: 8924.16419107121\n",
      "plms: 1421453482361.987 -780785157559.1447 -175035793.3710142 -883.6810004449183\n",
      "lmds:  [ 5.49510554e-01 -2.18922142e-04 -5.16769809e-06]\n",
      "lmd_max: tensor([0.5495], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5495], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5495], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.6349, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5495], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.7002, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 49.13188207922238\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.840599293114477e-34\n",
      "yk norm: 4.222073614598088e-32\n",
      "g_norm_l2: 8.812084377260305e-68\n",
      "yk norm: 1.707397852704889e-66\n",
      "g_norm_l2: 42.93269227210108\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 1.0499772436734391e-12\n",
      "g_norm_l2: 41.50305552443547\n",
      "yk norm: 1.1538499463218506e-13\n",
      "g_norm_l2: 1.2926728277345603e-97\n",
      "yk norm: 4.497271312943793e-96\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.667377565705405e-57\n",
      "yk norm: 2.5286584851289533e-57\n",
      "Loss: 105.27595097670212 | GradNorm^2: 58.953600646342025\n",
      "g_norm_l2: 56.36449803070452\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.667377565705405e-57\n",
      "yk norm: 2.954327310434509e-57\n",
      "g_norm_l2: 1.2926728277345603e-97\n",
      "yk norm: 5.9962155676076695e-96\n",
      "g_norm_l2: 44.01082187663912\n",
      "yk norm: 2214.5465311152075\n",
      "D_hat_inv: 260.6639676273373\n",
      "g_norm_D: 8753.145035458998\n",
      "loss:  tensor(440.8407, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 44.01082187663912\n",
      "D_inv norm: 260.66396762733734\n",
      "B norm: 1936.9524422572572\n",
      "a: 8753.145035458998\n",
      "b: 76617548.01178056\n",
      "c: 8753.145035459003\n",
      "plms: 1341289020016.7173 -737890307440.0597 -168652560.21554977 -881.6814081985656\n",
      "lmds:  [ 5.50363671e-01 -2.23114589e-04 -5.35317675e-06]\n",
      "lmd_max: tensor([0.5504], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5504], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5504], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.6640, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1936.9524, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5504], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.3905, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.003379809045112e-05\n",
      "yk norm: 0.0037567129795453903\n",
      "D_hat_inv: 260.77457814012536\n",
      "g_norm_D: 4.08564017793137e-08\n",
      "loss:  tensor(1.9609e-06, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 9.003379809045112e-05\n",
      "D_inv norm: 260.77457814012536\n",
      "B norm: 0.004133766326551781\n",
      "a: 4.08564017793137e-08\n",
      "b: 8.51245858436262e-10\n",
      "c: 0.02083506675488154\n",
      "plms: 3.547152857067191e-11 1.6847576217604176e-09 -8.341513504820141e-08 -3.9218844079697184e-06\n",
      "lmds:  [ 48.37193281 -51.39174388 -44.47624251]\n",
      "lmd_max: tensor([48.3719], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([48.3719], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([48.3719], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.7746, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.0041, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([48.3719], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(12609.8702, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 49.131882079222386\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.00474206355915331\n",
      "yk norm: 0.0018651522227332113\n",
      "D_hat_inv: 260.9955478193844\n",
      "g_norm_D: 0.00011213447358926605\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.00474206355915331\n",
      "D_inv norm: 260.9955478193844\n",
      "B norm: 0.21202362947256662\n",
      "a: 0.00011213447358926605\n",
      "b: 0.0001185571690537222\n",
      "c: 1.0572767255142397\n",
      "plms: 0.0002506954709667151 0.00011177917587508991 -0.00046135950106619824 -0.00021210819235576052\n",
      "lmds:  [ 1.3617778  -1.34609232 -0.4615618 ]\n",
      "lmd_max: tensor([1.3618], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([1.3618], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([1.3618], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(260.9955, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.2120, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([1.3618], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(355.2799, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.583294434507857e-28\n",
      "yk norm: 8.96355599397952e-28\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.10618899129446\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.029720386087809577\n",
      "yk norm: 0.1583855976166597\n",
      "D_hat_inv: 261.5499745511135\n",
      "g_norm_D: 0.004435416730920971\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.029720386087809577\n",
      "D_inv norm: 261.5499745511135\n",
      "B norm: 1.257181166375465\n",
      "a: 0.004435416730920971\n",
      "b: 0.0279999872254984\n",
      "c: 6.312819949994751\n",
      "plms: 0.35351775591344897 -0.12073923979415443 -0.06486457814176053 -0.001404715902963493\n",
      "lmds:  [ 0.63860082 -0.27438736 -0.0226769 ]\n",
      "lmd_max: tensor([0.6386], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.6386], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.6386], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.5500, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1.2572, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.6386], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(166.9491, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 1.4928841053303645e-27\n",
      "yk norm: 1.4433804961905414e-25\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 37.44860154946612\n",
      "yk norm: 3.728590085659209e-15\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 1706.3132379094584\n",
      "D_hat_inv: 261.25300804504906\n",
      "g_norm_D: 10173.011808038922\n",
      "loss:  tensor(381.2943, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 47.42656100329342\n",
      "D_inv norm: 261.25300804504906\n",
      "B norm: 2249.278688599114\n",
      "a: 10173.011808038922\n",
      "b: 103490169.24649943\n",
      "c: 10173.011808038931\n",
      "plms: 2105613427521.1724 -1131313170551.394 -222475636.9917708 -762.5885438433888\n",
      "lmds:  [ 5.37480946e-01 -1.93092229e-04 -3.48966527e-06]\n",
      "lmd_max: tensor([0.5375], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5375], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5375], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(261.2530, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2249.2787, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5375], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(140.3510, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.4385655758286834e-14\n",
      "yk norm: 1.8035254081928724e-13\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 1.4478901931224883e-13\n",
      "g_norm_l2: 1.6003494093222514e-16\n",
      "yk norm: 1.0862175715021474e-14\n",
      "g_norm_l2: 37.319629746506536\n",
      "yk norm: 1.922166629250557e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.097748326822897e-117\n",
      "yk norm: 1.9046942900682484e-116\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 3.866771770787698e-13\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 2568.181448237202\n",
      "D_hat_inv: 264.26183422212165\n",
      "g_norm_D: 11757.554266180323\n",
      "loss:  tensor(507.6161, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 50.84091715841172\n",
      "D_inv norm: 264.26183422212165\n",
      "B norm: 2584.7988575084855\n",
      "a: 11757.554266180323\n",
      "b: 138240082.3221752\n",
      "c: 11757.55426618033\n",
      "plms: 3250730539328.4224 -1765158093546.092 -300329945.1266984 -1015.2322094549025\n",
      "lmds:  [ 5.43173601e-01 -1.66640788e-04 -3.45036036e-06]\n",
      "lmd_max: tensor([0.5432], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5432], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5432], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(264.2618, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2584.7989, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5432], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.4696, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 3478.919268245826\n",
      "D_hat_inv: 263.41680262264447\n",
      "g_norm_D: 9567.06487812208\n",
      "loss:  tensor(423.9928, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.18893655269367\n",
      "D_inv norm: 263.41680262264447\n",
      "B norm: 2133.4178598687613\n",
      "a: 9567.06487812208\n",
      "b: 91528730.38219708\n",
      "c: 9567.06487812208\n",
      "plms: 1751322603557.2458 -952910232812.1581 -199263793.26287276 -847.9856066064294\n",
      "lmds:  [ 5.44317942e-01 -2.04686187e-04 -4.34591413e-06]\n",
      "lmd_max: tensor([0.5443], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5443], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5443], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(263.4168, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2133.4179, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5443], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.3154, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 6.024469501294822e-34\n",
      "yk norm: 9.959832221037949e-33\n",
      "g_norm_l2: 4.060633180113196e-124\n",
      "yk norm: 1.895161504184091e-123\n",
      "g_norm_l2: 55.9240551345492\n",
      "yk norm: 2.49438606162699e-13\n",
      "g_norm_l2: 4.669372553457538e-95\n",
      "yk norm: 3.669911020594225e-93\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.613794074389339e-70\n",
      "yk norm: 2.3793004746269395e-68\n",
      "g_norm_l2: 42.93269227210107\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 3.0502410963891837e-13\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 1.6358680591739396e-13\n",
      "g_norm_l2: 1.8268872957692948e-159\n",
      "yk norm: 9.036207984875235e-158\n",
      "g_norm_l2: 41.50663154498866\n",
      "yk norm: 1024.1668782094962\n",
      "D_hat_inv: 264.19248188066695\n",
      "g_norm_D: 8101.724727885735\n",
      "loss:  tensor(503.3926, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498866\n",
      "D_inv norm: 264.19248188066695\n",
      "B norm: 1722.8004622114468\n",
      "a: 8101.724727885735\n",
      "b: 65637943.566435166\n",
      "c: 8101.724727885732\n",
      "plms: 1063561100959.512 -597601313197.4408 -147573077.85848325 -1006.7852662852642\n",
      "lmds:  [ 5.62133984e-01 -2.39814961e-04 -7.02195902e-06]\n",
      "lmd_max: tensor([0.5621], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5621], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5621], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(264.1925, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5621], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(148.4399, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 2.4876686054074183e-27\n",
      "yk norm: 1.065165269759884e-25\n",
      "g_norm_l2: 1.3690532798651813e-34\n",
      "yk norm: 3.822526654379096e-33\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 4402.99271593964\n",
      "D_hat_inv: 265.22596204843956\n",
      "g_norm_D: 16500.633097304315\n",
      "loss:  tensor(653.1225, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 265.22596204843956\n",
      "B norm: 3845.166222281529\n",
      "a: 16500.633097304315\n",
      "b: 272270892.61185455\n",
      "c: 16500.633097304315\n",
      "plms: 8985284204127.514 -4847205486494.548 -587616519.9945447 -1306.244911417148\n",
      "lmds:  [ 5.39581654e-01 -1.18935880e-04 -2.26528437e-06]\n",
      "lmd_max: tensor([0.5396], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5396], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5396], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(265.2260, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5396], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(143.0461, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 39.45462363796923\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.531020927433413e-58\n",
      "yk norm: 9.054196206084031e-57\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0194379423919882e-67\n",
      "yk norm: 4.8226729428615373e-67\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.085790407668695e-14\n",
      "yk norm: 2.252591479061143e-12\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.5705401665475107e-81\n",
      "yk norm: 1.6751861643058313e-79\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 7.4372473399482e-14\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 1.1781948317346278e-13\n",
      "g_norm_l2: 3.510844652333958e-64\n",
      "yk norm: 7.750513139909457e-63\n",
      "g_norm_l2: 46.02996086757097\n",
      "yk norm: 3.604105200906211\n",
      "D_hat_inv: 266.4851986548529\n",
      "g_norm_D: 9840.937300935151\n",
      "loss:  tensor(369.4603, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.02996086757097\n",
      "D_inv norm: 266.48519865485287\n",
      "B norm: 4.1686979585154\n",
      "a: 9840.937300935151\n",
      "b: 190542.62672863848\n",
      "c: 19.362243747913308\n",
      "plms: 7378665.566175119 -3204181.0288772904 -390017.7023099535 -738.9206495665225\n",
      "lmds:  [ 0.53365001 -0.09747545 -0.00192517]\n",
      "lmd_max: tensor([0.5337], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5337], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5337], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(266.4852, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(4.1687, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5337], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(142.1446, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 5.704866573870176e-126\n",
      "yk norm: 2.5775073293284973e-124\n",
      "Loss: 70.57068443681466 | GradNorm^2: 44.572125780414616\n",
      "g_norm_l2: 34.878828104208225\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 6.21698472516458e-42\n",
      "yk norm: 2.322099260193482e-40\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 7.025181957796351e-18\n",
      "yk norm: 3.4024545551591837e-16\n",
      "g_norm_l2: 8.791099946274007e-29\n",
      "yk norm: 1.6966914981826937e-28\n",
      "g_norm_l2: 7.2983305046691445e-40\n",
      "yk norm: 9.490054117073486e-40\n",
      "g_norm_l2: 9.818704659556717e-66\n",
      "yk norm: 4.3939191845869116e-64\n",
      "g_norm_l2: 1.242714705903481e-07\n",
      "yk norm: 8.319511978403625e-06\n",
      "D_hat_inv: 267.43442980708585\n",
      "g_norm_D: 8.019977093931436e-14\n",
      "g_norm_l2: 3.017147880094717e-20\n",
      "yk norm: 1.0889518602986885e-18\n",
      "g_norm_l2: 2.3174858114194978e-79\n",
      "yk norm: 7.884755726745944e-78\n",
      "g_norm_l2: 6.530810627907788e-17\n",
      "yk norm: 4.433378664249116e-15\n",
      "g_norm_l2: 4.101875481267999e-87\n",
      "yk norm: 8.54981644503493e-86\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.009905441426119013\n",
      "yk norm: 0.27304022291323504\n",
      "D_hat_inv: 268.0702394413649\n",
      "g_norm_D: 0.0004891556931608475\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 0.009905441426119013\n",
      "D_inv norm: 268.0702394413649\n",
      "B norm: 0.3594922036917266\n",
      "a: 0.0004891556931608475\n",
      "b: 0.0008766697736296314\n",
      "c: 1.792210099742944\n",
      "plms: 0.0031423528448767716 0.00018240235458508126 -0.0027313839673762273 -0.0005457942142830405\n",
      "lmds:  [ 0.99319869 -0.84405622 -0.20718889]\n",
      "lmd_max: tensor([0.9932], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.9932], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.9932], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(268.0702, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.3595, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.9932], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(266.1458, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 35.8940790490785\n",
      "yk norm: 3.732540397506347e-14\n",
      "g_norm_l2: 1.9279192136412526e-60\n",
      "yk norm: 1.2966751479788474e-58\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 38.734231303470914\n",
      "yk norm: 10.200739054255187\n",
      "D_hat_inv: 268.49280282364\n",
      "g_norm_D: 7534.733567037176\n",
      "loss:  tensor(4.6553, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 38.734231303470914\n",
      "D_inv norm: 268.49280282364\n",
      "B norm: 14.407495115261382\n",
      "a: 7534.733567037176\n",
      "b: 545173.0736916324\n",
      "c: 72.35465844162643\n",
      "plms: 78891623.07705939 -37313861.60361554 -1076623.9980557335 -9.310511828551423\n",
      "lmds:  [ 5.00256446e-01 -2.72715765e-02 -8.65047047e-06]\n",
      "lmd_max: tensor([0.5003], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(268.4928, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(14.4075, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5003], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(134.2506, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 62.00940430516591\n",
      "yk norm: 1865.39116477599\n",
      "D_hat_inv: 267.8366833416509\n",
      "g_norm_D: 16643.40050906117\n",
      "loss:  tensor(645.7358, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 62.00940430516591\n",
      "D_inv norm: 267.8366833416509\n",
      "B norm: 3845.1662222815307\n",
      "a: 16643.40050906117\n",
      "b: 277002780.50501776\n",
      "c: 16643.400509061183\n",
      "plms: 9220536436137.154 -4966901413041.789 -596961230.2099823 -1291.4715348453085\n",
      "lmds:  [ 5.38798301e-01 -1.17957714e-04 -2.20381982e-06]\n",
      "lmd_max: tensor([0.5388], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5388], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5388], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(267.8367, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(3845.1662, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5388], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(144.2449, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 5.77040699768202e-46\n",
      "yk norm: 2.4685683024588943e-44\n",
      "g_norm_l2: 1.2207948111238094e-149\n",
      "yk norm: 3.1951818741286832e-149\n",
      "g_norm_l2: 46.961743348969875\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.268141501973581e-124\n",
      "yk norm: 6.314600159451169e-123\n",
      "g_norm_l2: 4.452288575627904e-63\n",
      "yk norm: 3.4446928164699636e-61\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.5455732219816155e-73\n",
      "yk norm: 7.310019591810355e-72\n",
      "g_norm_l2: 41.503055524435474\n",
      "yk norm: 3.0139649097644766e-13\n",
      "g_norm_l2: 44.01082187663913\n",
      "yk norm: 1.4162028180782747e-13\n",
      "g_norm_l2: 6.398118747363701e-118\n",
      "yk norm: 4.894359091103647e-117\n",
      "g_norm_l2: 46.18893655269367\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.0219704478379629e-137\n",
      "yk norm: 2.0295857055860516e-138\n",
      "g_norm_l2: 1.7413741200059792e-90\n",
      "yk norm: 6.948169214812417e-89\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 42.93269227210107\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.883778495140337e-102\n",
      "yk norm: 3.059134625616565e-100\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 3.0695306512592824e-13\n",
      "g_norm_l2: 42.33001765207998\n",
      "yk norm: 1.7280672168090081e-09\n",
      "D_hat_inv: 270.1231296833661\n",
      "g_norm_D: 9487.557775077441\n",
      "loss:  tensor(27.8015, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 42.33001765207998\n",
      "D_inv norm: 270.1231296833661\n",
      "B norm: 1.5111148386190553e-09\n",
      "a: 9487.557775077441\n",
      "b: 7.591182600722335e-05\n",
      "c: 8.001197758883079e-09\n",
      "plms: 1.2147710642434353e-12 0.00030364730341794825 18975.11539744145 -55.60300492309928\n",
      "lmds:  [ 2.93022394e-03 -1.24989193e+08 -1.24973382e+08]\n",
      "lmd_max: tensor([0.0029], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0029], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0029], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(270.1231, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1.5111e-09, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0029], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.7915, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 8.795766871410267e-85\n",
      "yk norm: 2.434542971545631e-83\n",
      "g_norm_l2: 1.8619700803730581\n",
      "yk norm: 70.84746343968223\n",
      "D_hat_inv: 270.51024583327666\n",
      "g_norm_D: 18.49017909584438\n",
      "loss:  tensor(0.0336, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 1.8619700803730581\n",
      "D_inv norm: 270.51024583327666\n",
      "B norm: 101.48207634821347\n",
      "a: 18.49017909584438\n",
      "b: 10007.513478532994\n",
      "c: 541.2339938222749\n",
      "plms: 10832812.976433316 -5396057.166913602 -20050.772010935303 -0.06718481552443417\n",
      "lmds:  [ 5.01810042e-01 -3.68517697e-03 -3.35376160e-06]\n",
      "lmd_max: tensor([0.5018], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5018], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5018], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(270.5102, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(101.4821, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5018], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(135.6775, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 50.84091715841172\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 3.5375264328970276e-115\n",
      "yk norm: 9.60489152525652e-114\n",
      "g_norm_l2: 7.867177263072394\n",
      "yk norm: 512.4535957298069\n",
      "D_hat_inv: 270.868099062722\n",
      "g_norm_D: 312.3755323083458\n",
      "loss:  tensor(0.2224, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 7.867177263072394\n",
      "D_inv norm: 270.86809906272197\n",
      "B norm: 248.5040399191069\n",
      "a: 312.3755323083458\n",
      "b: 391786.6200296245\n",
      "c: 1254.2167343724348\n",
      "plms: 982770670.288739 -490517858.738675 -784064.197396935 -0.4447829357263921\n",
      "lmds:  [ 5.00710672e-01 -1.59278947e-03 -5.67480190e-07]\n",
      "lmd_max: tensor([0.5007], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5007], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5007], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(270.8681, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(248.5040, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5007], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(135.5616, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 38.52273011081235\n",
      "yk norm: 2.2607155876895898e-07\n",
      "D_hat_inv: 270.9793840886687\n",
      "g_norm_D: 7884.339967506319\n",
      "loss:  tensor(22.3530, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 38.52273011081235\n",
      "D_inv norm: 270.97938408866867\n",
      "B norm: 2.908447052598096e-07\n",
      "a: 7884.339967506319\n",
      "b: 0.012183097810704945\n",
      "c: 1.545227357130092e-06\n",
      "plms: 3.765131206338603e-08 0.04873237231041813 15768.655430655315 -44.705946032486786\n",
      "lmds:  [ 2.83511449e-03 -6.47722546e+05 -6.46584870e+05]\n",
      "lmd_max: tensor([0.0028], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0028], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0028], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(270.9794, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(2.9084e-07, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0028], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(0.7683, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 41.50663154498864\n",
      "yk norm: 3946.9938830040287\n",
      "D_hat_inv: 267.8566252966975\n",
      "g_norm_D: 8244.315921265994\n",
      "loss:  tensor(479.1233, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 41.50663154498864\n",
      "D_inv norm: 267.8566252966975\n",
      "B norm: 1722.8004622114468\n",
      "a: 8244.315921265994\n",
      "b: 67968745.00963996\n",
      "c: 8244.315921265996\n",
      "plms: 1120711613262.887 -625214746475.6364 -151721175.82185668 -958.2465413329892\n",
      "lmds:  [ 5.58115565e-01 -2.36078400e-04 -6.48937696e-06]\n",
      "lmd_max: tensor([0.5581], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5581], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5581], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(267.8566, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(1722.8005, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5581], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(149.4253, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 2.7311318979434773e-79\n",
      "yk norm: 2.6553688653020223e-77\n",
      "g_norm_l2: 45.207385077355625\n",
      "yk norm: 1.4819590161881457e-13\n",
      "g_norm_l2: 55.92405513454919\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 41.555220964673886\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 5.948171107863608e-94\n",
      "yk norm: 1.0288798910435286e-92\n",
      "g_norm_l2: 54.022935674954304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 1.6565418978234785e-21\n",
      "yk norm: 7.842158037531654e-20\n",
      "g_norm_l2: 35.120780157696544\n",
      "yk norm: 328.3967287195241\n",
      "D_hat_inv: 269.00280210878634\n",
      "g_norm_D: 6512.255009461662\n",
      "loss:  tensor(1.1794, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 35.120780157696544\n",
      "D_inv norm: 269.00280210878634\n",
      "B norm: 547.6564584665613\n",
      "a: 6512.255009461662\n",
      "b: 18829669.680581965\n",
      "c: 2891.4208140228416\n",
      "plms: 108888997671.21906 -54388899674.51585 -37659954.87028924 -2.358705290852396\n",
      "lmds:  [ 5.00180859e-01 -6.91400101e-04 -6.26373244e-08]\n",
      "lmd_max: tensor([0.5002], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(269.0028, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(547.6565, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5002], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(134.4839, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "Loss: 65.71978772320443 | GradNorm^2: 32.19074926185105\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 4.073087529551146\n",
      "yk norm: 72.5477270499006\n",
      "D_hat_inv: 269.51277759826417\n",
      "g_norm_D: 88.15066356857795\n",
      "loss:  tensor(0.0837, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 4.073087529551146\n",
      "D_inv norm: 269.5127775982642\n",
      "B norm: 189.97372651902396\n",
      "a: 88.15066356857795\n",
      "b: 88980.98880268606\n",
      "c: 1009.4193872229009\n",
      "plms: 179638270.38339034 -89633827.36552219 -178123.7243308034 -0.16744678022208861\n",
      "lmds:  [ 5.00947828e-01 -1.97844880e-03 -9.40503944e-07]\n",
      "lmd_max: tensor([0.5009], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5009], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5009], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(269.5128, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(189.9737, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5009], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(134.9456, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 36.826385328060205\n",
      "yk norm: 7.768696120345986e-14\n",
      "g_norm_l2: 44.01082187663912\n",
      "yk norm: 1.2192554156750035e-12\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 47.42656100329342\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 39.442258412479454\n",
      "yk norm: 2.0279552519998133e-14\n",
      "g_norm_l2: 42.32505630956438\n",
      "yk norm: 0.04473253967898525\n",
      "D_hat_inv: 270.17166305302453\n",
      "g_norm_D: 9558.28082934683\n",
      "loss:  tensor(9.0516, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 42.32505630956438\n",
      "D_inv norm: 270.17166305302453\n",
      "B norm: 0.20998910285387273\n",
      "a: 9558.28082934683\n",
      "b: 10709.303867657396\n",
      "c: 1.1204215547608287\n",
      "plms: 23997.869779613717 30815.554890824096 -2342.6123972208698 -18.10315074150653\n",
      "lmds:  [ 0.07866855 -1.35569072 -0.00707326]\n",
      "lmd_max: tensor([0.0787], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.0787], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.0787], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(270.1717, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(0.2100, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.0787], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(21.2526, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 9.643900089198867\n",
      "yk norm: 356.79224650343525\n",
      "D_hat_inv: 270.34780865581837\n",
      "g_norm_D: 497.2876071000819\n",
      "loss:  tensor(0.2517, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 9.643900089198867\n",
      "D_inv norm: 270.34780865581837\n",
      "B norm: 324.9027393512368\n",
      "a: 497.2876071000819\n",
      "b: 863899.5360811235\n",
      "c: 1737.2231355591753\n",
      "plms: 3001572521.757932 -1498850103.235576 -1728553.77194886 -0.5034687153904861\n",
      "lmds:  [ 5.00505555e-01 -1.15031140e-03 -2.91339467e-07]\n",
      "lmd_max: tensor([0.5005], device='cuda:0', dtype=torch.float64), lmd_min: tensor([0.], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 1:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "lmd_star 2:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "D_inv norm:  tensor(270.3478, device='cuda:0', dtype=torch.float64)\n",
      "B norm:  tensor(324.9027, device='cuda:0', dtype=torch.float64)\n",
      "lmd_star:  tensor([0.5005], device='cuda:0', dtype=torch.float64)\n",
      "Precond norm:  tensor(135.2442, device='cuda:0', dtype=torch.float64)\n",
      "==================\n",
      "g_norm_l2: 3.1763215370686694e-07\n",
      "yk norm: 2.471352264072412e-05\n",
      "D_hat_inv: 270.4574136186995\n",
      "g_norm_D: 5.467682836651868e-13\n",
      "g_norm_l2: 0.0\n",
      "yk norm: 1.6781460548161788e-161\n",
      "g_norm_l2: 1.403819060351291e-111\n",
      "yk norm: 1.8847933166989794e-110\n",
      "g_norm_l2: 6.012454062525116e-121\n",
      "yk norm: 3.792122589315012e-119\n",
      "g_norm_l2: nan\n",
      "yk norm: nan\n",
      "g_norm_l2: 2.25555826501294e-35\n",
      "yk norm: 8.86242740005406e-34\n",
      "g_norm_l2: 38.522730118362304\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 35.9024538984454\n",
      "yk norm: 0.0\n",
      "g_norm_l2: 46.84977630494848\n",
      "yk norm: 4019.0832876361223\n",
      "D_hat_inv: nan\n",
      "g_norm_D: nan\n",
      "loss:  tensor(438.6838, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 46.84977630494848\n",
      "D_inv norm: nan\n",
      "B norm: 2194.901539823712\n",
      "a: nan\n",
      "b: nan\n",
      "c: nan\n",
      "plms: nan nan nan -877.3675792952963\n",
      "lmds:  None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=106'>107</a>\u001b[0m \u001b[39m# lmd = sympy.Symbol('lmd')\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39m# expr = AA * lmd**3 + BB * lmd**2 + CC * lmd + DD\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=108'>109</a>\u001b[0m \u001b[39m# lmds = sympy.solve(expr)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlmds: \u001b[39m\u001b[39m\"\u001b[39m, lmds)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=112'>113</a>\u001b[0m lmd_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmaximum(np\u001b[39m.\u001b[39;49mmax(lmds), torch\u001b[39m.\u001b[39;49mtensor(\u001b[39m0\u001b[39;49m))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=113'>114</a>\u001b[0m lmd_max \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(lmd_max, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat64, device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=115'>116</a>\u001b[0m lmd_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(np\u001b[39m.\u001b[39mmin(lmds), torch\u001b[39m.\u001b[39mtensor(\u001b[39m0\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# training \n",
    "STEPS = 100\n",
    "loss_class = get_loss(\"logreg\")\n",
    "\n",
    "\n",
    "# dataset\n",
    "batch_size = 1\n",
    "dataset_name = \"colon-cancer\"\n",
    "percentage = 1.0\n",
    "scale_range = None # [-value, value]\n",
    "train_data, train_target = get_dataset(dataset_name, batch_size, percentage, scale_range, loss_class.y_range)\n",
    "train_load = data_utils.TensorDataset(train_data, train_target)\n",
    "train_dataloader = DataLoader(train_load, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# parameters\n",
    "alpha=0.1\n",
    "beta=0.999\n",
    "w = torch.zeros(train_data.shape[1], dtype=torch.float64, device=device).requires_grad_()\n",
    "\n",
    "loss_function = loss_class(w)\n",
    "\n",
    "# save loss and grad size to history\n",
    "hist_sps_d = []\n",
    "loss = loss_function(train_data.to(device).to(torch.float64), train_target.to(device).to(torch.float64)) \n",
    "g, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "print(f\"Loss: {loss.item()} | GradNorm^2: {(torch.linalg.norm(g) ** 2 ).item()}\")\n",
    "hist_sps_d.append([loss.item(), (torch.linalg.norm(g) ** 2).item()])\n",
    "\n",
    "# preconditioninig matrix\n",
    "Dk = diag_estimate_old(w, g, 100)\n",
    "print(\"Dk norm: \", torch.linalg.norm(Dk))\n",
    "\n",
    "\n",
    "for step in range(STEPS):\n",
    "\n",
    "    for i, (batch_data, batch_target) in enumerate(train_dataloader):\n",
    "        batch_data = batch_data.to(device).to(torch.float64)\n",
    "        batch_target = batch_target.to(device).to(torch.float64)\n",
    "\n",
    "        loss = loss_function(batch_data, batch_target)\n",
    "        gk = g.clone().detach()\n",
    "        g, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "        g_delta = g - gk\n",
    "\n",
    "    \n",
    "        vk = diag_estimate_old(w, g, 1)\n",
    "\n",
    "        print(f\"g_norm_l2: {torch.linalg.norm(g)}\")\n",
    "\n",
    "        # Smoothing and Truncation \n",
    "        Dk = beta * Dk + (1 - beta) * vk\n",
    "        Dk_hat = torch.abs(Dk)\n",
    "        Dk_hat[Dk_hat < alpha] = alpha\n",
    "\n",
    "        Dk_hat_inv = 1 / Dk_hat\n",
    "\n",
    "        sk = torch.randn(batch_data.shape[1], dtype=torch.float64, device=device)\n",
    "        # yk = torch.autograd.functional.hvp(loss_function, sk)\n",
    "        yk, = torch.autograd.grad(g, w, grad_outputs=sk)\n",
    "        yk_norm = torch.linalg.norm(yk)\n",
    "\n",
    "        print(f\"yk norm: {yk_norm}\")\n",
    "\n",
    "        if yk_norm < 1e-10 or torch.isnan(yk_norm):\n",
    "            continue\n",
    "\n",
    "        B = ((yk.reshape(-1, 1) @ yk.reshape(1, -1)) / (yk.dot(sk))).to(dtype=torch.float64)\n",
    "\n",
    "        gnorm = (g * Dk_hat_inv).dot(g)\n",
    "\n",
    "        print(f\"D_hat_inv: {torch.linalg.norm(Dk_hat_inv)}\")\n",
    "        print(f\"g_norm_D: {gnorm}\")\n",
    "\n",
    "        if gnorm < 1e-12:\n",
    "            continue\n",
    "\n",
    "        f_grad = g.clone().detach().to(dtype=torch.float64)\n",
    "        D_inv = torch.diagflat(Dk_hat_inv.clone().detach()).to(dtype=torch.float64)\n",
    "        a = torch.dot(f_grad, D_inv@f_grad).to(dtype=torch.float64)\n",
    "        b = torch.dot(f_grad, D_inv@B@D_inv@f_grad).to(dtype=torch.float64)\n",
    "        c = torch.trace(B@D_inv).to(dtype=torch.float64)\n",
    "\n",
    "        if torch.linalg.norm(f_grad) < 1e-12:\n",
    "            continue\n",
    "\n",
    "        print(\"loss: \", loss)\n",
    "        print(f\"f_grad norm: {torch.linalg.norm(f_grad)}\")\n",
    "        print(f\"D_inv norm: {torch.linalg.norm(D_inv)}\")\n",
    "        print(f\"B norm: {torch.linalg.norm(B)}\") \n",
    "        print(f\"a: {a}\")\n",
    "        print(f\"b: {b}\")\n",
    "        print(f\"c: {c}\") \n",
    "\n",
    "        AA = (2 * a * c ** 2).detach().cpu().numpy()\n",
    "        BB = (4 * a * c - 2 * loss * c**2 - b * c).detach().cpu().numpy()\n",
    "        CC = (2 * a - 4 * c * loss - 2 * b).detach().cpu().numpy()\n",
    "        DD = (- 2 * loss).detach().cpu().numpy()\n",
    "        \n",
    "        print(f\"plms: {AA} {BB} {CC} {DD}\")\n",
    "\n",
    "        def lagr(lmd):\n",
    "            b = lambda l: D_inv - (D_inv @ (l * B) @ D_inv) / (1 + torch.trace((l * B) @ D_inv))\n",
    "            return lmd * loss -  (1/2)*lmd**2 * torch.dot(f_grad, b(lmd)@f_grad)\n",
    "\n",
    "        lmds = solve(AA, BB, CC, DD)\n",
    "\n",
    "        # lmd = sympy.Symbol('lmd')\n",
    "        # expr = AA * lmd**3 + BB * lmd**2 + CC * lmd + DD\n",
    "        # lmds = sympy.solve(expr)\n",
    "\n",
    "        print(\"lmds: \", lmds)\n",
    "        \n",
    "        lmd_max = np.maximum(np.max(lmds), torch.tensor(0))\n",
    "        lmd_max = torch.tensor(lmd_max, dtype=torch.float64, device=device).reshape(1)\n",
    "\n",
    "        lmd_min = np.maximum(np.min(lmds), torch.tensor(0))\n",
    "        lmd_min = torch.tensor(lmd_min, dtype=torch.float64, device=device).reshape(1)\n",
    "\n",
    "        print(f\"lmd_max: {lmd_max}, lmd_min: {lmd_min}\")\n",
    "\n",
    "        lmd_star = lmd_max\n",
    "        print(\"lmd_star 1: \", lmd_star)\n",
    "        if lmd_min > 0 and lagr(lmd_max) < lagr(lmd_min):\n",
    "            lmd_star = lmd_min\n",
    "        print(\"lmd_star 2: \", lmd_star)\n",
    "\n",
    "        print(\"D_inv norm: \", torch.linalg.norm(D_inv))\n",
    "        print(\"B norm: \", torch.linalg.norm(B))\n",
    "        print(\"lmd_star: \", lmd_star)\n",
    "\n",
    "        \n",
    "        precond = lmd_star * (D_inv - (D_inv @ (lmd_star * B) @ D_inv) / (1 + torch.trace((lmd_star * B) @ D_inv)))\n",
    "\n",
    "        print(\"Precond norm: \", torch.linalg.norm(precond))\n",
    "        print(\"==================\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w.sub_(precond @ g)\n",
    "\n",
    "    \n",
    "\n",
    "    loss = loss_function(train_data.to(device).to(torch.float64), train_target.to(device).to(torch.float64))\n",
    "    g, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "    print(f\"Loss: {loss.item()} | GradNorm^2: {(torch.linalg.norm(g) ** 2 ).item()}\")\n",
    "    hist_sps_d.append([loss.item(), (torch.linalg.norm(g) ** 2).item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 4, 6],\n",
       "        [3, 6, 9]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.asarray([[1, 2], [4, 3]])\n",
    "b = torch.asarray([[2, 5, 3], [0, 1, 4]])\n",
    "c = torch.asarray([[1, 0], [2, 2]])\n",
    "\n",
    "d = torch.asarray([[1, 2, 3]])\n",
    "e = torch.asarray([[3, 5, 1]])\n",
    "\n",
    "\n",
    "d.mul(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]]),\n",
       " torch.Size([3, 3]),\n",
       " tensor([1., 2., 3.]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.eye(3)\n",
    "q = torch.asarray([1., 2., 3.])\n",
    "z = torch.asarray([2., 2., 3.])\n",
    "\n",
    "A, A.shape, q, q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z - A @ q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = (z - A @ q).reshape(-1, 1)\n",
    "\n",
    "ys @ ys.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq = torch.asarray([[1, 2, 3]])\n",
    "\n",
    "qq, qq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0918, -0.1069, -0.0032,  ...,  0.0029, -0.1239,  0.1123],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg = g.clone().detach()\n",
    "ss = torch.randn(batch_data.shape[1], dtype=torch.float64, device=device)\n",
    "\n",
    "(gg * ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_torch(w):\n",
    "        return torch.mean(torch.log(1 + torch.exp(-y * (X @ w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(train_data.shape[1], device=device).requires_grad_()\n",
    "v = torch.randn(train_data.shape[1], device=device)\n",
    "\n",
    "def closure(w):\n",
    "    loss_function = loss_class(w)\n",
    "    return loss_function(train_data.to(device), train_target.to(device))\n",
    "\n",
    "loss = closure(w)\n",
    "# hvp, = torch.autograd.grad(g, w, grad_outputs=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_torch = torch.autograd.functional.hessian(closure, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# %%timeit\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m hvp, \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(g, w, grad_outputs\u001b[39m=\u001b[39;49mv, retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/sps2/lib/python3.10/site-packages/torch/autograd/__init__.py:275\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs)\n\u001b[1;32m    274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    276\u001b[0m         outputs, grad_outputs_, retain_graph, create_graph, inputs,\n\u001b[1;32m    277\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "hvp, = torch.autograd.grad(g, w, grad_outputs=v, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "Hvp_torch = torch.autograd.functional.hvp(closure, w, v)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "Hvp_torch_2 = torch.autograd.functional.vhp(closure, w, v)[1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4506e-09, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(Hvp_torch.sum() - Hvp_torch_2.sum().item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4506e-09, device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.abs(Hvp.sum() - Hvp_torch.sum().item()) < SMALL\n",
    "torch.abs(hvp.sum() - Hvp_torch.sum().item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\min \\frac{1}{2} \\| w - w^t \\|^2_D \\\\ \n",
    "s.t. \\quad f_i + \\langle \\nabla f_i, w - w^t \\rangle + \\frac{1}{2} \\langle B(w-w^t), (w-w^t) \\rangle = 0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farshed.abdukhakimov/projects/sps2/datasets\n",
      "Loss: 0.6931471805599454 | GradNorm^2: 0.3195669607542957\n",
      "Dk norm:  tensor(1.2351, device='cuda:0')\n",
      "w-x: 0.6755426433049205\n",
      "Loss: 0.03555294490561396 | GradNorm^2: 0.000580568727899756\n",
      "Loss: 0.003684802247198842 | GradNorm^2: 6.867250700358725e-06\n",
      "Loss: 0.007757956071311118 | GradNorm^2: 5.860315870659724e-05\n",
      "Loss: 0.0026929791866434154 | GradNorm^2: 9.302474918216288e-06\n",
      "Loss: 0.0023991831940701944 | GradNorm^2: 1.1014190456571182e-05\n",
      "Loss: 0.0007882460628125505 | GradNorm^2: 3.1760866100762934e-06\n",
      "Loss: 0.0017656464424613831 | GradNorm^2: 1.0517360920909722e-05\n",
      "Loss: 0.00018724801907859804 | GradNorm^2: 4.0549136880977054e-07\n",
      "Loss: 0.00018028426096711807 | GradNorm^2: 3.800829137791337e-07\n",
      "Loss: 0.00021123718587867313 | GradNorm^2: 4.585567238663337e-07\n",
      "Loss: 0.0005663879440984218 | GradNorm^2: 1.4780627853295872e-06\n",
      "Loss: 0.0003102904687333758 | GradNorm^2: 7.377749904425623e-07\n",
      "Loss: 0.000378114972759007 | GradNorm^2: 9.363460853205557e-07\n",
      "Loss: 0.00021844479868517413 | GradNorm^2: 4.6405339320112025e-07\n",
      "Loss: 0.0006020180653966358 | GradNorm^2: 1.4453383901412555e-06\n",
      "Loss: 0.00015334272926360057 | GradNorm^2: 2.6951731089555076e-07\n",
      "Loss: 0.00019095874332868959 | GradNorm^2: 3.6015961184806144e-07\n",
      "Loss: 5.735744006540047e-05 | GradNorm^2: 5.270266540530041e-08\n",
      "Loss: 0.00018278513659830329 | GradNorm^2: 3.442400855016644e-07\n",
      "Loss: 0.00016594966600980726 | GradNorm^2: 2.961245342202317e-07\n",
      "Loss: 0.00016516630389289312 | GradNorm^2: 2.9331001550155857e-07\n",
      "Loss: 7.057019027309613e-05 | GradNorm^2: 7.665237088916514e-08\n",
      "Loss: 1.1160237298735012e-05 | GradNorm^2: 2.43738380024428e-09\n",
      "Loss: 9.924745923358354e-06 | GradNorm^2: 1.9384797375531946e-09\n",
      "Loss: 6.844370054079463e-06 | GradNorm^2: 9.339334787973829e-10\n",
      "Loss: 5.978130886754777e-06 | GradNorm^2: 7.150680452105509e-10\n",
      "Loss: 2.7905787428841247e-06 | GradNorm^2: 1.579918356685859e-10\n",
      "Loss: 2.1634068561598225e-07 | GradNorm^2: 9.583836473468778e-13\n",
      "Loss: 3.7836788264713054e-07 | GradNorm^2: 2.928337522210947e-12\n",
      "Loss: 4.6829082739906786e-08 | GradNorm^2: 4.4937362939462786e-14\n",
      "Loss: 1.1106138550361723e-07 | GradNorm^2: 2.5254515759597043e-13\n",
      "Loss: 5.6095869475746414e-08 | GradNorm^2: 6.441569853842572e-14\n",
      "Loss: 3.855043766986758e-08 | GradNorm^2: 3.042799429548338e-14\n",
      "Loss: 7.736440582072743e-09 | GradNorm^2: 1.2259223257094092e-15\n",
      "Loss: 4.09423716477943e-09 | GradNorm^2: 3.4326353445687956e-16\n",
      "Loss: 3.3073610885107024e-09 | GradNorm^2: 2.2404917238552313e-16\n",
      "Loss: 4.7070118056737e-09 | GradNorm^2: 4.537508682874499e-16\n",
      "Loss: 1.6351335623092898e-09 | GradNorm^2: 5.476669129233607e-17\n",
      "Loss: 4.0713784472409253e-10 | GradNorm^2: 3.396412797667117e-18\n",
      "Loss: 7.182954898305751e-10 | GradNorm^2: 1.0569985385595048e-17\n",
      "Loss: 3.167500484709121e-10 | GradNorm^2: 2.0563023419336597e-18\n",
      "Loss: 5.0066663022692615e-11 | GradNorm^2: 5.137906417346266e-20\n",
      "Loss: 1.742696329173206e-11 | GradNorm^2: 6.227375583889058e-21\n",
      "Loss: 1.7950750458519626e-11 | GradNorm^2: 6.6077623308197406e-21\n",
      "Loss: 1.8985277775006555e-11 | GradNorm^2: 7.394166142532016e-21\n",
      "Loss: 5.339704875174943e-12 | GradNorm^2: 5.850067416001138e-22\n",
      "Loss: 5.2477757885005635e-12 | GradNorm^2: 5.646471852994302e-22\n",
      "Loss: 2.038241113983904e-12 | GradNorm^2: 8.517650023207524e-23\n",
      "Loss: 9.501986683759443e-13 | GradNorm^2: 1.8512802096052072e-23\n",
      "Loss: 2.187647731465373e-13 | GradNorm^2: 9.807117104906334e-25\n",
      "Loss: 1.2255361366037145e-12 | GradNorm^2: 3.0765279120362585e-23\n",
      "Loss: 3.285429260066527e-13 | GradNorm^2: 2.211270873596365e-24\n",
      "Loss: 1.1771512696719424e-13 | GradNorm^2: 2.8383958424244024e-25\n",
      "Loss: 4.927299336156756e-14 | GradNorm^2: 4.974023744961235e-26\n",
      "Loss: 4.467297476344776e-14 | GradNorm^2: 4.0886819789137505e-26\n",
      "Loss: 5.487636713496766e-14 | GradNorm^2: 6.170939423117257e-26\n",
      "Loss: 2.8087221261043715e-14 | GradNorm^2: 1.6166098730170663e-26\n",
      "Loss: 1.6958670366546723e-14 | GradNorm^2: 5.89170684776682e-27\n",
      "Loss: 1.3930237782426405e-14 | GradNorm^2: 3.97504142412853e-27\n",
      "Loss: 7.164109012691148e-15 | GradNorm^2: 1.0513823018191263e-27\n",
      "Loss: 4.0221395883683276e-15 | GradNorm^2: 3.3138715109185498e-28\n",
      "Loss: 2.8648509791107564e-15 | GradNorm^2: 1.681279640490399e-28\n",
      "Loss: 1.4450391755727464e-15 | GradNorm^2: 4.2768270876872865e-29\n",
      "Loss: 7.468450061013679e-16 | GradNorm^2: 1.1425579977795792e-29\n",
      "Loss: 7.779760751571175e-16 | GradNorm^2: 1.2395197206195816e-29\n",
      "Loss: 7.370055110529844e-16 | GradNorm^2: 1.1135986692710768e-29\n",
      "Loss: 2.1748017249971606e-16 | GradNorm^2: 9.689320065227806e-31\n",
      "Loss: 2.0023372423438177e-16 | GradNorm^2: 8.222128151916605e-31\n",
      "Loss: 3.1628510194372734e-16 | GradNorm^2: 2.0512603678939934e-30\n",
      "Loss: 2.976447252133739e-17 | GradNorm^2: 1.7446280982540455e-32\n",
      "Loss: 9.158929974195523e-17 | GradNorm^2: 1.7192765099034167e-31\n",
      "Loss: 2.981913638271721e-17 | GradNorm^2: 1.8194920826084307e-32\n",
      "Loss: 1.145207895908247e-17 | GradNorm^2: 2.6060768356433388e-33\n",
      "Loss: 7.570944801111857e-18 | GradNorm^2: 1.1227052649834952e-33\n",
      "Loss: 8.308906929740077e-18 | GradNorm^2: 1.41767306885696e-33\n",
      "Loss: 2.7605249996834147e-18 | GradNorm^2: 9.907422017230408e-35\n",
      "Loss: 2.0225628710551768e-18 | GradNorm^2: 6.701502877820186e-35\n",
      "Loss: 1.1206091582873296e-18 | GradNorm^2: 1.7294044081313736e-35\n",
      "Loss: 1.1206091582873314e-18 | GradNorm^2: 2.228609346236858e-36\n",
      "Loss: 1.1752730196671994e-18 | GradNorm^2: 2.5606382746805886e-35\n",
      "Loss: 7.379621286282419e-19 | GradNorm^2: 1.0420750036256081e-35\n",
      "Loss: 6.0130247517856775e-19 | GradNorm^2: 5.9991928369624147e-36\n",
      "Loss: 7.652940593181768e-19 | GradNorm^2: 1.38043220613029e-35\n",
      "Loss: 1.639915841396095e-19 | GradNorm^2: 8.028092112125979e-37\n",
      "Loss: 1.9132351482954442e-19 | GradNorm^2: 1.7285445328525358e-36\n",
      "Loss: 1.0932772275973967e-19 | GradNorm^2: 1.02036876887927e-36\n",
      "Loss: 1.0932772275973967e-19 | GradNorm^2: 8.0919637915474e-37\n",
      "Loss: 5.466386137986984e-20 | GradNorm^2: 1.28604865238215e-36\n",
      "Loss: 1.9132351482954444e-19 | GradNorm^2: 7.436041495491447e-36\n",
      "Loss: 5.466386137986984e-20 | GradNorm^2: 6.900810067811324e-37\n",
      "Loss: 1.0932772275973967e-19 | GradNorm^2: 4.779933091282827e-36\n",
      "Loss: 1.0932772275973967e-19 | GradNorm^2: 4.5799230843432346e-36\n",
      "Loss: 0.0 | GradNorm^2: 2.9949927973877872e-36\n",
      "Loss: 0.0 | GradNorm^2: 2.9949927973877872e-36\n",
      "Loss: 0.0 | GradNorm^2: 2.9949927973877872e-36\n",
      "Loss: 0.0 | GradNorm^2: 2.9949927973877872e-36\n",
      "Loss: 0.0 | GradNorm^2: 2.9949927973877872e-36\n",
      "Loss: 0.0 | GradNorm^2: 2.9949927973877872e-36\n",
      "Loss: 0.0 | GradNorm^2: 2.9949927973877872e-36\n",
      "Loss: 0.0 | GradNorm^2: 2.9949927973877872e-36\n",
      "w-x: 68.87979436022009\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "STEPS = 100\n",
    "loss_class = get_loss(\"logreg\")\n",
    "\n",
    "# dataset\n",
    "batch_size = 16\n",
    "dataset_name = \"mushrooms\"\n",
    "percentage = 1.0\n",
    "scale_range = None # [-value, value]\n",
    "train_data, train_target = get_dataset(dataset_name, batch_size, percentage, scale_range, loss_class.y_range)\n",
    "train_data = train_data.to(torch.get_default_dtype())\n",
    "train_target = train_target.to(torch.get_default_dtype())\n",
    "train_load = data_utils.TensorDataset(train_data, train_target)\n",
    "train_dataloader = DataLoader(train_load, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# parameters\n",
    "alpha = 1e-4\n",
    "beta=0.999\n",
    "w = torch.zeros(train_data.shape[1], device=device).requires_grad_()\n",
    "\n",
    "loss_function = loss_class(w)\n",
    "\n",
    "# save loss and grad size to history\n",
    "hist_sps_d = []\n",
    "loss = loss_function(train_data.to(device), train_target.to(device))\n",
    "g, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "print(f\"Loss: {loss.item()} | GradNorm^2: {(torch.linalg.norm(g) ** 2 ).item()}\")\n",
    "hist_sps_d.append([loss.item(), (torch.linalg.norm(g) ** 2).item()])\n",
    "\n",
    "# preconditioninig matrix\n",
    "Dk = diag_estimate_old(w, g, 10)\n",
    "print(\"Dk norm: \", torch.linalg.norm(Dk))\n",
    "\n",
    "print(f\"w-x: {torch.abs(torch.sum(w) - torch.sum(xopt))}\")\n",
    "\n",
    "for step in range(STEPS):\n",
    "\n",
    "    for i, (batch_data, batch_target) in enumerate(train_dataloader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_target = batch_target.to(device)\n",
    "\n",
    "        loss = loss_function(batch_data, batch_target)\n",
    "        g, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "    \n",
    "        vk = diag_estimate_old(w, g, 1)\n",
    "\n",
    "        # print(f\"g_norm_l2: {torch.linalg.norm(g)}\")   \n",
    "\n",
    "        # Smoothing and Truncation \n",
    "        Dk = beta * Dk + (1 - beta) * vk\n",
    "        Dk_hat = torch.abs(Dk)\n",
    "        Dk_hat[Dk_hat < alpha] = alpha\n",
    "\n",
    "        Dk_hat_inv = 1 / Dk_hat\n",
    "\n",
    "        sk = torch.randn((batch_data.shape[1], 1), device=device)\n",
    "        sk= sk / sk.norm()\n",
    "        # yk, = torch.autograd.grad(g, w, grad_outputs=sk)\n",
    "        yk = torch.diagflat(Dk_hat) @ sk\n",
    "        yk_norm = torch.linalg.norm(yk)\n",
    "\n",
    "        # print(f\"yk norm: {yk_norm}\")\n",
    "\n",
    "        if torch.isnan(yk_norm):\n",
    "            continue\n",
    "\n",
    "        # B = ((yk.reshape(-1, 1) @ yk.reshape(1, -1)) / (yk.dot(sk)))\n",
    "        B = yk.T * yk / (sk.T @ yk)\n",
    "\n",
    "        gnorm = (g * Dk_hat_inv).dot(g)\n",
    "\n",
    "        # print(f\"D_hat_inv: {torch.linalg.norm(Dk_hat_inv)}\")\n",
    "        # print(f\"g_norm_D: {gnorm}\")\n",
    "\n",
    "        # if gnorm < 1e-15:\n",
    "        #     continue\n",
    "\n",
    "        f_grad = g.clone().detach()\n",
    "        D_inv = torch.diagflat(Dk_hat_inv.clone().detach())\n",
    "\n",
    "        a = torch.dot(f_grad, D_inv@f_grad)\n",
    "        a = a.cpu().detach().numpy()\n",
    "\n",
    "        b = torch.dot(f_grad, D_inv@B@D_inv@f_grad)\n",
    "        b = b.cpu().detach().numpy() \n",
    "\n",
    "        c = torch.trace(B@D_inv)\n",
    "        c = c.cpu().detach().numpy()\n",
    "\n",
    "        # if torch.linalg.norm(f_grad) < 1e-8:\n",
    "        #     continue\n",
    "\n",
    "        # print(\"loss: \", loss)\n",
    "        # print(f\"f_grad norm: {torch.linalg.norm(f_grad)}\")\n",
    "        # print(f\"D_inv norm: {torch.linalg.norm(D_inv)}\")\n",
    "        # print(f\"B norm: {torch.linalg.norm(B)}\") \n",
    "        # print(f\"a: {a}\")\n",
    "        # print(f\"b: {b}\")\n",
    "        # print(f\"c: {c}\") \n",
    "\n",
    "        AA = 2 * a * c ** 2\n",
    "        BB = 4 * a * c - 2 * loss.item() * c**2 - b * c\n",
    "        CC = 2 * a - 4 * c * loss.item() - 2 * b\n",
    "        DD = - 2 * loss.item()\n",
    "\n",
    "        \n",
    "        BB = BB / AA\n",
    "        CC = CC / AA\n",
    "        DD = DD / AA\n",
    "\n",
    "        AA = torch.tensor(1.0)\n",
    "        \n",
    "        # print(f\"plms: {AA} {BB} {CC} {DD}\")\n",
    "\n",
    "        def lagr(lmd):\n",
    "            b = lambda l: D_inv - (D_inv @ (l * B) @ D_inv) / (1 + torch.trace((l * B) @ D_inv))\n",
    "            return lmd * loss -  (1/2)*lmd**2 * torch.dot(f_grad, b(lmd)@f_grad)\n",
    "\n",
    "        lmds = solve(AA, BB, CC, DD)\n",
    "        lmds = torch.from_numpy(lmds).to(device)\n",
    "            \n",
    "        # print(\"lmds: \", lmds)\n",
    "        \n",
    "        lmd_max = torch.max(lmds)\n",
    "        lmd_min = torch.maximum(torch.min(lmds), torch.tensor(0))\n",
    "\n",
    "        # print(f\"lmd_max: {lmd_max}, lmd_min: {lmd_min}\")\n",
    "\n",
    "        lmd_star = lmd_max\n",
    "        if lagr(lmd_max) < lagr(lmd_min):\n",
    "            lmd_star = lmd_min\n",
    "\n",
    "        # print(\"lmd_star 2: \", lmd_star)\n",
    "\n",
    "        # print(\"D_inv norm: \", torch.linalg.norm(D_inv))\n",
    "        # print(\"B norm: \", torch.linalg.norm(B))\n",
    "        # print(\"lmd_star: \", lmd_star)\n",
    "        \n",
    "        precond = lmd_star * ((D_inv - (1 / (1 + lmd_star * torch.trace(B @ D_inv))) * (D_inv @ (lmd_star * B) @ D_inv) ))\n",
    "\n",
    "        # print(\"Precond norm: \", torch.linalg.norm(precond))\n",
    "        # print(\"==================\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w.sub_(precond  @ f_grad)\n",
    "\n",
    "    loss = loss_function(train_data.to(device), train_target.to(device))\n",
    "    g, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "    print(f\"Loss: {loss.item()} | GradNorm^2: {(torch.linalg.norm(g) ** 2 ).item()}\")\n",
    "    hist_sps_d.append([loss.item(), (torch.linalg.norm(g) ** 2).item()])\n",
    "\n",
    "print(f\"w-x: {torch.abs(torch.sum(w) - torch.sum(xopt))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy([x[0] for x in hist_sps_d], label=\"loss\")\n",
    "plt.semilogy([x[1] for x in hist_sps_d], label=\"grad\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\min \\frac{1}{2} \\| w - w^t \\|^2_B \\\\ \n",
    "s.t. \\quad f_i + \\langle \\nabla f_i, w - w^t \\rangle + \\frac{1}{2} \\langle B(w-w^t), (w-w^t) \\rangle = 0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farshed.abdukhakimov/projects/sps2/datasets\n",
      "Loss: 0.6931471805599453 | GradNorm^2: 25.480627894208755\n",
      "g_norm_l2: 20.69306094515359\n",
      "yk norm: 110.33770038095659\n",
      "g_norm: 1.0000000000000004\n",
      "loss:  tensor(0.6931, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "f_grad norm: 20.69306094515359\n",
      "B norm: 70.83156658122064\n",
      "lmds: [-1.0 - 1.60894358184558*I, -1.0 + 1.60894358184558*I]\n",
      "-1.0 - 1.60894358184558*I <class 'sympy.core.add.Add'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "maximum(): argument 'input' (position 1) must be Tensor, not Add",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb Cell 58\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m lmd_2 \u001b[39m=\u001b[39m lmds[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mprint\u001b[39m(lmd_1, \u001b[39mtype\u001b[39m(lmd_1))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m lmd_star \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmaximum(torch\u001b[39m.\u001b[39mtensor(\u001b[39m0\u001b[39m), torch\u001b[39m.\u001b[39;49mmaximum(lmd_1, lmd_2))        \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlmd_max: \u001b[39m\u001b[39m\"\u001b[39m, lmd_star)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.135/home/farshed.abdukhakimov/projects/sps2/notebooks/sps2_new.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# precond = lmd_star * (D_inv - (D_inv @ (lmd_star * B) @ D_inv) / (1 + torch.trace((lmd_star * B) @ D_inv)))\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: maximum(): argument 'input' (position 1) must be Tensor, not Add"
     ]
    }
   ],
   "source": [
    "# training \n",
    "STEPS = 20\n",
    "loss_class = get_loss(\"logreg\")\n",
    "\n",
    "\n",
    "# dataset\n",
    "batch_size = 16\n",
    "dataset_name = \"mushrooms\"\n",
    "percentage = 1.0\n",
    "scale_range = None # [-value, value]\n",
    "train_data, train_target = get_dataset(dataset_name, batch_size, percentage, scale_range, loss_class.y_range)\n",
    "train_load = data_utils.TensorDataset(train_data, train_target)\n",
    "train_dataloader = DataLoader(train_load, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# parameters\n",
    "w = torch.zeros(train_data.shape[1], dtype=torch.float64, device=device).requires_grad_()\n",
    "\n",
    "loss_function = loss_class(w)\n",
    "\n",
    "# save loss and grad size to history\n",
    "hist_sps_d = []\n",
    "loss = loss_function(train_data.to(device).to(torch.float64), train_target.to(device).to(torch.float64)) \n",
    "g, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "print(f\"Loss: {loss.item()} | GradNorm^2: {(torch.linalg.norm(g) ** 2 ).item()}\")\n",
    "hist_sps_d.append([loss.item(), (torch.linalg.norm(g) ** 2).item()])\n",
    "\n",
    "\n",
    "for step in range(STEPS):\n",
    "\n",
    "    for i, (batch_data, batch_target) in enumerate(train_dataloader):\n",
    "        batch_data = batch_data.to(device).to(torch.float64)\n",
    "        batch_target = batch_target.to(device).to(torch.float64)\n",
    "\n",
    "        loss = loss_function(batch_data, batch_target)\n",
    "        gk = g.clone().detach()\n",
    "        g, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "        g_delta = g - gk\n",
    "\n",
    "        print(f\"g_norm_l2: {torch.linalg.norm(g)}\")\n",
    "\n",
    "\n",
    "        sk = torch.randn(batch_data.shape[1], dtype=torch.float64, device=device)\n",
    "        yk, = torch.autograd.grad(g, w, grad_outputs=sk)\n",
    "        yk_norm = torch.linalg.norm(yk)\n",
    "\n",
    "        print(f\"yk norm: {yk_norm}\")\n",
    "\n",
    "        if yk_norm < 1e-10 or torch.isnan(yk_norm):\n",
    "            continue\n",
    "\n",
    "        B = ((sk.reshape(-1, 1) @ sk.reshape(1, -1)) / (yk.dot(sk))).to(dtype=torch.float64)\n",
    "\n",
    "        gnorm = (g @ B).dot(g)\n",
    "\n",
    "        print(f\"g_norm: {gnorm}\")\n",
    "\n",
    "        if gnorm < 1e-12:\n",
    "            continue\n",
    "\n",
    "        f_grad = g.clone().detach().to(dtype=torch.float64)\n",
    "        \n",
    "        if torch.linalg.norm(f_grad) < 1e-12:\n",
    "            continue\n",
    "\n",
    "        print(\"loss: \", loss)\n",
    "        print(f\"f_grad norm: {torch.linalg.norm(f_grad)}\")\n",
    "        print(f\"B norm: {torch.linalg.norm(B)}\") \n",
    "\n",
    "        lmd = sympy.Symbol('lmd')\n",
    "        expr = (2 * loss - gnorm) * lmd ** 2 + (4 * loss - 2 * gnorm) * lmd + 2 * loss\n",
    "        lmds = sympy.solve(expr)\n",
    "        print(f\"lmds: {lmds}\")\n",
    "        lmd_1 = lmds[0]\n",
    "        lmd_2 = lmds[1]\n",
    "\n",
    "        print(lmd_1, type(lmd_1))\n",
    "\n",
    "        lmd_star = torch.maximum(torch.tensor(0), torch.maximum(lmd_1, lmd_2))        \n",
    "        print(\"lmd_max: \", lmd_star)\n",
    "\n",
    "        # precond = lmd_star * (D_inv - (D_inv @ (lmd_star * B) @ D_inv) / (1 + torch.trace((lmd_star * B) @ D_inv)))\n",
    "        precond = lmd_star/(1 + lmd_star) * B \n",
    "\n",
    "        print(\"Precond norm: \", torch.linalg.norm(precond))\n",
    "        print(\"==================\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w.sub_(precond @ g)\n",
    "\n",
    "    \n",
    "\n",
    "    loss = loss_function(train_data.to(device).to(torch.float64), train_target.to(device).to(torch.float64))\n",
    "    g, = torch.autograd.grad(loss, w, create_graph=True)\n",
    "    print(f\"Loss: {loss.item()} | GradNorm^2: {(torch.linalg.norm(g) ** 2 ).item()}\")\n",
    "    hist_sps_d.append([loss.item(), (torch.linalg.norm(g) ** 2).item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('sps2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "35d98a01b571b9c5855d990661b06f31354de19c91463a2a0e2c023e458877c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
